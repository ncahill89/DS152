---
title: "Introduction to Image Analysis"
format: html
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidytext)
library(stopwords)
library(class)

mnist_train <- readRDS("data/mnist_train.rds")
mnist_test <- readRDS("data/mnist_test.rds")
mnist_melted <- readRDS("data/mnist_melted.rds")


pred_label_knn <- knn(mnist_train %>% select(-label), 
                      mnist_test %>% select(-label), 
                      cl = mnist_train$label , 
                      k = 5)


mnist_res <- mnist_test %>%
                select(label) %>% 
                mutate(pred_label = pred_label_knn)



```

## Image Analysis

### What is an Image?

-   What is an image? What does a computer "see"?
-   In essence, it is an array of numbers representing colour intensities called pixels.
-   The pixel (a word invented from "picture element") is the basic unit of programmable color on a computer display or in a computer image.

### Spot the snow leopard!

![](images/find_leopard.jpg)

### Spot the spider!

![](images/aranha_thiago.jpg)

### Image Analysis - Why?

The application of image analysis can be expanded to different domains of science, such as:

**Image detection on videos**

![](images/video.jpg)

**Autonomous cars**

![](images/aut_car.jpeg)

**Animals identification**

![](images/camera.png)

**Disease diagnosis**

![](images/malario.png)

<!-- **Measure Student Engagement** -->

<!-- ![](images/MoodRec.png) -->

### Example: MNIST handwritten digit database

http://yann.lecun.com/exdb/mnist/

-   70,000 grayscale images of handwritten numbers at low resolution (28 by 28 pixels)
-   Used 60,000 to train the algorithm and 10,000 to test

#### Values in the Dataset

1.  Pixel Values

-   Each pixel in an image is represented by a value from 0 to 255:

    -   0: Black (no ink)

    -   255: White (maximum ink)

    -   Intermediate values: Shades of gray

-   Most analysis will often normalize these values to a range of \[0.0, 1.0\] or \[-1.0, 1.0\] for training.

2.  Labels

-   Each image is labeled with the digit it represents: 0, 1, 2, ..., 9 (so 10 classes total)

#### Illustrative example of a single image

![](images/eight.jpeg)

### Visualising the numbers in the MNIST training dataset

The data needs to be reformatted for plotting. For example

```{r}
as_tibble(mnist_melted)
```

Then we can plot using standard ggplot methods. For example

```{r}
ggplot(mnist_melted, aes(x = x, y = y, fill = intensity)) +
  geom_tile() +
  scale_fill_continuous(name = "Pixel Intensity") +
  scale_y_reverse() +
  facet_wrap(~ image) +
  theme(
    strip.background = element_blank(),
    strip.text.x = element_blank(),
    panel.spacing = unit(0, "lines"),
    axis.text = element_blank(),
    axis.ticks = element_blank()
  ) +
  labs(
    title = "MNIST Image Data",
    subtitle = "Visualization of a sample of images contained in MNIST data set.",
    x = NULL,
    y = NULL
  )
```

### Image Classification Algorithms

-   we can use virtually ANY supervised classification algorithm (each pixel is a "feature" or "predictor")
-   e.g. k-nearest neighbours, trees/random forests, logistic/multinomial regression, support vector machines, neural networks
-   you have already studied a few of these techniques
-   We will use KNN to classify the images

### Formatting data for analysis

If we assume each pixel is a feature/predictor then we should format that data such that the columns are pixels and each row corresponds to an image.

We'll work with a subset of the MNIST data and consider 1000 images in the training data and 100 images in the test data.

```{r}
mnist_train
```

```{r}
mnist_test
```

### Applying KNN

```{r image1}
library(class)
pred_label_knn <- knn(mnist_train %>% select(-label), 
                      mnist_test %>% select(-label), 
                      cl = mnist_train$label , 
                      k = 5)
pred_label_knn
```

### Storing results

```{r image2}
mnist_res <- mnist_test %>%
                select(label) %>% 
                mutate(pred_label = pred_label_knn)

mnist_res
```

### Calculating accuracy

```{r image3}
N <- nrow(mnist_res)

confusion_mat <- table(mnist_res %>% select(label, pred_label))
confusion_mat

accuracy <- (confusion_mat %>% diag %>% sum)/N
accuracy
```
