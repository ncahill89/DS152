[
  {
    "objectID": "1-TidyverseRecap.html",
    "href": "1-TidyverseRecap.html",
    "title": "Tidyverse Recap",
    "section": "",
    "text": "The tidyverse is a collection of R packages designed for data science.\nAll packages share an underlying design philosophy, grammar, and data structures.\nIt emphasizes tidy data in data frames, performs operations one step at a time, connects with pipes and makes code human readable."
  },
  {
    "objectID": "1-TidyverseRecap.html#tidyr-pivot",
    "href": "1-TidyverseRecap.html#tidyr-pivot",
    "title": "Tidyverse Recap",
    "section": "tidyr: pivot",
    "text": "tidyr: pivot\n\n# Load the tidyr package\nlibrary(tidyr)\n\n\n# Assume we have a dataset 'data' with 'ID1', 'ID2', 'x', and 'y' columns\ndata_ex1 &lt;- tibble(ID1 = rep(LETTERS[1:4],times = 3), \n                   ID2 = rep(letters[1:3], each = 4), \n                   x = 1:12, \n                   y = 21:32)\n\nprint(data_ex1)\n\n# A tibble: 12 × 4\n   ID1   ID2       x     y\n   &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt;\n 1 A     a         1    21\n 2 B     a         2    22\n 3 C     a         3    23\n 4 D     a         4    24\n 5 A     b         5    25\n 6 B     b         6    26\n 7 C     b         7    27\n 8 D     b         8    28\n 9 A     c         9    29\n10 B     c        10    30\n11 C     c        11    31\n12 D     c        12    32\n\n# Use pivot_longer() to convert wide data to long format\ndata_long &lt;- data_ex1 %&gt;% pivot_longer(cols = c(\"x\", \"y\"), \n                                       names_to = \"Variable\", \n                                       values_to = \"Value\")\n\n# Print the long format data\nprint(data_long)\n\n# A tibble: 24 × 4\n   ID1   ID2   Variable Value\n   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;    &lt;int&gt;\n 1 A     a     x            1\n 2 A     a     y           21\n 3 B     a     x            2\n 4 B     a     y           22\n 5 C     a     x            3\n 6 C     a     y           23\n 7 D     a     x            4\n 8 D     a     y           24\n 9 A     b     x            5\n10 A     b     y           25\n# ℹ 14 more rows\n\n# Use pivot_wider() to convert long data back to wide format\ndata_wide &lt;- data_long %&gt;% pivot_wider(names_from = Variable,\n                                       values_from = Value)\n\n# Print the wide format data\nprint(data_wide)\n\n# A tibble: 12 × 4\n   ID1   ID2       x     y\n   &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt;\n 1 A     a         1    21\n 2 B     a         2    22\n 3 C     a         3    23\n 4 D     a         4    24\n 5 A     b         5    25\n 6 B     b         6    26\n 7 C     b         7    27\n 8 D     b         8    28\n 9 A     c         9    29\n10 B     c        10    30\n11 C     c        11    31\n12 D     c        12    32\n\n\nIn this example, pivot_longer is used to convert the wide format data to long format, where each row is a single observation associated with the variables ID1, ID2, Variable (containing the original column names ‘x’ and ‘y’), and Value (containing the values from ‘x’ and ‘y’ columns). We can then also convert back to wide format using pivot_wider."
  },
  {
    "objectID": "1-TidyverseRecap.html#tidyr-separate",
    "href": "1-TidyverseRecap.html#tidyr-separate",
    "title": "Tidyverse Recap",
    "section": "tidyr: separate",
    "text": "tidyr: separate\n\n# Load the tidyr package\nlibrary(tidyr)\n\n# Assume we have a dataset 'dataNew' with a 'datetime' column\ndata_ex2 &lt;- tibble(datetime = \n                    c(\"2016-01-01 07:30:29\", \"2016-01-02 09:43:36\", \"2016-01-03 13:59:00\"), \n                   event = c(\"u\", \"a\", \"l\"))\n\n# Use the separate() function from tidyr to separate the 'datetime' column into \n# 'date' and 'time'\n# Then separate 'time' into 'hour', 'min', 'second'\ndata_sep &lt;- data_ex2 %&gt;% \n              separate(datetime, c('date', 'time'), sep = ' ') %&gt;% \n              separate(time, c('hour', 'min', 'second'), sep = ':')\n\n# Print the new dataset\nprint(data_sep)\n\n# A tibble: 3 × 5\n  date       hour  min   second event\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;\n1 2016-01-01 07    30    29     u    \n2 2016-01-02 09    43    36     a    \n3 2016-01-03 13    59    00     l    \n\n# change hour, min, second to numeric values\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\ndata_sep %&gt;% mutate_at(vars(hour, min, second), as.numeric)\n\n# A tibble: 3 × 5\n  date        hour   min second event\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;\n1 2016-01-01     7    30     29 u    \n2 2016-01-02     9    43     36 a    \n3 2016-01-03    13    59      0 l"
  },
  {
    "objectID": "1-TidyverseRecap.html#example-dplyr",
    "href": "1-TidyverseRecap.html#example-dplyr",
    "title": "Tidyverse Recap",
    "section": "Example: dplyr",
    "text": "Example: dplyr\n\n# Load the dplyr package\nlibrary(dplyr)\n\n# Assume we have a dataset 'data' with 'ID', 'Age', 'Gender', and 'Income' columns\ndata_ex3 &lt;- tibble(ID = 1:4, \n                   Age = c(21, 35, 58, 40), \n                   Gender = c(\"Male\", \"Female\", \"Male\", \"Female\"), \n                   Income = c(50000, 80000, 120000, 75000))\n\n# Use select() to choose the 'ID' and 'Age' columns\nselected_data &lt;- data_ex3 %&gt;% select(ID, Age)\nselected_data\n\n# A tibble: 4 × 2\n     ID   Age\n  &lt;int&gt; &lt;dbl&gt;\n1     1    21\n2     2    35\n3     3    58\n4     4    40\n\n# Use filter() to get rows where 'Age' is greater than 30\nfiltered_data &lt;- data_ex3 %&gt;% filter(Age &gt; 30)\nfiltered_data\n\n# A tibble: 3 × 4\n     ID   Age Gender Income\n  &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;\n1     2    35 Female  80000\n2     3    58 Male   120000\n3     4    40 Female  75000\n\n# Use mutate() to create a new column 'IncomeInThousands'\nmutated_data &lt;- data_ex3 %&gt;% mutate(IncomeInThousands = Income / 1000)\nmutated_data\n\n# A tibble: 4 × 5\n     ID   Age Gender Income IncomeInThousands\n  &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;             &lt;dbl&gt;\n1     1    21 Male    50000                50\n2     2    35 Female  80000                80\n3     3    58 Male   120000               120\n4     4    40 Female  75000                75\n\n# Use arrange() to sort data by 'Income'\narranged_data &lt;- data_ex3 %&gt;% arrange(Income)\narranged_data\n\n# A tibble: 4 × 4\n     ID   Age Gender Income\n  &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;\n1     1    21 Male    50000\n2     4    40 Female  75000\n3     2    35 Female  80000\n4     3    58 Male   120000\n\n# Use summarise() to get the mean 'Income'\nsummary_data &lt;- data_ex3 %&gt;% summarise(MeanIncome = mean(Income))\nsummary_data\n\n# A tibble: 1 × 1\n  MeanIncome\n       &lt;dbl&gt;\n1      81250\n\n# Use group_by() and summarise() to get the mean 'Income' for each 'Gender'\ngrouped_data &lt;- data_ex3 %&gt;% \n                  group_by(Gender) %&gt;% \n                  summarise(MeanIncome = mean(Income))\ngrouped_data\n\n# A tibble: 2 × 2\n  Gender MeanIncome\n  &lt;chr&gt;       &lt;dbl&gt;\n1 Female      77500\n2 Male        85000\n\n\nIn these examples, select is used to choose specific columns, filter is used to select rows based on a condition, mutate is used to create a new column, arrange is used to sort data, summarise is used to calculate summary statistics, and group_by is used to perform operations on groups of data."
  },
  {
    "objectID": "1-TidyverseRecap.html#example-ggplot",
    "href": "1-TidyverseRecap.html#example-ggplot",
    "title": "Tidyverse Recap",
    "section": "Example: ggplot",
    "text": "Example: ggplot"
  },
  {
    "objectID": "1-TidyverseRecap.html#question",
    "href": "1-TidyverseRecap.html#question",
    "title": "Tidyverse Recap",
    "section": "Question",
    "text": "Question\nSuppose we have a dataset called penguins and suppose we would like to study how the ratio of penguin body mass to flipper size differs across the species in the dataset. Rearrange the following steps in the pipeline into an order that accomplishes this goal.\n\n# a\narrange(avg_mass_flipper_ratio)\n\n# b\ngroup_by(species)\n\n# c\npenguins \n  \n# d\nsummarise(\n  avg_mass_flipper_ratioo = median(mass_flipper_ratio)\n)\n  \n# e\nmutate(\n  mass_flipper_ratio = body_mass_g/flipper_length_mm\n)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to Introduction to Data Science (2)!",
    "section": "",
    "text": "Welcome to the course website for DS152 Introduction to Data Science (2).\nModule information\nLecture material (slides, notes, videos) are licensed under CC-BY-NC 4.0.\nContact: Niamh Cahill (niamh.cahill@mu.ie)"
  },
  {
    "objectID": "index.html#lecture-slides",
    "href": "index.html#lecture-slides",
    "title": "Welcome to Bayesian Data Analysis!",
    "section": "Lecture Slides",
    "text": "Lecture Slides\n\nWeek 1\n1a: Bayes Rule\n1b: Inferring a Binomial Probability\n\n\nWeek 2\n2a: Beta Binomial\n2b: Bayesian Inference\n\n\nWeek 3\n3: Single Parameter Normal\n\n\nWeek 4\n4: MCMC Sampling\n\n\nWeek 5\n5a: MCMC Diagnostics\n5b: Just Another Gibbs Sampler\n\n\nWeek 6\n6: Bayesian Linear Regression\n\n\nWeek 7\n7: Model Checking\n\n\nWeek 8\n8: Introducing Bayesian Hierarchical Modelling\n\n\nWeek 9\n9: Bayesian Hierarchical Regression Modelling\n\n\nWeek 10\n10: Bayesian Generalised Linear Models (GLMs)\n\n\nWeek 11\n11: Bayesian Hierarchical Modelling - GLM"
  },
  {
    "objectID": "index.html#tutorials",
    "href": "index.html#tutorials",
    "title": "Welcome to Bayesian Data Analysis!",
    "section": "Tutorials",
    "text": "Tutorials\nTutorial Sheet 1: Bayesian inference using binomial and Poisson models\n\nTutorial Sheet 2: Bayesian Model for Multiple Proportions - Email Campaign Click-Through Rates\nTutorial Sheet 3: Bayesian Regression Model - Fisherys Data\nTutorial Sheet 4: Bayesian Hierarchical Regression Modelling - Simulation"
  },
  {
    "objectID": "index.html#assignments",
    "href": "index.html#assignments",
    "title": "Welcome to Introduction to Data Science (2)!",
    "section": "Assignments",
    "text": "Assignments\nAssignment 1: Tidyverse Recap\nAssignment 2: Linear Regression\nAssignment 3: Sampling and Observational Studies\nAssignment 4: Experimental Studies"
  },
  {
    "objectID": "index.html#lecture-notes",
    "href": "index.html#lecture-notes",
    "title": "Welcome to Introduction to Data Science (2)!",
    "section": "Lecture Notes",
    "text": "Lecture Notes\n1: Tidyverse Recap\n2: Correlation (and Causation)\n3: Multiple Regression Models\n4: Sampling Principles and Strategies\n5: Observational Studies\n6: Experimental Studies\n7: Predictive Analytics\n8: (un)Supervised Learning\n9: Text Analysis"
  },
  {
    "objectID": "0-Information.html#course-organisation",
    "href": "0-Information.html#course-organisation",
    "title": "Module Information",
    "section": "",
    "text": "Lecture and Lab Timetable\n\nMonday 11am (Lecture, CB8), Wednesday 2pm (Lecture, CH)\nTuesday 3pm (Lab, TSI239), Friday 9am (Lab, TSI239)\n\nLabs will start in week 2\nPlease confirm your choice on Moodle.\n\n\nTutorials\n\nTuesdays @ 9am, 10am, 2pm, 3pm, 5pm, Wednesdays @ 12pm, 1pm\nTutorials – starting week 4 (24/02/2025)\n\nOffice hours\n\nBy appointment"
  },
  {
    "objectID": "0-Information.html#course-organisation-1",
    "href": "0-Information.html#course-organisation-1",
    "title": "Module Information",
    "section": "Course organisation",
    "text": "Course organisation\nMarks\n\n10% – compulsory assignments\n10% – quizzes\n15% – mid-term exam (March 28th, MCQ)\n65% – final exam (date TBC)\n\nNotes\n\nNotes will be a combination of handouts posted on Moodle and notes taken down in class\n\nAssignments\n\nWill be uploaded PDFs\n\nRecommended reading\n\nR for Data Science (https://r4ds.had.co.nz)"
  },
  {
    "objectID": "0-Information.html#diversity-inclusion",
    "href": "0-Information.html#diversity-inclusion",
    "title": "Module Information",
    "section": "Diversity & inclusion",
    "text": "Diversity & inclusion\nIt is my intent to present materials and activities that are respectful of diversity: gender identity, sexuality, disability, age, socioeconomic status, ethnicity, race, nationality, religion, and culture. I may not always get this right so please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nTo help with this:\n\nIf you have a name that differs from those that appear in your official University records, please let me know!\nPlease let me know your preferred pronouns if you wish to do so.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "0-Information.html",
    "href": "0-Information.html",
    "title": "Module Information",
    "section": "",
    "text": "Lecture and Lab Timetable\n\nMonday 11am (Lecture, CB8), Wednesday 2pm (Lecture, CH)\nTuesday 3pm (Lab, TSI239), Friday 9am (Lab, TSI239)\n\nLabs will start in week 2\nPlease confirm your choice on Moodle.\n\n\nTutorials\n\nTuesdays @ 9am, 10am, 2pm, 3pm, 5pm, Wednesdays @ 12pm, 1pm\nTutorials – starting week 4 (24/02/2025)\n\nOffice hours\n\nBy appointment"
  },
  {
    "objectID": "1-TidyverseRecap.html#what-is-tidyverse",
    "href": "1-TidyverseRecap.html#what-is-tidyverse",
    "title": "Tidyverse Recap",
    "section": "",
    "text": "The tidyverse is a collection of R packages designed for data science.\nAll packages share an underlying design philosophy, grammar, and data structures.\nIt emphasizes tidy data in data frames, performs operations one step at a time, connects with pipes and makes code human readable."
  },
  {
    "objectID": "1-TidyverseRecap.html#key-packages-in-tidyverse",
    "href": "1-TidyverseRecap.html#key-packages-in-tidyverse",
    "title": "Tidyverse Recap",
    "section": "Key Packages in tidyverse",
    "text": "Key Packages in tidyverse\n\nreadr: Used for importing data.\ntidyr: Used for tidying and reshaping data.\ndplyr: Used for data transformation.\nggplot2: Used for data visualization.\nmagrittr: Provides the pipe operator (%&gt;%) or (|&gt;) which is used to chain together sequences of operations."
  },
  {
    "objectID": "1-TidyverseRecap.html#importing-data-with-readr",
    "href": "1-TidyverseRecap.html#importing-data-with-readr",
    "title": "Tidyverse Recap",
    "section": "Importing Data with readr",
    "text": "Importing Data with readr\n\nreadr provides faster and consistent replacements for data import functions in base R.\nIt fits into the tidyverse naturally and extends neatly into other data types.\nExample: read_csv(file, show_col_types = FALSE)."
  },
  {
    "objectID": "1-TidyverseRecap.html#tidying-data-with-tidyr",
    "href": "1-TidyverseRecap.html#tidying-data-with-tidyr",
    "title": "Tidyverse Recap",
    "section": "Tidying Data with tidyr",
    "text": "Tidying Data with tidyr\n\ntidyr provides a set of functions that help to tidy data.\nTidy data is data where every column is a variable, every row is an observation, and every cell is a single value.\n\n\ntidyr: pivot\n\n# Load the tidyr package\nlibrary(tidyr)\n\n\n# Assume we have a dataset 'data' with 'ID1', 'ID2', 'x', and 'y' columns\ndata_ex1 &lt;- tibble(ID1 = rep(LETTERS[1:4],times = 3), \n                   ID2 = rep(letters[1:3], each = 4), \n                   x = 1:12, \n                   y = 21:32)\n\nprint(data_ex1)\n\n# A tibble: 12 × 4\n   ID1   ID2       x     y\n   &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt;\n 1 A     a         1    21\n 2 B     a         2    22\n 3 C     a         3    23\n 4 D     a         4    24\n 5 A     b         5    25\n 6 B     b         6    26\n 7 C     b         7    27\n 8 D     b         8    28\n 9 A     c         9    29\n10 B     c        10    30\n11 C     c        11    31\n12 D     c        12    32\n\n# Use pivot_longer() to convert wide data to long format\ndata_long &lt;- data_ex1 %&gt;% pivot_longer(cols = c(\"x\", \"y\"), \n                                       names_to = \"Variable\", \n                                       values_to = \"Value\")\n\n# Print the long format data\nprint(data_long)\n\n# A tibble: 24 × 4\n   ID1   ID2   Variable Value\n   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;    &lt;int&gt;\n 1 A     a     x            1\n 2 A     a     y           21\n 3 B     a     x            2\n 4 B     a     y           22\n 5 C     a     x            3\n 6 C     a     y           23\n 7 D     a     x            4\n 8 D     a     y           24\n 9 A     b     x            5\n10 A     b     y           25\n# ℹ 14 more rows\n\n# Use pivot_wider() to convert long data back to wide format\ndata_wide &lt;- data_long %&gt;% pivot_wider(names_from = Variable,\n                                       values_from = Value)\n\n# Print the wide format data\nprint(data_wide)\n\n# A tibble: 12 × 4\n   ID1   ID2       x     y\n   &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt;\n 1 A     a         1    21\n 2 B     a         2    22\n 3 C     a         3    23\n 4 D     a         4    24\n 5 A     b         5    25\n 6 B     b         6    26\n 7 C     b         7    27\n 8 D     b         8    28\n 9 A     c         9    29\n10 B     c        10    30\n11 C     c        11    31\n12 D     c        12    32\n\n\nIn this example, pivot_longer is used to convert the wide format data to long format, where each row is a single observation associated with the variables ID1, ID2, Variable (containing the original column names ‘x’ and ‘y’), and Value (containing the values from ‘x’ and ‘y’ columns). We can then also convert back to wide format using pivot_wider.\n\n\ntidyr: separate\n\n# Load the tidyr package\nlibrary(tidyr)\n\n# Assume we have a dataset 'dataNew' with a 'datetime' column\ndata_ex2 &lt;- tibble(datetime = \n                    c(\"2016-01-01 07:30:29\", \"2016-01-02 09:43:36\", \"2016-01-03 13:59:00\"), \n                   event = c(\"u\", \"a\", \"l\"))\n\n# Use the separate() function from tidyr to separate the 'datetime' column into \n# 'date' and 'time'\n# Then separate 'time' into 'hour', 'min', 'second'\ndata_sep &lt;- data_ex2 %&gt;% \n              separate(datetime, c('date', 'time'), sep = ' ') %&gt;% \n              separate(time, c('hour', 'min', 'second'), sep = ':')\n\n# Print the new dataset\nprint(data_sep)\n\n# A tibble: 3 × 5\n  date       hour  min   second event\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;\n1 2016-01-01 07    30    29     u    \n2 2016-01-02 09    43    36     a    \n3 2016-01-03 13    59    00     l    \n\n# change hour, min, second to numeric values\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\ndata_sep %&gt;% mutate_at(vars(hour, min, second), as.numeric)\n\n# A tibble: 3 × 5\n  date        hour   min second event\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;\n1 2016-01-01     7    30     29 u    \n2 2016-01-02     9    43     36 a    \n3 2016-01-03    13    59      0 l"
  },
  {
    "objectID": "1-TidyverseRecap.html#transforming-data-with-dplyr",
    "href": "1-TidyverseRecap.html#transforming-data-with-dplyr",
    "title": "Tidyverse Recap",
    "section": "Transforming Data with dplyr",
    "text": "Transforming Data with dplyr\n\ndplyr is a grammar of data manipulation, providing a consistent set of verbs that solve the most common data manipulation challenges.\nExample: filter(data, condition).\n\n\nExample: dplyr\n\n# Load the dplyr package\nlibrary(dplyr)\n\n# Assume we have a dataset 'data' with 'ID', 'Age', 'Gender', and 'Income' columns\ndata_ex3 &lt;- tibble(ID = 1:4, \n                   Age = c(21, 35, 58, 40), \n                   Gender = c(\"Male\", \"Female\", \"Male\", \"Female\"), \n                   Income = c(50000, 80000, 120000, 75000))\n\n# Use select() to choose the 'ID' and 'Age' columns\nselected_data &lt;- data_ex3 %&gt;% select(ID, Age)\nselected_data\n\n# A tibble: 4 × 2\n     ID   Age\n  &lt;int&gt; &lt;dbl&gt;\n1     1    21\n2     2    35\n3     3    58\n4     4    40\n\n# Use filter() to get rows where 'Age' is greater than 30\nfiltered_data &lt;- data_ex3 %&gt;% filter(Age &gt; 30)\nfiltered_data\n\n# A tibble: 3 × 4\n     ID   Age Gender Income\n  &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;\n1     2    35 Female  80000\n2     3    58 Male   120000\n3     4    40 Female  75000\n\n# Use mutate() to create a new column 'IncomeInThousands'\nmutated_data &lt;- data_ex3 %&gt;% mutate(IncomeInThousands = Income / 1000)\nmutated_data\n\n# A tibble: 4 × 5\n     ID   Age Gender Income IncomeInThousands\n  &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;             &lt;dbl&gt;\n1     1    21 Male    50000                50\n2     2    35 Female  80000                80\n3     3    58 Male   120000               120\n4     4    40 Female  75000                75\n\n# Use arrange() to sort data by 'Income'\narranged_data &lt;- data_ex3 %&gt;% arrange(Income)\narranged_data\n\n# A tibble: 4 × 4\n     ID   Age Gender Income\n  &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;\n1     1    21 Male    50000\n2     4    40 Female  75000\n3     2    35 Female  80000\n4     3    58 Male   120000\n\n# Use summarise() to get the mean 'Income'\nsummary_data &lt;- data_ex3 %&gt;% summarise(MeanIncome = mean(Income))\nsummary_data\n\n# A tibble: 1 × 1\n  MeanIncome\n       &lt;dbl&gt;\n1      81250\n\n# Use group_by() and summarise() to get the mean 'Income' for each 'Gender'\ngrouped_data &lt;- data_ex3 %&gt;% \n                  group_by(Gender) %&gt;% \n                  summarise(MeanIncome = mean(Income))\ngrouped_data\n\n# A tibble: 2 × 2\n  Gender MeanIncome\n  &lt;chr&gt;       &lt;dbl&gt;\n1 Female      77500\n2 Male        85000\n\n\nIn these examples, select is used to choose specific columns, filter is used to select rows based on a condition, mutate is used to create a new column, arrange is used to sort data, summarise is used to calculate summary statistics, and group_by is used to perform operations on groups of data."
  },
  {
    "objectID": "1-TidyverseRecap.html#visualizing-data-with-ggplot2",
    "href": "1-TidyverseRecap.html#visualizing-data-with-ggplot2",
    "title": "Tidyverse Recap",
    "section": "Visualizing Data with ggplot2",
    "text": "Visualizing Data with ggplot2\n\nggplot2 is a system for declaratively creating graphics, based on “The Grammar of Graphics”.\nYou provide the data, tell ggplot2 how to map variables to aesthetics, what graphic to use, and it takes care of the details.\n\n\n\n\nExample: ggplot\nBasic scatter plot with a regression line\n\n# Load the ggplot2 package\nlibrary(ggplot2)\n\np1 &lt;- ggplot(mtcars, aes(x = mpg, y = hp)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\")\np1\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nHistogram\n\n# Load the ggplot2 package\nlibrary(ggplot2)\n\np2 &lt;- ggplot(mtcars, aes(x = mpg)) +\n  geom_histogram(binwidth = 2, fill = \"blue\", color = \"white\")\np2\n\n\n\n\n\n\n\n\nBoxplot\n\n# Load the ggplot2 package\nlibrary(ggplot2)\n\np3 &lt;- ggplot(mtcars, aes(x = factor(cyl), y = mpg)) +\n  geom_boxplot(fill = \"orange\", color = \"darkred\")\np3\n\n\n\n\n\n\n\n\nBar chart\n\n# Load the ggplot2 package\nlibrary(ggplot2)\n\np4 &lt;- ggplot(mtcars, aes(x = factor(cyl))) +\n  geom_bar(fill = \"steelblue\") +\n  labs(x = \"Number of cylinders\", y = \"Frequency\")\np4\n\n\n\n\n\n\n\n\nIn these examples, geom_point is used to create a scatter plot, geom_smooth with method = \"lm\" is used to add a linear regression line, geom_histogram is used to create a histogram, geom_boxplot is used to create a boxplot, and geom_bar is used to create a bar chart."
  },
  {
    "objectID": "1-TidyverseRecap.html#class-exercise",
    "href": "1-TidyverseRecap.html#class-exercise",
    "title": "Tidyverse Recap",
    "section": "Class Exercise",
    "text": "Class Exercise\nSuppose we have a dataset called penguins and suppose we would like to study how the ratio of penguin body mass to flipper size differs across the species in the dataset. Rearrange the following steps in the pipeline into an order that accomplishes this goal.\n\n# a\narrange(avg_mass_flipper_ratio)\n\n# b\ngroup_by(species) %&gt;% \n\n# c\npenguins %&gt;% \n  \n# d\nsummarise(\n  avg_mass_flipper_ratio = median(mass_flipper_ratio, na.rm = TRUE)\n) %&gt;% \n  \n# e\nmutate(\n  mass_flipper_ratio = body_mass_g/flipper_length_mm\n) %&gt;%"
  },
  {
    "objectID": "2-Correlation.html",
    "href": "2-Correlation.html",
    "title": "Correlation (and Causation)",
    "section": "",
    "text": "When we see a pattern, we don’t just say “how extraordinary!” and move on; instead, we try and attribute a cause!\nhttps://www.tylervigen.com/spurious-correlations"
  },
  {
    "objectID": "2-Correlation.html#correlation-vs.-causation",
    "href": "2-Correlation.html#correlation-vs.-causation",
    "title": "Causation and Correlation",
    "section": "",
    "text": "When we see a pattern, we don’t just say “how extraordinary!” and move on; instead, we try and attribute a cause!\n\nWe all draw conclusions on the basis of what we see\nBut it is important for us to remember that just because there is a correlation between two facts, there isn’t necessarily a cause/effect relationship between them.\n\nlistening to loud music and acne\nice cream consumption and shark attacks\nhand size and reading ability in children\n…\n\nThese variables are correlated, but one does not cause the other!\n\nhttps://www.tylervigen.com/spurious-correlations"
  },
  {
    "objectID": "2-Correlation.html#correlation",
    "href": "2-Correlation.html#correlation",
    "title": "Correlation (and Causation)",
    "section": "Correlation",
    "text": "Correlation\nCorrelation (r) quantifies the linear association between two quantitative variables.\n\nThe value of \\(r\\) is between -1 and 1.\n\\(r &gt;\\) 0 when \\(x\\) and \\(y\\) have a positive association.\n\\(r &lt;\\) 0 when \\(x\\) and \\(y\\) have a negative association.\n\\(r\\) = 1 means a perfect positive linear association.\n\\(r\\) = -1 means a perfect negative linear association.\n\\(r\\) = 0 indicates no linear association between \\(x\\) and \\(y\\).\nThe value of \\(r\\) is a measure of the extent to which \\(x\\) and \\(y\\) are linearly related."
  },
  {
    "objectID": "2-Correlation.html#what-are-the-correlation-values-here",
    "href": "2-Correlation.html#what-are-the-correlation-values-here",
    "title": "Correlation (and Causation)",
    "section": "What are the correlation values here?",
    "text": "What are the correlation values here?\nTask: Match the plot panel number to the letter with the correct correlation value.\n\n\n\n\n\n\n\n\n\n          A           B           C           D           E           F \n-0.02770462  0.96643642 -0.69813746  0.04969697 -0.96735724  0.11948059 \n          G           H \n-0.39421900  0.67692544"
  },
  {
    "objectID": "2-Correlation.html#what-are-the-correlation-values-here-1",
    "href": "2-Correlation.html#what-are-the-correlation-values-here-1",
    "title": "Causation and Correlation",
    "section": "What are the correlation values here?",
    "text": "What are the correlation values here?"
  },
  {
    "objectID": "2-Correlation.html#what-are-the-correlation-values-here-2",
    "href": "2-Correlation.html#what-are-the-correlation-values-here-2",
    "title": "Causation and Correlation",
    "section": "What are the correlation values here?",
    "text": "What are the correlation values here?"
  },
  {
    "objectID": "2-Correlation.html#what-are-the-correlation-values-here-3",
    "href": "2-Correlation.html#what-are-the-correlation-values-here-3",
    "title": "Causation and Correlation",
    "section": "What are the correlation values here?",
    "text": "What are the correlation values here?"
  },
  {
    "objectID": "2-Correlation.html#what-are-the-correlation-values-here-4",
    "href": "2-Correlation.html#what-are-the-correlation-values-here-4",
    "title": "Causation and Correlation",
    "section": "What are the correlation values here?",
    "text": "What are the correlation values here?"
  },
  {
    "objectID": "2-Correlation.html#what-are-the-correlation-values-here-5",
    "href": "2-Correlation.html#what-are-the-correlation-values-here-5",
    "title": "Causation and Correlation",
    "section": "What are the correlation values here?",
    "text": "What are the correlation values here?"
  },
  {
    "objectID": "2-Correlation.html#what-are-the-correlation-values-here-6",
    "href": "2-Correlation.html#what-are-the-correlation-values-here-6",
    "title": "Causation and Correlation",
    "section": "What are the correlation values here?",
    "text": "What are the correlation values here?"
  },
  {
    "objectID": "2-Correlation.html#what-are-the-correlation-values-here-7",
    "href": "2-Correlation.html#what-are-the-correlation-values-here-7",
    "title": "Causation and Correlation",
    "section": "What are the correlation values here?",
    "text": "What are the correlation values here?"
  },
  {
    "objectID": "2-Correlation.html#calculating-the-correlation-coefficient",
    "href": "2-Correlation.html#calculating-the-correlation-coefficient",
    "title": "Correlation (and Causation)",
    "section": "Calculating the correlation coefficient",
    "text": "Calculating the correlation coefficient\nWe denote \\[\\begin{eqnarray*}\nS_{xx} &=& \\sum_{i=1}^{n}(x_i - \\bar{x})^2 = \\sum_{i=1}^{n}x_i^2 - n\\bar{x}^2 \\\\\nS_{yy} &=& \\sum_{i=1}^{n}(y_i - \\bar{y})^2 = \\sum_{i=1}^{n}y_i^2 - n\\bar{y}^2 \\\\\nS_{xy} &=& \\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y}) = \\sum_{i=1}^{n}x_iy_i - n\\bar{x}\\bar{y}\n\\end{eqnarray*}\\]\nThen \\[\\begin{eqnarray*}\nr &=& \\frac{Sxy}{\\sqrt{SxxSyy}}     \n\\end{eqnarray*}\\]\n\nExample: Calculate the correlation between \\(x\\) and \\(y\\)\n\n\n\n\n\nx\n2\n4\n1\n6\n7\n\n\ny\n3\n4\n0\n8\n8\n\n\n\n\n\n\n\\[\\begin{align*}\n&\\sum_{i=1}^{n}x_i^2=106, \\sum_{i=1}^{n}y_i^2=153, \\sum_{i=1}^{n}x_iy_i=126, \\bar{x}=4,\\bar{y}=4.6\\\\\n&S_{xx} = \\sum_{i=1}^{n}x_i^2 - n\\bar{x}^2 = 26, S_{yy} = \\sum_{i=1}^{n}y_i^2 - n\\bar{y}^2 = 47.2\\\\\n&S_{xy} = \\sum_{i=1}^{n}x_iy_i - n\\bar{x}\\bar{y} = 34\\\\\n\\\\\n&r = \\frac{Sxy}{\\sqrt{SxxSyy}} = \\frac{34}{\\sqrt{26 \\times 47.2}} = 0.97        \n\\end{align*}\\]\n\n\nExample: Change of scale and the correlation coefficient\nThe distance of the race and the time it took to complete was recorded for five races in kilometres and seconds respectively. The correlation was calculated between the two variables. The data set was also converted into miles (\\(\\times\\) 0.621371192) and minutes (/60) and the correlation was re-calculated.\n\n\n\n\n\nKilometres\nSeconds\nMiles\nMinutes\n\n\n\n\n0.1\n10\n0.0621371\n0.1666667\n\n\n0.4\n120\n0.2485485\n2.0000000\n\n\n0.8\n300\n0.4970970\n5.0000000\n\n\n1.6\n535\n0.9941939\n8.9166667\n\n\n3.0\n950\n1.8641136\n15.8333333\n\n\n\n\n\n\n\n\n\n\n\nNotes\n\n\n\n\nIf \\(x\\) and \\(y\\) measurement units are changed, correlation does not change.\nIf \\(x\\) and \\(y\\) are reversed, i.e. correlation of \\(y\\) and \\(x\\), the correlation does not change.\nCorrelation is a measure of linear association. It does not establish causation.\nTwo variables, x and y, could be highly correlated because there is another variable, z, having an impact on both x and y."
  },
  {
    "objectID": "2-Correlation.html#example-calculate-the-correlation-between-x-and-y",
    "href": "2-Correlation.html#example-calculate-the-correlation-between-x-and-y",
    "title": "Causation and Correlation",
    "section": "Example: Calculate the correlation between \\(x\\) and \\(y\\)",
    "text": "Example: Calculate the correlation between \\(x\\) and \\(y\\)\n\n\n\n\n\nx\n2\n4\n1\n6\n7\n\n\ny\n3\n4\n0\n8\n8\n\n\n\n\n\n\n\\[\\begin{align*}\n&\\sum_{i=1}^{n}x_i^2=106, \\sum_{i=1}^{n}y_i^2=153, \\sum_{i=1}^{n}x_iy_i=126, \\bar{x}=4,\\bar{y}=4.6\\\\\n&S_{xx} = \\sum_{i=1}^{n}x_i^2 - n\\bar{x}^2 = 26, S_{yy} = \\sum_{i=1}^{n}y_i^2 - n\\bar{y}^2 = 47.2\\\\\n&S_{xy} = \\sum_{i=1}^{n}x_iy_i - n\\bar{x}\\bar{y} = 34\\\\\n\\\\\n&r = \\frac{Sxy}{\\sqrt{SxxSyy}} = \\frac{34}{\\sqrt{26 \\times 47.2}} = 0.97        \n\\end{align*}\\]"
  },
  {
    "objectID": "2-Correlation.html#notes-on-correlation",
    "href": "2-Correlation.html#notes-on-correlation",
    "title": "Causation and Correlation",
    "section": "Notes on correlation",
    "text": "Notes on correlation\n\nIf \\(x\\) and \\(y\\) measurement units are changed, correlation does not change.\nIf \\(x\\) and \\(y\\) are reversed, i.e. correlation of \\(y\\) and \\(x\\), the correlation does not change.\nCorrelation is a measure of linear association. It does not establish causation.\nTwo variables, x and y, could be highly correlated because there is another variable, z, having an impact on both x and y.\n\nExample, we have not established that extra height causes bigger feet. In fact genetic factors cause both."
  },
  {
    "objectID": "2-Correlation.html#example-change-of-scale-and-the-correlation-coefficient",
    "href": "2-Correlation.html#example-change-of-scale-and-the-correlation-coefficient",
    "title": "Causation and Correlation",
    "section": "Example: Change of scale and the correlation coefficient",
    "text": "Example: Change of scale and the correlation coefficient\nThe distance of the race and the time it took to complete was recorded for five races in kilometres and seconds respectively. The correlation was calculated between the two variables. The data set was also converted into miles (\\(\\times\\) 0.621371192) and minutes (/60) and the correlation was re-calculated.\n\n\n\n\n\nKilometres\nSeconds\nMiles\nMinutes\n\n\n\n\n0.1\n10\n0.0621371\n0.1666667\n\n\n0.4\n120\n0.2485485\n2.0000000\n\n\n0.8\n300\n0.4970970\n5.0000000\n\n\n1.6\n535\n0.9941939\n8.9166667\n\n\n3.0\n950\n1.8641136\n15.8333333"
  },
  {
    "objectID": "2-Correlation.html#explore-spurious-correlations",
    "href": "2-Correlation.html#explore-spurious-correlations",
    "title": "Causation and Correlation",
    "section": "Explore Spurious Correlations",
    "text": "Explore Spurious Correlations\nFind two correlated variables from: https://www.tylervigen.com/spurious-correlations.\nCreate a scatter plot and find the correlation."
  },
  {
    "objectID": "2-Correlation.html#association-between-pga-golfers-accuracy-and-driving-distance",
    "href": "2-Correlation.html#association-between-pga-golfers-accuracy-and-driving-distance",
    "title": "Causation and Correlation",
    "section": "Association between PGA golfer’s accuracy and driving distance",
    "text": "Association between PGA golfer’s accuracy and driving distance\nDescription:\nThe data set `golf’ was taken from PGA Tour Recordsof 195 golf rounds by PGA players in an attempt to explain what golf attributes contribute the most to low scores."
  },
  {
    "objectID": "2-Correlation.html#spurious-correlations",
    "href": "2-Correlation.html#spurious-correlations",
    "title": "Correlation (and Causation)",
    "section": "Spurious Correlations",
    "text": "Spurious Correlations\nA spurious correlation is a statistical relationship between two variables that appears to be meaningful but is actually caused by coincidence or the influence of a third (confounding) variable. This misleading association can arise due to random chance, indirect causation, or omitted variables.\nFor example, there may be a strong correlation between ice cream sales and drowning incidents, but this does not mean one causes the other. Instead, a third factor—hot weather—increases both ice cream sales and swimming activity, which in turn raises the risk of drowning.\nSpurious correlations can often be identified through deeper statistical analysis, such as controlling for confounding variables or using causal inference techniques.\nTask: Find two correlated variables from: https://www.tylervigen.com/spurious-correlations. Create a scatter plot and find the correlation."
  },
  {
    "objectID": "2-Correlation.html#what-is-the-capital-of-france",
    "href": "2-Correlation.html#what-is-the-capital-of-france",
    "title": "Causation and Correlation",
    "section": "What is the capital of France?",
    "text": "What is the capital of France?\n\nLondon\nParis\nBerlin\nMadrid"
  },
  {
    "objectID": "2-Correlation.html#example-data-1-association-between-pga-golfers-accuracy-and-driving-distance",
    "href": "2-Correlation.html#example-data-1-association-between-pga-golfers-accuracy-and-driving-distance",
    "title": "Causation and Correlation",
    "section": "Example Data (1): Association between PGA golfer’s accuracy and driving distance",
    "text": "Example Data (1): Association between PGA golfer’s accuracy and driving distance\nDescription:\nThe data set `golf’ was taken from PGA Tour Recordsof 195 golf rounds by PGA players in an attempt to explain what golf attributes contribute the most to low scores."
  },
  {
    "objectID": "2-Correlation.html#example-data-2-association-between-pga-golfers-accuracy-and-driving-distance",
    "href": "2-Correlation.html#example-data-2-association-between-pga-golfers-accuracy-and-driving-distance",
    "title": "Causation and Correlation",
    "section": "Example Data (2): Association between PGA golfer’s accuracy and driving distance",
    "text": "Example Data (2): Association between PGA golfer’s accuracy and driving distance"
  },
  {
    "objectID": "2-Correlation.html#example-data-1-what-is-the-association-between-pga-golfers-accuracy-and-driving-distance",
    "href": "2-Correlation.html#example-data-1-what-is-the-association-between-pga-golfers-accuracy-and-driving-distance",
    "title": "Correlation (and Causation)",
    "section": "Example Data (1): What is the association between PGA golfer’s accuracy and driving distance?",
    "text": "Example Data (1): What is the association between PGA golfer’s accuracy and driving distance?\nThe data set `golf’ was taken from PGA Tour Recordsof 195 golf rounds by PGA players in an attempt to explain what golf attributes contribute the most to low scores."
  },
  {
    "objectID": "2-Correlation.html#example-data-2-what-is-the-relationship-between-cars-weights-and-their-mileage",
    "href": "2-Correlation.html#example-data-2-what-is-the-relationship-between-cars-weights-and-their-mileage",
    "title": "Correlation (and Causation)",
    "section": "Example Data (2): What is the relationship between cars’ weights and their mileage?",
    "text": "Example Data (2): What is the relationship between cars’ weights and their mileage?\nThe data mtcars was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973–74 models)."
  },
  {
    "objectID": "0-Information.html#assessment-and-materials",
    "href": "0-Information.html#assessment-and-materials",
    "title": "Module Information",
    "section": "Assessment and Materials",
    "text": "Assessment and Materials\nNotes\n\nNotes will be a combination of links posted on Moodle and notes taken down in class\n\nAssignments\n\nWill be uploaded PDFs.\n\nLab quizzes\n\nWill be Moodle Quiz format with multiple attempts allowed until the end of the semester.\n\nMidterm Exam\n\nWill be a Moodle Quiz MCQ.\n\nMarks\n\n10% – compulsory assignments\n10% – quizzes\n15% – mid-term exam (March 28th, MCQ)\n65% – final exam (date TBC)\n\nRecommended reading\n\nR for Data Science (https://r4ds.had.co.nz)"
  },
  {
    "objectID": "0-Information.html#topics-covered",
    "href": "0-Information.html#topics-covered",
    "title": "Module Information",
    "section": "Topics Covered",
    "text": "Topics Covered\n\nTidyverse Recap\nCorrelation (and Causation)\nObservational Studies\nControlled Experiments\nSurveys\nData Privacy and Anonymisation\nSupervised and Unsupervised Learning\nPredictive Analytics\nImage and Text Analysis"
  },
  {
    "objectID": "0-Information.html#materials-and-assessments",
    "href": "0-Information.html#materials-and-assessments",
    "title": "Module Information",
    "section": "Materials and Assessments",
    "text": "Materials and Assessments\nNotes\n\nNotes will be a combination of links posted on Moodle and notes taken down in class\n\nTutorial Questions\n\nPractice tutorial questions will be posted to Moodle.\n\nAssignments\n\nAssignment questions will be posted to Moodle and answers should be uploaded as PDFs.\n\nLab Quizzes\n\nEach lab will have an associated quiz that will be a Moodle Quiz format with multiple attempts allowed until the end of the semester.\n\nMidterm Exam\n\nThe midterm exam will be a Moodle Quiz MCQ.\n\nMarks\n\n10% – compulsory assignments\n10% – quizzes\n15% – mid-term exam (March 28th, MCQ)\n65% – final exam (date TBC)\n\nRecommended reading\n\nR for Data Science (https://r4ds.had.co.nz)"
  },
  {
    "objectID": "3-MultipleRegression.html",
    "href": "3-MultipleRegression.html",
    "title": "Multiple Regression",
    "section": "",
    "text": "We have seen last semester, in DS151, how to study the relationship between two variables using linear regression.\nWe can create a linear regression model that includes a predictor, such that \\[\\hat{\\mbox{y}}=\\beta_0+\\beta_1\\mbox{x}\\]"
  },
  {
    "objectID": "3-MultipleRegression.html#recap-simple-regression",
    "href": "3-MultipleRegression.html#recap-simple-regression",
    "title": "Multiple Regression",
    "section": "",
    "text": "We have seen last semester, in DS151, how to study the relationship between two variables using linear regression.\nWe can create a linear regression model that includes a predictor, such that \\[\\hat{\\mbox{y}}=\\beta_0+\\beta_1\\mbox{x}\\]"
  },
  {
    "objectID": "3-MultipleRegression.html#multiple-regression-example-1-the-crab-dataset",
    "href": "3-MultipleRegression.html#multiple-regression-example-1-the-crab-dataset",
    "title": "Multiple Regression",
    "section": "Multiple Regression Example 1: The Crab Dataset",
    "text": "Multiple Regression Example 1: The Crab Dataset\nIn many research and applied fields, many different variables are measured at the same time, for various reasons. In many cases, we may actually have too many variables and may end up selecting a subset of them (only the most important) to proceed with the analysis. (NB: there are many ways to define variable importance, and we will look at some of them in depth throughout the Data Science programme).\nLet’s have a look at an example where we have many predictor variables. The crabs dataset from package MASS has 200 observations on 2 qualitative variables (species colour and sex), and 5 morphological measurements (frontal lobe size, rear width, carapace length and width, and body depth) of crabs of the species Leptograspus variegatus.\n\n\n\ncrab_dat &lt;- MASS::crabs\nglimpse(crab_dat)\n\nRows: 200\nColumns: 8\n$ sp    &lt;fct&gt; B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B…\n$ sex   &lt;fct&gt; M, M, M, M, M, M, M, M, M, M, M, M, M, M, M, M, M, M, M, M, M, M…\n$ index &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 1…\n$ FL    &lt;dbl&gt; 8.1, 8.8, 9.2, 9.6, 9.8, 10.8, 11.1, 11.6, 11.8, 11.8, 12.2, 12.…\n$ RW    &lt;dbl&gt; 6.7, 7.7, 7.8, 7.9, 8.0, 9.0, 9.9, 9.1, 9.6, 10.5, 10.8, 11.0, 1…\n$ CL    &lt;dbl&gt; 16.1, 18.1, 19.0, 20.1, 20.3, 23.0, 23.8, 24.5, 24.2, 25.2, 27.3…\n$ CW    &lt;dbl&gt; 19.0, 20.8, 22.4, 23.1, 23.0, 26.5, 27.1, 28.4, 27.8, 29.3, 31.6…\n$ BD    &lt;dbl&gt; 7.0, 7.4, 7.7, 8.2, 8.2, 9.8, 9.8, 10.4, 9.7, 10.3, 10.9, 11.4, …\n\nhead(crab_dat)\n\n  sp sex index   FL  RW   CL   CW  BD\n1  B   M     1  8.1 6.7 16.1 19.0 7.0\n2  B   M     2  8.8 7.7 18.1 20.8 7.4\n3  B   M     3  9.2 7.8 19.0 22.4 7.7\n4  B   M     4  9.6 7.9 20.1 23.1 8.2\n5  B   M     5  9.8 8.0 20.3 23.0 8.2\n6  B   M     6 10.8 9.0 23.0 26.5 9.8\n\nlibrary(GGally)\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\nlibrary(ggplot2)\nggpairs(crab_dat, columns = 4:8, ggplot2::aes(colour=sex)) +theme_bw()\n\n\n\n\n\n\n\n\nImagine we are interested in predicting the carapace length (CL) of this species of crab. We can create a linear regression model that includes multiple predictors, such as \\[\\hat{\\mbox{CL}}=\\beta_0+\\beta_1\\mbox{FL}+\\beta_2\\mbox{RW}+\\beta_3\\mbox{CW}+\\beta_4\\mbox{BD}\\] This model can be fitted in R by executing:\n\nfit1 &lt;- lm(CL ~ FL + RW + CW + BD, data = crab_dat)\nfit1 %&gt;% coef\n\n(Intercept)          FL          RW          CW          BD \n  0.3163364   0.2648933  -0.1778948   0.6402190   0.4714152 \n\n\nWe have that \\[\\hat{\\mbox{CL}}=0.32+0.26\\mbox{FL}-0.18\\mbox{RW}+0.64\\mbox{CW}+0.47\\mbox{BD}\\].\nWe can plot the actual observations versus the predicted ones to see how well we did:\n\ncrab_dat &lt;- crab_dat %&gt;% \n              mutate(CL_pred = predict(fit1))\n\nggplot(data = crab_dat,\n       mapping = aes(x = CL, y = CL_pred, colour = sex)) +\n  theme_bw() +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1) +\n  xlab(\"Observed CL\") + \n  ylab(\"Predicted CL\")\n\n\n\n\n\n\n\n\nHow well would we have done if we only used one predictor variable, say RW?\n\nfit2 &lt;- lm(CL ~ RW, data = crab_dat)\n\ncrab_dat &lt;- crab_dat %&gt;% \n              mutate(CL_pred2 = predict(fit2))\n\nggplot(data = crab_dat,\n       mapping = aes(x = CL, y = CL_pred2, colour = sex)) +\n  theme_bw() +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1) +\n  xlab(\"Observed CL\") + \n  ylab(\"Predicted CL\")\n\n\n\n\n\n\n\n\nNow what about the categorical variables, namely sex and sp (species colour)? We can also include them in our model. Because they are categorical, they will only influence the overall mean response for each category, and hence we don’t estimate a slope for them, i.e. \\[\\hat{\\mbox{CL}}=\\beta_0+\\beta_1\\mbox{FL}+\\beta_2\\mbox{RW}+\\beta_3\\mbox{CW}+\\beta_4\\mbox{BD}+\\beta_5I(\\mbox{sp}=\\mbox{O})+\\beta_6I(\\mbox{sex}=\\mbox{M})\\] (NB: \\(I(\\mbox{sex}=\\mbox{M})\\) is an indicator function, which is equal to 1 if sex is equal to M and zero otherwise. The same type of interpretation can be drawn from \\(I(\\mbox{sp}=\\mbox{O})\\))\n\nfit3 &lt;- lm(CL ~ FL + RW + CW + BD + sp + sex, data = crab_dat)\nfit3 %&gt;% coef\n\n(Intercept)          FL          RW          CW          BD         spO \n-0.19583237  0.21392757 -0.03750446  0.65118521  0.38956671  0.16389052 \n       sexM \n 0.37020979 \n\ncrab_dat &lt;- crab_dat %&gt;% \n              mutate(CL_pred3 = predict(fit3))\n\nggplot(data = crab_dat,\n       mapping = aes(x = CL, y = CL_pred3, colour = sex)) +\n  theme_bw() +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1) +\n  xlab(\"Observed CL\") + \n  ylab(\"Predicted CL\")\n\n\n\n\n\n\n\n\nHow do we interpret the coefficients related to sp and sex? They are the increase (or decrease, if negative) in the overall mean if a crab is orange (O) or male (M).\nOne way of comparing how well our modelling strategies did in terms of predictions is to sum the squared discrepancies (residuals) between predicted and observed values, and see which one is smaller.\n\ndiscrepancy_fit1 &lt;- sum(residuals(fit1)^2)\ndiscrepancy_fit2 &lt;- sum(residuals(fit2)^2)\ndiscrepancy_fit3 &lt;- sum(residuals(fit3)^2)\n\ndiscrepancy_fit1\n\n[1] 27.35058\n\ndiscrepancy_fit2\n\n[1] 2047.417\n\ndiscrepancy_fit3\n\n[1] 25.06863\n\n\nTypically we would split the data into training and test set, use only the training set to fit the model, and then perform this computation on both sets. We will see more details on how to compare the models in terms of their predictive power in the module Statistical Machine Learning. We will also see more details on this in the modules Linear Models I and II, how to properly test hypotheses, how to assess goodness-of-fit, what the important assumptions are and how to properly check them.\n\nLogistic Regression Example 2: The Iris Dataset\nWe explored this dataset initially last semester in DS151.\nIris is a genus of about 300 species of flowering plants, taking its name from the Greek word for a rainbow (which is also the name for the Greek goddess of rainbows, Iris). The flowers are very showy, and we would like to know if it is possible to identify some of the species based on measurements of different parts of the flowers.\nLet’s look at a famous example dataset that gives the measurements in centimeters of the variables:\nfor 50 flowers from each of three species if Iris: Iris setosa, Iris versicolor, and Iris virginica.\nThis dataset is available in base R as iris. Let’s have a look:\n\nlibrary(tidyverse)\nglimpse(iris)\n\nRows: 150\nColumns: 5\n$ Sepal.Length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n$ Sepal.Width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.…\n$ Petal.Length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.…\n$ Petal.Width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.…\n$ Species      &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, s…\n\n\nLet’s work, initially, only with species versicolor and virginica. We create a plot that shows in the \\(x\\) axis the petal length, and in the \\(y\\) axis only the values of 0 and 1, representing whether the observation belongs to class virginica or not (0 = the observation belongs to class versicolor; 1 = it belongs to class virginica). We call this a binary (or dummy) variable.\n\niris2 &lt;- iris %&gt;%\n  filter(Species != \"setosa\") %&gt;%\n  mutate(Species.binary = as.numeric(Species == \"virginica\"))\n  \nggplot(iris2, aes(x = Petal.Length, y = Species.binary)) +\n  geom_point() +\n  theme_bw()\n\n\n\n\n\n\n\n\nIt appears that as the petal length increases, so does the likelihood of belonging to the virginica class. We may interpret the numbers 0 and 1 here as the proportion \\(p\\) of plants that belong to class virginica and present a specific measurement of petal length.\nRemember. We transform the scale of the response in such a way that it will be bounded between 0 and 1, and hence our estimates will be sensical. The transformation we use is called the logit, and is the natural logarithm of the odds of belonging to class virginica: \\[\\displaystyle\\log\\left(\\frac{p}{1-p}\\right)=\\beta_0+\\beta_1*\\mbox{Petal.Length},\\] where \\(p\\) is the proportion of plants that belong to class virginica. This way, the estimated proportions will always be bounded between 0 and 1, and are now suitable to our problem. Let’s see how it looks like for our example:\n\nggplot(iris2, aes(x = Petal.Length, y = Species.binary)) +\n  geom_point() +\n  geom_smooth(method = glm, method.args = list(family = \"binomial\"), se = FALSE) +\n  theme_bw()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nIncluding more predictors\nIt is frequently of interest to use multiple covariates to improve our predictive power. Let’s fit a logistic regression model including all four covariates as predictors in our model: \\[\\displaystyle\\log\\left(\\frac{p}{1-p}\\right)=\\beta_0+\\beta_1*\\mbox{Sepal.Length}+\\beta_2*\\mbox{Sepal.Width}+\\beta_3*\\mbox{Petal.Length}+\\beta_4*\\mbox{Petal.Width}\\]\n\nfull_logistic_reg &lt;- glm(Species.binary ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,\n                         family = binomial, data = iris2)\nfull_logistic_reg %&gt;% coef %&gt;% round(digits = 4)\n\n (Intercept) Sepal.Length  Sepal.Width Petal.Length  Petal.Width \n    -42.6378      -2.4652      -6.6809       9.4294      18.2861 \n\n\nHow well did we do?\n\niris_predict &lt;- iris2 %&gt;% \n                  mutate(p_hat = predict(full_logistic_reg, type = \"response\") %&gt;% round(2),\n                         Species_pred = ifelse(p_hat &gt;= 0.5,\"virginica\",\"versicolor\"))\n\nn_correct_full &lt;- sum(iris_predict$Species_pred == iris_predict$Species)\nn_correct_full\n\n[1] 98\n\n\nOur model now correctly predicts the class of 98 out of 100 observations."
  },
  {
    "objectID": "3-MultipleRegression.html#example-3-the-wine-dataset",
    "href": "3-MultipleRegression.html#example-3-the-wine-dataset",
    "title": "Multiple Regression",
    "section": "Example 3: The Wine Dataset",
    "text": "Example 3: The Wine Dataset"
  },
  {
    "objectID": "3-MultipleRegression.html#logistic-regression-the-wine-dataset",
    "href": "3-MultipleRegression.html#logistic-regression-the-wine-dataset",
    "title": "Multiple Regression",
    "section": "Logistic Regression: The Wine dataset",
    "text": "Logistic Regression: The Wine dataset\nThe wine dataset contains the results of a chemical analysis of wines grown in a specific area of Italy. Three types of wine are represented in the 178 samples, with the results of 13 chemical analyses recorded for each sample. The Type variable has been transformed into a categoric variable.\nThe data contains no missing values and consits of only numeric data, with a three class target variable (Type) for classification.\nLet’s have a glimpse at the dataset:\n\nwine &lt;- read_csv(\"https://www.dropbox.com/s/l5x4ur06gfhpg0h/wine.csv?raw=1\") \n\nRows: 178 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): Type\ndbl (13): Alcohol, Malic, Ash, Alcalinity, Magnesium, Phenols, Flavanoids, N...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(wine)\n\nRows: 178\nColumns: 14\n$ Type                 &lt;chr&gt; \"type1\", \"type1\", \"type1\", \"type1\", \"type1\", \"typ…\n$ Alcohol              &lt;dbl&gt; 14.23, 13.20, 13.16, 14.37, 13.24, 14.20, 14.39, …\n$ Malic                &lt;dbl&gt; 1.71, 1.78, 2.36, 1.95, 2.59, 1.76, 1.87, 2.15, 1…\n$ Ash                  &lt;dbl&gt; 2.43, 2.14, 2.67, 2.50, 2.87, 2.45, 2.45, 2.61, 2…\n$ Alcalinity           &lt;dbl&gt; 15.6, 11.2, 18.6, 16.8, 21.0, 15.2, 14.6, 17.6, 1…\n$ Magnesium            &lt;dbl&gt; 127, 100, 101, 113, 118, 112, 96, 121, 97, 98, 10…\n$ Phenols              &lt;dbl&gt; 2.80, 2.65, 2.80, 3.85, 2.80, 3.27, 2.50, 2.60, 2…\n$ Flavanoids           &lt;dbl&gt; 3.06, 2.76, 3.24, 3.49, 2.69, 3.39, 2.52, 2.51, 2…\n$ Nonflavanoid.phenols &lt;dbl&gt; 0.28, 0.26, 0.30, 0.24, 0.39, 0.34, 0.30, 0.31, 0…\n$ Proanth              &lt;dbl&gt; 2.29, 1.28, 2.81, 2.18, 1.82, 1.97, 1.98, 1.25, 1…\n$ Color                &lt;dbl&gt; 5.64, 4.38, 5.68, 7.80, 4.32, 6.75, 5.25, 5.05, 5…\n$ Hue                  &lt;dbl&gt; 1.04, 1.05, 1.03, 0.86, 1.04, 1.05, 1.02, 1.06, 1…\n$ OD                   &lt;dbl&gt; 3.92, 3.40, 3.17, 3.45, 2.93, 2.85, 3.58, 3.58, 2…\n$ Proline              &lt;dbl&gt; 1065, 1050, 1185, 1480, 735, 1450, 1290, 1295, 10…\n\n\nChange the code below and make different plots with other covariate combinations. What sort of patterns begin to emerge?\n\nggplot(wine, aes(x = Ash, y = Malic, colour = Type)) +\n  geom_point() +\n  theme_bw() +\n  labs(colour = \"Wine Type\")\n\n\n\n\n\n\n\n\nWe will work only with types 1 and 2\n\nwine2 &lt;- wine %&gt;%\n  filter(Type != \"type3\") %&gt;%\n  mutate(Type_binary = as.numeric(Type == \"type1\")) %&gt;% \n  as_tibble\nwine2\n\n# A tibble: 130 × 15\n   Type  Alcohol Malic   Ash Alcalinity Magnesium Phenols Flavanoids\n   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n 1 type1    14.2  1.71  2.43       15.6       127    2.8        3.06\n 2 type1    13.2  1.78  2.14       11.2       100    2.65       2.76\n 3 type1    13.2  2.36  2.67       18.6       101    2.8        3.24\n 4 type1    14.4  1.95  2.5        16.8       113    3.85       3.49\n 5 type1    13.2  2.59  2.87       21         118    2.8        2.69\n 6 type1    14.2  1.76  2.45       15.2       112    3.27       3.39\n 7 type1    14.4  1.87  2.45       14.6        96    2.5        2.52\n 8 type1    14.1  2.15  2.61       17.6       121    2.6        2.51\n 9 type1    14.8  1.64  2.17       14          97    2.8        2.98\n10 type1    13.9  1.35  2.27       16          98    2.98       3.15\n# ℹ 120 more rows\n# ℹ 7 more variables: Nonflavanoid.phenols &lt;dbl&gt;, Proanth &lt;dbl&gt;, Color &lt;dbl&gt;,\n#   Hue &lt;dbl&gt;, OD &lt;dbl&gt;, Proline &lt;dbl&gt;, Type_binary &lt;dbl&gt;\n\n\nChange the code below and fit a logistic regression model using the four predictors you believe are the best to classify the two types of wine. Also play around with different thresholds for the classification rule. Compare with your peers. What predictors yielded the best predictive performance?\n\n# include the predictors below\nlogistic_reg &lt;- glm(Type_binary ~ Malic + Ash + Alcalinity + Magnesium,\n                           family = binomial, data = wine2)\n\n# set the threshold for the classification rule below\nthreshold &lt;- 0.50\n\n# computes the percentage of correct predictions\nwine_predict &lt;- wine2 %&gt;% \n                  mutate(p_hat = predict(logistic_reg, type = \"response\") %&gt;% round(2),\n                         Type_pred = ifelse(p_hat &gt;= threshold, \"type1\",\"type2\")) \n\n\nn_correct &lt;- sum(wine_predict$Type_pred == wine_predict$Type)\nn_total &lt;- nrow(wine2)\npercentage_correct &lt;- n_correct/n_total * 100\npercentage_correct\n\n[1] 86.92308"
  },
  {
    "objectID": "3-MultipleRegression.html#modeling-cars",
    "href": "3-MultipleRegression.html#modeling-cars",
    "title": "Multiple Regression",
    "section": "Modeling cars",
    "text": "Modeling cars\n\n\n\n\n\n\n\n\n\n\nDescribe: What is the relationship between cars’ weights and their mileage?\n\n\n\n\n\n\n\n\n\n\n\nPredict: What is your best guess for a car’s MPG that weighs 3,500 pounds?\n\n\n\nWarning in geom_segment(aes(x = 3.5, xend = 3.5, y = -Inf, yend = 18.5), : All aesthetics have length 1, but the data has 32 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in geom_segment(aes(x = -Inf, xend = 3.5, y = 18.5, yend = 18.5), : All aesthetics have length 1, but the data has 32 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row."
  },
  {
    "objectID": "3-MultipleRegression.html#modelling-cars",
    "href": "3-MultipleRegression.html#modelling-cars",
    "title": "Multiple Regression",
    "section": "Modelling cars",
    "text": "Modelling cars\n\nDescribe: What is the relationship between cars’ weights and their mileage?"
  },
  {
    "objectID": "3-MultipleRegression.html#modelling-cars-1",
    "href": "3-MultipleRegression.html#modelling-cars-1",
    "title": "Multiple Regression",
    "section": "Modelling cars",
    "text": "Modelling cars\n\nPredict: What is your best guess for a car’s MPG that weighs 3,500 pounds?\n\n\n\nWarning in geom_segment(aes(x = 3.5, xend = 3.5, y = -Inf, yend = 18.5), : All aesthetics have length 1, but the data has 32 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in geom_segment(aes(x = -Inf, xend = 3.5, y = 18.5, yend = 18.5), : All aesthetics have length 1, but the data has 32 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row."
  },
  {
    "objectID": "3-MultipleRegression.html#modelling",
    "href": "3-MultipleRegression.html#modelling",
    "title": "Multiple Regression",
    "section": "Modelling",
    "text": "Modelling\n\nUse models to explain the relationship between variables and to make predictions\nFor now we will focus on linear models (but there are many many other types of models too!)"
  },
  {
    "objectID": "3-MultipleRegression.html#modelling-vocabulary",
    "href": "3-MultipleRegression.html#modelling-vocabulary",
    "title": "Multiple Regression",
    "section": "Modelling vocabulary",
    "text": "Modelling vocabulary\n\nPredictor (explanatory variable)\nOutcome (response variable)\nRegression line\n\nSlope\nIntercept\n\n\n\nPredictor (explanatory variable)\n\n\n\n\n\n\n\n\n\n\nmpg\nwt\n\n\n\n\n21\n2.62\n\n\n21\n2.875\n\n\n22.8\n2.32\n\n\n21.4\n3.215\n\n\n18.7\n3.44\n\n\n18.1\n3.46\n\n\n...\n...\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOutcome (response variable)\n\n\n\n\n\n\n\n\n\n\nmpg\nwt\n\n\n\n\n21\n2.62\n\n\n21\n2.875\n\n\n22.8\n2.32\n\n\n21.4\n3.215\n\n\n18.7\n3.44\n\n\n18.1\n3.46\n\n\n...\n...\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRegression line\n\n\n\n\n\n\n\n\n\n\n\nRegression line: slope\n\n\n\n\n\n\n\n\n\n\n\nRegression line: intercept"
  },
  {
    "objectID": "3-MultipleRegression.html#predictor-explanatory-variable",
    "href": "3-MultipleRegression.html#predictor-explanatory-variable",
    "title": "Multiple Regression",
    "section": "Predictor (explanatory variable)",
    "text": "Predictor (explanatory variable)\n\n\n\n\n\n\n\n\n\n\nmpg\nwt\n\n\n\n\n21\n2.62\n\n\n21\n2.875\n\n\n22.8\n2.32\n\n\n21.4\n3.215\n\n\n18.7\n3.44\n\n\n18.1\n3.46\n\n\n...\n..."
  },
  {
    "objectID": "3-MultipleRegression.html#outcome-response-variable",
    "href": "3-MultipleRegression.html#outcome-response-variable",
    "title": "Multiple Regression",
    "section": "Outcome (response variable)",
    "text": "Outcome (response variable)\n\n\n\n\n\n\n\n\n\n\nmpg\nwt\n\n\n\n\n21\n2.62\n\n\n21\n2.875\n\n\n22.8\n2.32\n\n\n21.4\n3.215\n\n\n18.7\n3.44\n\n\n18.1\n3.46\n\n\n...\n..."
  },
  {
    "objectID": "3-MultipleRegression.html#correlation-1",
    "href": "3-MultipleRegression.html#correlation-1",
    "title": "Multiple Regression",
    "section": "Correlation",
    "text": "Correlation\n\nRanges between -1 and 1.\nSame sign as the slope.\n\nWe have seen last semester, in DS151, how to study the relationship between two variables using linear regression. See, e.g. the mammals dataset:\n\nlibrary(tidyverse)\nmammals &lt;- read_csv(\"https://www.dropbox.com/s/rb3zd0nk4430tbv/mammals.csv?raw=1\")\nmammals\n\n# A tibble: 62 × 3\n   name               body brain\n   &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt;\n 1 Arctic fox        3.38   44.5\n 2 Owl monkey        0.48   15.5\n 3 Mountain beaver   1.35    8.1\n 4 Cow             465     423  \n 5 Grey wolf        36.3   120. \n 6 Goat             27.7   115  \n 7 Roe deer         14.8    98.2\n 8 Guinea pig        1.04    5.5\n 9 Verbet            4.19   58  \n10 Chinchilla        0.425   6.4\n# ℹ 52 more rows\n\n\n\n\nLet’s have a look at an exploratory plot, using brain weight as the response variable and body weight as the predictor variable:\n\nggplot(data = mammals,\n       mapping = aes(y = brain, x = body)) +\n  theme_bw() +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nLet’s label the points:\n\nggplot(data = mammals,\n       mapping = aes(y = brain, x = body, label = name)) +\n  theme_bw() +\n  geom_point() +\n  geom_label()\n\n\n\n\n\n\n\n\nIt is difficult to see the clump of points at the bottom left part of the plot. Maybe it is better to take the logarithm of the two variables to visualise them –\n\nggplot(data = mammals,\n       mapping = aes(y = log(brain), x = log(body), label = name)) +\n  theme_bw() +\n  geom_label()\n\n\n\n\n\n\n\n\nWe can overlay a linear regression line to the plot:\n\nggplot(data = mammals,\n       mapping = aes(y = log(brain), x = log(body))) +\n  theme_bw() +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThe equation that predicts brain weight as a function of body weight is\n\nlm(log(brain) ~ log(body), data = mammals) %&gt;%\n  coef\n\n(Intercept)   log(body) \n  2.1347887   0.7516859 \n\n\n\\[\\log(\\mbox{brain weight}) = 2.13+0.75\\times\\log(\\mbox{body weight})\\]\nHowever, it is rare to find a dataset with only two variables. In many research and applied fields, many different variables are measured at the same time, for various reasons. In many cases, we may actually have too many variables and may end up selecting a subset of them (only the most important) to proceed with the analysis. (NB: there are many ways to define variable importance, and we will look at some of them in depth throughout the Data Science programme)."
  },
  {
    "objectID": "3-MultipleRegression.html#regression-line",
    "href": "3-MultipleRegression.html#regression-line",
    "title": "Multiple Regression",
    "section": "Regression line",
    "text": "Regression line"
  },
  {
    "objectID": "3-MultipleRegression.html#regression-line-slope",
    "href": "3-MultipleRegression.html#regression-line-slope",
    "title": "Multiple Regression",
    "section": "Regression line: slope",
    "text": "Regression line: slope"
  },
  {
    "objectID": "3-MultipleRegression.html#regression-line-intercept",
    "href": "3-MultipleRegression.html#regression-line-intercept",
    "title": "Multiple Regression",
    "section": "Regression line: intercept",
    "text": "Regression line: intercept"
  },
  {
    "objectID": "3-MultipleRegression.html#correlation",
    "href": "3-MultipleRegression.html#correlation",
    "title": "Multiple Regression",
    "section": "Correlation",
    "text": "Correlation"
  },
  {
    "objectID": "3-MultipleRegression.html#example-modeling-cars",
    "href": "3-MultipleRegression.html#example-modeling-cars",
    "title": "Multiple Regression",
    "section": "Example: Modeling cars",
    "text": "Example: Modeling cars\n\n\n\n\n\n\n\n\n\n\nDescribe: What is the relationship between cars’ weights and their mileage?\n\n\n\n\n\n\n\n\n\n\n\nPredict: What is your best guess for a car’s MPG that weighs 3,500 pounds?\n\n\n\n\n\n\n\n\n\n\n\nModelling vocabulary\n\nPredictor (explanatory variable)\nOutcome (response variable)\nRegression line\n\nSlope\nIntercept\n\n\n\nPredictor (explanatory variable)\n\n\n\n\n\n\n\n\n\n\nmpg\nwt\n\n\n\n\n21\n2.62\n\n\n21\n2.875\n\n\n22.8\n2.32\n\n\n21.4\n3.215\n\n\n18.7\n3.44\n\n\n18.1\n3.46\n\n\n...\n...\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOutcome (response variable)\n\n\n\n\n\n\n\n\n\n\nmpg\nwt\n\n\n\n\n21\n2.62\n\n\n21\n2.875\n\n\n22.8\n2.32\n\n\n21.4\n3.215\n\n\n18.7\n3.44\n\n\n18.1\n3.46\n\n\n...\n...\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRegression line\n\n\n\n\n\n\n\n\n\n\n\nRegression line: slope\n\n\n\n\n\n\n\n\n\n\n\nRegression line: intercept\n\n\n\n\n\n\n\n\n\n\n\n\nR Code: Modeling cars\n\nmtcars_mod &lt;- lm(mpg ~ wt, data = mtcars)\nmtcars_mod\n\n\nCall:\nlm(formula = mpg ~ wt, data = mtcars)\n\nCoefficients:\n(Intercept)           wt  \n     37.285       -5.344  \n\nggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(\n    x = \"Weight (1,000 lbs)\",\n    y = \"Miles per gallon (MPG)\",\n    title = \"MPG vs. weights of cars\"\n  )"
  },
  {
    "objectID": "3-MultipleRegression.html#r-code",
    "href": "3-MultipleRegression.html#r-code",
    "title": "Multiple Regression",
    "section": "R Code",
    "text": "R Code\n\nmtcars_mod &lt;- lm(mpg ~ wt, data = mtcars)\nmtcars_mod\n\n\nCall:\nlm(formula = mpg ~ wt, data = mtcars)\n\nCoefficients:\n(Intercept)           wt  \n     37.285       -5.344  \n\nggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(\n    x = \"Weight (1,000 lbs)\",\n    y = \"Miles per gallon (MPG)\",\n    title = \"MPG vs. weights of cars\"\n  ) \n\n\n\n\n\n\n\n\nHowever, it is rare to find a dataset with only two variables. In many research and applied fields, many different variables are measured at the same time, for various reasons. In many cases, we may actually have too many variables and may end up selecting a subset of them (only the most important) to proceed with the analysis. (NB: there are many ways to define variable importance, and we will look at some of them in depth throughout the Data Science programme)."
  },
  {
    "objectID": "3-MultipleRegression.html#multiple-regression",
    "href": "3-MultipleRegression.html#multiple-regression",
    "title": "Multiple Regression",
    "section": "Multiple Regression",
    "text": "Multiple Regression\nMultiple linear regression is used to model the relationship between a continuous outcome variable and two or more predictor variables. It extends simple linear regression by incorporating multiple predictors to explain variations in the outcome variable. The model estimates coefficients for each predictor, allowing researchers to assess their individual contributions while controlling for others, making it useful for predicting outcomes and identifying key influencing factors."
  },
  {
    "objectID": "3-MultipleRegression.html#example-1-the-crab-dataset",
    "href": "3-MultipleRegression.html#example-1-the-crab-dataset",
    "title": "Multiple Regression",
    "section": "Example 1: The Crab Dataset",
    "text": "Example 1: The Crab Dataset\nLet’s have a look at an example where we have many predictor variables. The crabs dataset from package MASS has 200 observations on 2 qualitative variables (species colour and sex), and 5 morphological measurements (frontal lobe size, rear width, carapace length and width, and body depth) of crabs of the species Leptograspus variegatus.\n\n\n\nExploratory Analysis\n\ncrab_dat &lt;- MASS::crabs\nglimpse(crab_dat)\n\nRows: 200\nColumns: 8\n$ sp    &lt;fct&gt; B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B…\n$ sex   &lt;fct&gt; M, M, M, M, M, M, M, M, M, M, M, M, M, M, M, M, M, M, M, M, M, M…\n$ index &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 1…\n$ FL    &lt;dbl&gt; 8.1, 8.8, 9.2, 9.6, 9.8, 10.8, 11.1, 11.6, 11.8, 11.8, 12.2, 12.…\n$ RW    &lt;dbl&gt; 6.7, 7.7, 7.8, 7.9, 8.0, 9.0, 9.9, 9.1, 9.6, 10.5, 10.8, 11.0, 1…\n$ CL    &lt;dbl&gt; 16.1, 18.1, 19.0, 20.1, 20.3, 23.0, 23.8, 24.5, 24.2, 25.2, 27.3…\n$ CW    &lt;dbl&gt; 19.0, 20.8, 22.4, 23.1, 23.0, 26.5, 27.1, 28.4, 27.8, 29.3, 31.6…\n$ BD    &lt;dbl&gt; 7.0, 7.4, 7.7, 8.2, 8.2, 9.8, 9.8, 10.4, 9.7, 10.3, 10.9, 11.4, …\n\nlibrary(GGally)\nlibrary(ggplot2)\nggpairs(crab_dat, columns = 4:8, aes(colour=sex)) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nDescribe: What are the relationships between the variables?\n\n\n\nExploratory Modelling\nImagine we are interested in predicting the carapace length (CL) of this species of crab. We can create a linear regression model that includes multiple predictors, such as \\[\\hat{\\mbox{CL}}=\\beta_0+\\beta_1\\mbox{FL}+\\beta_2\\mbox{RW}+\\beta_3\\mbox{CW}+\\beta_4\\mbox{BD}\\]\nThis model can be fit in R by executing:\n\ncrab_mod1 &lt;- lm(CL ~ FL + RW + CW + BD, data = crab_dat)\ncrab_mod1\n\n\nCall:\nlm(formula = CL ~ FL + RW + CW + BD, data = crab_dat)\n\nCoefficients:\n(Intercept)           FL           RW           CW           BD  \n     0.3163       0.2649      -0.1779       0.6402       0.4714  \n\n\nWe have that \\[\\hat{\\mbox{CL}}=0.32+0.26\\mbox{FL}-0.18\\mbox{RW}+0.64\\mbox{CW}+0.47\\mbox{BD}\\].\nInterpretation:\n\nAs FL increases by one unit, holding the other predictors constant, then carapace length will increase by 0.26.\nAs RW increases by one unit, holding the other predictors constant, then carapace length will decrease by 0.18.\nAs CW increases by one unit, holding the other predictors constant, then carapace length will increase by 0.64.\nAs BD increases by one unit, holding the other predictors constant, then carapace length will increase by 0.47.\n\n\nQuestion: How well does the model do at predicting carapace length?\n\n\ncrab_dat &lt;- crab_dat %&gt;% \n              mutate(CL_pred = predict(crab_mod1))\n\nggplot(data = crab_dat,\n       mapping = aes(x = CL, y = CL_pred, colour = sex)) +\n  theme_bw() +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1) +\n  xlab(\"Observed CL\") + \n  ylab(\"Predicted CL\")\n\n\n\n\n\n\n\n\n\nQuestion: How well would we have done if we only used one predictor variable, say RW?\n\n\ncrab_mod2 &lt;- lm(CL ~ RW, data = crab_dat)\ncrab_mod2\n\n\nCall:\nlm(formula = CL ~ RW, data = crab_dat)\n\nCoefficients:\n(Intercept)           RW  \n      0.645        2.470  \n\ncrab_dat &lt;- crab_dat %&gt;% \n              mutate(CL_pred2 = predict(crab_mod2))\n\nggplot(data = crab_dat,\n       mapping = aes(x = CL, y = CL_pred2, colour = sex)) +\n  theme_bw() +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1) +\n  xlab(\"Observed CL\") + \n  ylab(\"Predicted CL\")\n\n\n\n\n\n\n\n\n\nQuestion: What about including the categorical variables, namely sex or sp (species colour)?\n\nWe can include categorical variables in our model, such that\n\\[\\hat{\\mbox{CL}}=\\beta_0+\\beta_1\\mbox{RW}+\\beta_2I(\\mbox{sex}=\\mbox{M})\\] (NB: \\(I(\\mbox{sex}=\\mbox{M})\\) is an indicator function, which is equal to 1 if sex is equal to M and zero otherwise. The same type of interpretation can be drawn from \\(I(\\mbox{sp}=\\mbox{O})\\))\n\ncrab_mod3 &lt;- lm(CL ~ RW + sex, data = crab_dat)\ncrab_mod3\n\n\nCall:\nlm(formula = CL ~ RW + sex, data = crab_dat)\n\nCoefficients:\n(Intercept)           RW         sexM  \n     -6.293        2.792        5.670  \n\ncrab_dat &lt;- crab_dat %&gt;% \n              mutate(CL_pred3 = predict(crab_mod3))\n\nggplot(data = crab_dat,\n       mapping = aes(x = CL, y = CL_pred3, colour = sex)) +\n  theme_bw() +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1) +\n  xlab(\"Observed CL\") + \n  ylab(\"Predicted CL\")\n\n\n\n\n\n\n\n\n\nQuestion: How do we interpret the coefficients related to sex?\n\nFor a male crab the expected carapace length increases by 5.67 compared to a female crab.\n\n\nModel Comparison\nOne way of comparing how well our modelling strategies did in terms of predictions is to sum the squared discrepancies (residuals) between predicted and observed values, and see which one is smaller.\n\ndiscrepancy_mod1 &lt;- sum(residuals(crab_mod1)^2)\ndiscrepancy_mod2 &lt;- sum(residuals(crab_mod2)^2)\ndiscrepancy_mod3 &lt;- sum(residuals(crab_mod3)^2)\n\n\ndiscrepancy_mod1\n\n[1] 27.35058\n\ndiscrepancy_mod2\n\n[1] 2047.417\n\ndiscrepancy_mod3\n\n[1] 576.4921\n\n\nTypically we would split the data into training and test set, use only the training set to fit the model, and then perform this computation on both sets. We will see more details on how to compare the models in terms of their predictive power in the module Statistical Machine Learning. We will also see more details on this in the modules Linear Models I and II, how to properly test hypotheses, how to assess goodness-of-fit, what the important assumptions are and how to properly check them."
  },
  {
    "objectID": "3-MultipleRegression.html#logistic-regression",
    "href": "3-MultipleRegression.html#logistic-regression",
    "title": "Multiple Regression",
    "section": "Logistic Regression",
    "text": "Logistic Regression\nLogistic regression is a generalized regression model where the outcome is a two-level categorical variable. The outcome, takes the value 1 or 0 with probability. Ultimately, it is the probability of the outcome taking the value 1 (i.e., being a “success”) that we model in relation to the predictor variables. For this to work, we transform the expected outcome in such a way that it will be bounded between 0 and 1, and hence our estimates will be sensical. The transformation we use is called the logit, and is the natural logarithm of the odds of success.\n\nModelling binary outcomes\n\n\\(y\\) takes on values 0 (failure) or 1 (success)\n\\(p\\): probability of success\n\\(1-p\\): probability of failure\nWe can’t model \\(y\\) directly, so instead we model \\(p\\)\n\nLinear model\n\\[\n\\hat{p}_i = \\beta_o + \\beta_1 \\times x\n\\]\n\nBut remember that \\(p\\) must be between 0 and 1\nWe need a link function that transforms the linear model to have an appropriate range\n\nLogit link function\nThe logit function takes values between 0 and 1 (probabilities) and maps them to values in the range negative infinity to positive infinity:\n\\[\nlogit(p) = log \\bigg( \\frac{p}{1 - p} \\bigg)\n\\]\nGeneralized linear model\n\nWe model the logit (log-odds) of \\(p\\) :\n\n\\[\nlogit(\\hat{p}) = log \\bigg( \\frac{\\hat{p}}{1 - \\hat{p}} \\bigg) = \\beta_o + \\beta_1 \\times x\n\\]\n\nThen take the inverse to obtain the predicted \\(p\\):\n\n\\[\n\\hat{p} = \\frac{e^{\\beta_o + \\beta_1 \\times x }}{1 + e^{\\beta_o + \\beta_1 \\times x }}\n\\]\nA logistic model visualized"
  },
  {
    "objectID": "3-MultipleRegression.html#example-2-the-iris-dataset",
    "href": "3-MultipleRegression.html#example-2-the-iris-dataset",
    "title": "Multiple Regression",
    "section": "Example 2: The Iris Dataset",
    "text": "Example 2: The Iris Dataset\nYou will have explored the Iris dataset initially last semester in DS151.\nIris is a genus of about 300 species of flowering plants, taking its name from the Greek word for a rainbow (which is also the name for the Greek goddess of rainbows, Iris). The flowers are very showy, and we would like to know if it is possible to identify some of the species based on measurements of different parts of the flowers.\nThe dataset gives the measurements in centimeters of the variables:\n\nsepal length\nsepal width\npetal length\npetal width\n\nfor 50 flowers from each of three species of Iris: Iris setosa, Iris versicolor, and Iris virginica.\nThis dataset is available in base R as iris. Let’s have a look:\n\nlibrary(tidyverse)\nglimpse(iris)\n\nRows: 150\nColumns: 5\n$ Sepal.Length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n$ Sepal.Width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.…\n$ Petal.Length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.…\n$ Petal.Width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.…\n$ Species      &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, s…\n\n\nLet’s work, initially, only with species versicolor and virginica. We create a plot that shows in the \\(x\\) axis the petal length, and in the \\(y\\) axis only the values of 0 and 1, representing whether the observation belongs to class virginica or not (0 = the observation belongs to class versicolor; 1 = it belongs to class virginica). We call this a binary (or dummy) variable.\n\niris2 &lt;- iris %&gt;%\n  filter(Species != \"setosa\") %&gt;%\n  mutate(Species.binary = as.numeric(Species == \"virginica\"))\n  \nggplot(iris2, aes(x = Petal.Length, y = Species.binary)) +\n  geom_point() +\n  theme_bw()\n\n\n\n\n\n\n\n\nWe may interpret the numbers 0 and 1 here as the probability \\(p\\) of belonging to class virginica. It appears that as the petal length increases, so does the likelihood of belonging to the virginica class.\n\nggplot(iris2, aes(x = Petal.Length, y = Species.binary)) +\n  geom_point() +\n  geom_smooth(method = glm, method.args = list(family = \"binomial\"), se = FALSE) +\n  theme_bw()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nIncluding more predictors\nIt is frequently of interest to use multiple covariates to improve our predictive power. Let’s fit a logistic regression model including all four covariates as predictors in our model: \\[\\displaystyle\\log\\left(\\frac{p}{1-p}\\right)=\\beta_0+\\beta_1*\\mbox{Sepal.Length}+\\beta_2*\\mbox{Sepal.Width}+\\beta_3*\\mbox{Petal.Length}+\\beta_4*\\mbox{Petal.Width}\\]\n\nfull_logistic_reg &lt;- glm(Species.binary ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,\n                         family = binomial, data = iris2)\nfull_logistic_reg %&gt;% coef %&gt;% round(digits = 4)\n\n (Intercept) Sepal.Length  Sepal.Width Petal.Length  Petal.Width \n    -42.6378      -2.4652      -6.6809       9.4294      18.2861 \n\n\nHow well did we do?\n\niris_predict &lt;- iris2 %&gt;% \n                  mutate(p_hat = predict(full_logistic_reg, type = \"response\") %&gt;% round(2),\n                         Species_pred = ifelse(p_hat &gt;= 0.5,\"virginica\",\"versicolor\"))\n\nn_correct_full &lt;- sum(iris_predict$Species_pred == iris_predict$Species)\nn_correct_full\n\n[1] 98\n\n\nOur model now correctly predicts the class of 98 out of 100 observations."
  },
  {
    "objectID": "3-MultipleRegression.html#example-the-iris-dataset",
    "href": "3-MultipleRegression.html#example-the-iris-dataset",
    "title": "Multiple Regression",
    "section": "Example: The Iris Dataset",
    "text": "Example: The Iris Dataset\nYou will have explored the Iris dataset initially last semester in DS151.\nIris is a genus of about 300 species of flowering plants, taking its name from the Greek word for a rainbow (which is also the name for the Greek goddess of rainbows, Iris). The flowers are very showy, and we would like to know if it is possible to identify some of the species based on measurements of different parts of the flowers.\nThe dataset gives the measurements in centimeters of the variables:\n\nsepal length\nsepal width\npetal length\npetal width\n\nfor 50 flowers from each of three species of Iris: Iris setosa, Iris versicolor, and Iris virginica.\nThis dataset is available in base R as iris. Let’s have a look:\n\nlibrary(tidyverse)\nglimpse(iris)\n\nRows: 150\nColumns: 5\n$ Sepal.Length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n$ Sepal.Width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.…\n$ Petal.Length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.…\n$ Petal.Width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.…\n$ Species      &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, s…\n\n\n\nExploratory Analysis\nLet’s work, initially, only with species versicolor and virginica. We create a plot that shows in the \\(x\\) axis the petal length, and in the \\(y\\) axis only the values of 0 and 1, representing whether the observation belongs to class virginica or not (0 = the observation belongs to class versicolor; 1 = it belongs to class virginica). We call this a binary (or dummy) variable.\n\niris2 &lt;- iris %&gt;%\n  filter(Species != \"setosa\") %&gt;%\n  mutate(Species.binary = as.numeric(Species == \"virginica\"))\n  \nggplot(iris2, aes(x = Petal.Length, y = Species.binary)) +\n  geom_point() +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nExploratory Modelling\nA simple logistic regression model can be fit, such that \\[\\displaystyle\\log\\left(\\frac{p}{1-p}\\right)=\\beta_0+\\beta_1*\\mbox{Petal.Length}\\]\nDo this in R by executing:\n\niris_mod1 &lt;- glm(Species.binary ~ Petal.Length,\n                 family = binomial,\n                 data = iris2)\niris_mod1 %&gt;% coef() %&gt;% round(digits = 4)\n\n (Intercept) Petal.Length \n    -43.7809       9.0020 \n\n\n\nggplot(iris2, aes(x = Petal.Length, y = Species.binary)) +\n  geom_point() +\n  geom_smooth(method = glm, method.args = list(family = \"binomial\"), se = FALSE) +\n  ylab(\"p\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nWe may interpret the y-axis numbers here as the probability \\(p\\) of belonging to class virginica. It appears that as the petal length increases, so does the likelihood of belonging to the virginica class."
  },
  {
    "objectID": "3-MultipleRegression.html#exploratory-analysis-1",
    "href": "3-MultipleRegression.html#exploratory-analysis-1",
    "title": "Multiple Regression",
    "section": "Exploratory Analysis",
    "text": "Exploratory Analysis\nLet’s work, initially, only with species versicolor and virginica. We create a plot that shows in the \\(x\\) axis the petal length, and in the \\(y\\) axis only the values of 0 and 1, representing whether the observation belongs to class virginica or not (0 = the observation belongs to class versicolor; 1 = it belongs to class virginica). We call this a binary (or dummy) variable.\n\niris2 &lt;- iris %&gt;%\n  filter(Species != \"setosa\") %&gt;%\n  mutate(Species.binary = as.numeric(Species == \"virginica\"))\n  \nggplot(iris2, aes(x = Petal.Length, y = Species.binary)) +\n  geom_point() +\n  theme_bw()"
  },
  {
    "objectID": "3-MultipleRegression.html#exploratory-modelling-1",
    "href": "3-MultipleRegression.html#exploratory-modelling-1",
    "title": "Multiple Regression",
    "section": "Exploratory Modelling",
    "text": "Exploratory Modelling\nA simple logistic regression model can be fit, such that \\[\\displaystyle\\log\\left(\\frac{p}{1-p}\\right)=\\beta_0+\\beta_1*\\mbox{Petal.Length}\\]\nDo this in R by executing:\n\niris_mod1 &lt;- glm(Species.binary ~ Petal.Length,\n                 family = binomial,\n                 data = iris2)\niris_mod1 %&gt;% coef() %&gt;% round(digits = 4)\n\n (Intercept) Petal.Length \n    -43.7809       9.0020 \n\n\n\nggplot(iris2, aes(x = Petal.Length, y = Species.binary)) +\n  geom_point() +\n  geom_smooth(method = glm, method.args = list(family = \"binomial\"), se = FALSE) +\n  ylab(\"p\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nWe may interpret the y-axis numbers here as the probability \\(p\\) of belonging to class virginica. It appears that as the petal length increases, so does the likelihood of belonging to the virginica class.\n\nIncluding more predictors\nIt is frequently of interest to use multiple covariates to improve our predictive power. Let’s fit a logistic regression model including all four covariates as predictors in our model: \\[\\displaystyle\\log\\left(\\frac{p}{1-p}\\right)=\\beta_0+\\beta_1*\\mbox{Sepal.Length}+\\beta_2*\\mbox{Sepal.Width}+\\beta_3*\\mbox{Petal.Length}+\\beta_4*\\mbox{Petal.Width}\\]\n\niris_mod2 &lt;- glm(Species.binary ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,\n                 family = binomial, \n                 data = iris2)\niris_mod2 %&gt;% coef %&gt;% round(digits = 4)\n\n (Intercept) Sepal.Length  Sepal.Width Petal.Length  Petal.Width \n    -42.6378      -2.4652      -6.6809       9.4294      18.2861 \n\n\n\n\nClassification\n\nQuestion: How well did we do at classifying the Iris species?\n\n\niris_predict &lt;- iris2 %&gt;% \n                  mutate(p_hat = predict(iris_mod2, type = \"response\") %&gt;% round(2),\n                         Species_pred = ifelse(p_hat &gt;= 0.5,\"virginica\",\"versicolor\"))\n\nn_correct_full &lt;- sum(iris_predict$Species_pred == iris_predict$Species)\nn_correct_full\n\n[1] 98\n\n\nOur model correctly predicts the species class of 98 out of 100 observations."
  },
  {
    "objectID": "3-MultipleRegression.html#example-the-wine-dataset",
    "href": "3-MultipleRegression.html#example-the-wine-dataset",
    "title": "Multiple Regression",
    "section": "Example: The Wine Dataset",
    "text": "Example: The Wine Dataset\nThe wine dataset contains the results of a chemical analysis of wines grown in a specific area of Italy. Three types of wine are represented in the 178 samples, with the results of 13 chemical analyses recorded for each sample. The Type variable has been transformed into a categoric variable.\nThe data contains no missing values and consits of only numeric data, with a three class target variable (Type) for classification.\nLet’s have a glimpse at the dataset:\n\nwine &lt;- read_csv(\"https://www.dropbox.com/s/l5x4ur06gfhpg0h/wine.csv?raw=1\") \n\nRows: 178 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): Type\ndbl (13): Alcohol, Malic, Ash, Alcalinity, Magnesium, Phenols, Flavanoids, N...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(wine)\n\nRows: 178\nColumns: 14\n$ Type                 &lt;chr&gt; \"type1\", \"type1\", \"type1\", \"type1\", \"type1\", \"typ…\n$ Alcohol              &lt;dbl&gt; 14.23, 13.20, 13.16, 14.37, 13.24, 14.20, 14.39, …\n$ Malic                &lt;dbl&gt; 1.71, 1.78, 2.36, 1.95, 2.59, 1.76, 1.87, 2.15, 1…\n$ Ash                  &lt;dbl&gt; 2.43, 2.14, 2.67, 2.50, 2.87, 2.45, 2.45, 2.61, 2…\n$ Alcalinity           &lt;dbl&gt; 15.6, 11.2, 18.6, 16.8, 21.0, 15.2, 14.6, 17.6, 1…\n$ Magnesium            &lt;dbl&gt; 127, 100, 101, 113, 118, 112, 96, 121, 97, 98, 10…\n$ Phenols              &lt;dbl&gt; 2.80, 2.65, 2.80, 3.85, 2.80, 3.27, 2.50, 2.60, 2…\n$ Flavanoids           &lt;dbl&gt; 3.06, 2.76, 3.24, 3.49, 2.69, 3.39, 2.52, 2.51, 2…\n$ Nonflavanoid.phenols &lt;dbl&gt; 0.28, 0.26, 0.30, 0.24, 0.39, 0.34, 0.30, 0.31, 0…\n$ Proanth              &lt;dbl&gt; 2.29, 1.28, 2.81, 2.18, 1.82, 1.97, 1.98, 1.25, 1…\n$ Color                &lt;dbl&gt; 5.64, 4.38, 5.68, 7.80, 4.32, 6.75, 5.25, 5.05, 5…\n$ Hue                  &lt;dbl&gt; 1.04, 1.05, 1.03, 0.86, 1.04, 1.05, 1.02, 1.06, 1…\n$ OD                   &lt;dbl&gt; 3.92, 3.40, 3.17, 3.45, 2.93, 2.85, 3.58, 3.58, 2…\n$ Proline              &lt;dbl&gt; 1065, 1050, 1185, 1480, 735, 1450, 1290, 1295, 10…\n\n\nChange the code below and make different plots with other covariate combinations. What sort of patterns begin to emerge?\n\nggplot(wine, aes(x = Ash, y = Malic, colour = Type)) +\n  geom_point() +\n  theme_bw() +\n  labs(colour = \"Wine Type\")\n\n\n\n\n\n\n\n\nWe will work only with types 1 and 2\n\nwine2 &lt;- wine %&gt;%\n  filter(Type != \"type3\") %&gt;%\n  mutate(Type_binary = as.numeric(Type == \"type1\")) %&gt;% \n  as_tibble\nwine2\n\n# A tibble: 130 × 15\n   Type  Alcohol Malic   Ash Alcalinity Magnesium Phenols Flavanoids\n   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n 1 type1    14.2  1.71  2.43       15.6       127    2.8        3.06\n 2 type1    13.2  1.78  2.14       11.2       100    2.65       2.76\n 3 type1    13.2  2.36  2.67       18.6       101    2.8        3.24\n 4 type1    14.4  1.95  2.5        16.8       113    3.85       3.49\n 5 type1    13.2  2.59  2.87       21         118    2.8        2.69\n 6 type1    14.2  1.76  2.45       15.2       112    3.27       3.39\n 7 type1    14.4  1.87  2.45       14.6        96    2.5        2.52\n 8 type1    14.1  2.15  2.61       17.6       121    2.6        2.51\n 9 type1    14.8  1.64  2.17       14          97    2.8        2.98\n10 type1    13.9  1.35  2.27       16          98    2.98       3.15\n# ℹ 120 more rows\n# ℹ 7 more variables: Nonflavanoid.phenols &lt;dbl&gt;, Proanth &lt;dbl&gt;, Color &lt;dbl&gt;,\n#   Hue &lt;dbl&gt;, OD &lt;dbl&gt;, Proline &lt;dbl&gt;, Type_binary &lt;dbl&gt;\n\n\nChange the code below and fit a logistic regression model using the four predictors you believe are the best to classify the two types of wine. Also play around with different thresholds for the classification rule. Compare with your peers. What predictors yielded the best predictive performance?\n\n# include the predictors below\nlogistic_reg &lt;- glm(Type_binary ~ Malic + Ash + Alcalinity + Magnesium,\n                           family = binomial, data = wine2)\n\n# set the threshold for the classification rule below\nthreshold &lt;- 0.50\n\n# computes the percentage of correct predictions\nwine_predict &lt;- wine2 %&gt;% \n                  mutate(p_hat = predict(logistic_reg, type = \"response\") %&gt;% round(2),\n                         Type_pred = ifelse(p_hat &gt;= threshold, \"type1\",\"type2\")) \n\n\nn_correct &lt;- sum(wine_predict$Type_pred == wine_predict$Type)\nn_total &lt;- nrow(wine2)\npercentage_correct &lt;- n_correct/n_total * 100\npercentage_correct\n\n[1] 86.92308"
  },
  {
    "objectID": "3-MultipleRegression.html#example-the-crab-dataset",
    "href": "3-MultipleRegression.html#example-the-crab-dataset",
    "title": "Multiple Regression",
    "section": "Example: The Crab Dataset",
    "text": "Example: The Crab Dataset\nLet’s have a look at an example where we have many predictor variables. The crabs dataset from package MASS has 200 observations on 2 qualitative variables (species colour and sex), and 5 morphological measurements (frontal lobe size, rear width, carapace length and width, and body depth) of crabs of the species Leptograspus variegatus.\n\n\n\nExploratory Analysis\n\ncrab_dat &lt;- MASS::crabs\nglimpse(crab_dat)\n\nRows: 200\nColumns: 8\n$ sp    &lt;fct&gt; B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B…\n$ sex   &lt;fct&gt; M, M, M, M, M, M, M, M, M, M, M, M, M, M, M, M, M, M, M, M, M, M…\n$ index &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 1…\n$ FL    &lt;dbl&gt; 8.1, 8.8, 9.2, 9.6, 9.8, 10.8, 11.1, 11.6, 11.8, 11.8, 12.2, 12.…\n$ RW    &lt;dbl&gt; 6.7, 7.7, 7.8, 7.9, 8.0, 9.0, 9.9, 9.1, 9.6, 10.5, 10.8, 11.0, 1…\n$ CL    &lt;dbl&gt; 16.1, 18.1, 19.0, 20.1, 20.3, 23.0, 23.8, 24.5, 24.2, 25.2, 27.3…\n$ CW    &lt;dbl&gt; 19.0, 20.8, 22.4, 23.1, 23.0, 26.5, 27.1, 28.4, 27.8, 29.3, 31.6…\n$ BD    &lt;dbl&gt; 7.0, 7.4, 7.7, 8.2, 8.2, 9.8, 9.8, 10.4, 9.7, 10.3, 10.9, 11.4, …\n\nlibrary(GGally)\nlibrary(ggplot2)\nggpairs(crab_dat, columns = 4:8, aes(colour=sex)) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nDescribe: What are the relationships between the variables?\n\n\n\nExploratory Modelling\nImagine we are interested in predicting the carapace length (CL) of this species of crab. We can create a linear regression model that includes multiple predictors, such as \\[\\hat{\\mbox{CL}}=\\beta_0+\\beta_1\\mbox{FL}+\\beta_2\\mbox{RW}+\\beta_3\\mbox{CW}+\\beta_4\\mbox{BD}\\]\nThis model can be fit in R by executing:\n\ncrab_mod1 &lt;- lm(CL ~ FL + RW + CW + BD, data = crab_dat)\ncrab_mod1\n\n\nCall:\nlm(formula = CL ~ FL + RW + CW + BD, data = crab_dat)\n\nCoefficients:\n(Intercept)           FL           RW           CW           BD  \n     0.3163       0.2649      -0.1779       0.6402       0.4714  \n\n\nWe have that \\[\\hat{\\mbox{CL}}=0.32+0.26\\mbox{FL}-0.18\\mbox{RW}+0.64\\mbox{CW}+0.47\\mbox{BD}\\].\nInterpretation:\n\nAs FL increases by one unit, holding the other predictors constant, then carapace length will increase by 0.26.\nAs RW increases by one unit, holding the other predictors constant, then carapace length will decrease by 0.18.\nAs CW increases by one unit, holding the other predictors constant, then carapace length will increase by 0.64.\nAs BD increases by one unit, holding the other predictors constant, then carapace length will increase by 0.47.\n\n\nQuestion: How well does the model do at predicting carapace length?\n\n\ncrab_dat &lt;- crab_dat %&gt;% \n              mutate(CL_pred = predict(crab_mod1))\n\nggplot(data = crab_dat,\n       mapping = aes(x = CL, y = CL_pred)) +\n  theme_bw() +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1) +\n  xlab(\"Observed CL\") + \n  ylab(\"Predicted CL\")\n\n\n\n\n\n\n\n\n\nQuestion: How well would we have done if we only used one predictor variable, say RW?\n\n\ncrab_mod2 &lt;- lm(CL ~ RW, data = crab_dat)\ncrab_mod2\n\n\nCall:\nlm(formula = CL ~ RW, data = crab_dat)\n\nCoefficients:\n(Intercept)           RW  \n      0.645        2.470  \n\ncrab_dat &lt;- crab_dat %&gt;% \n              mutate(CL_pred2 = predict(crab_mod2))\n\n\nggplot(data = crab_dat,\n      aes(x = RW, y = CL)) +\n  theme_bw() +\n  geom_point() +\n  geom_line(aes(x = RW, y = CL_pred2)) \n\n\n\n\n\n\n\n\n\nQuestion: How well does the model do at predicting carapace length?\n\n\nggplot(data = crab_dat,\n       aes(x = CL, y = CL_pred2)) +\n  theme_bw() +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1) +\n  xlab(\"Observed CL\") + \n  ylab(\"Predicted CL\")\n\n\n\n\n\n\n\n\n\nQuestion: What about including the categorical variables, namely sex or sp (species colour)?\n\nWe can include categorical variables in our model, such that\n\\[\\hat{\\mbox{CL}}=\\beta_0+\\beta_1\\mbox{RW}+\\beta_2I(\\mbox{sex}=\\mbox{M})\\] (NB: \\(I(\\mbox{sex}=\\mbox{M})\\) is an indicator function, which is equal to 1 if sex is equal to M and zero otherwise. The same type of interpretation can be drawn from \\(I(\\mbox{sp}=\\mbox{O})\\))\n\ncrab_mod3 &lt;- lm(CL ~ RW + sex, data = crab_dat)\ncrab_mod3\n\n\nCall:\nlm(formula = CL ~ RW + sex, data = crab_dat)\n\nCoefficients:\n(Intercept)           RW         sexM  \n     -6.293        2.792        5.670  \n\n\n\nQuestion: How do we interpret the coefficients related to sex?\n\nFor a male crab the expected carapace length increases by 5.67 compared to a female crab.\n\ncrab_dat &lt;- crab_dat %&gt;% \n              mutate(CL_pred3 = predict(crab_mod3))\n\n\nggplot(data = crab_dat,\n      aes(x = RW, y = CL, colour = sex)) +\n  theme_bw() +\n  geom_point() +\n  geom_line(aes(x = RW, y = CL_pred3, colour = sex)) \n\n\n\n\n\n\n\n\n\nQuestion: How well does the model do at predicting carapace length?\n\n\nggplot(data = crab_dat,\n       aes(x = CL, y = CL_pred3, colour = sex)) +\n  theme_bw() +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1) +\n  xlab(\"Observed CL\") + \n  ylab(\"Predicted CL\")\n\n\n\n\n\n\n\n\n\n\nModel Comparison\nOne way of comparing how well our modelling strategies did in terms of predictions is to sum the squared discrepancies (residuals) between predicted and observed values, and see which one is smaller.\n\ndiscrepancy_mod1 &lt;- sum(residuals(crab_mod1)^2)\ndiscrepancy_mod2 &lt;- sum(residuals(crab_mod2)^2)\ndiscrepancy_mod3 &lt;- sum(residuals(crab_mod3)^2)\n\n\ndiscrepancy_mod1\n\n[1] 27.35058\n\ndiscrepancy_mod2\n\n[1] 2047.417\n\ndiscrepancy_mod3\n\n[1] 576.4921\n\n\nTypically we would split the data into training and test set, use only the training set to fit the model, and then perform this computation on both sets. We will see more details on how to compare the models in terms of their predictive power in the module Statistical Machine Learning. We will also see more details on this in the modules Linear Models I and II, how to properly test hypotheses, how to assess goodness-of-fit, what the important assumptions are and how to properly check them."
  },
  {
    "objectID": "ObservationalStudies.html",
    "href": "ObservationalStudies.html",
    "title": "Observational Studies",
    "section": "",
    "text": "Observational Study: A study which observes individuals and measures variables, but does not attempt to influence the responses.\n\nAn observational study on individuals from a random sample allows one to generalize conclusions about the sample to the population.\nAn observational study cannot show cause-and-effect relationships because there is the possibility that the response is affected by some variable(s) other than the ones being measured. That is, confounding variables may be present. “It ain’t what you don’t know that gets you into trouble. It’s what you know for sure that just ain’t so.” - Mark Twain\nIn prospective observational studies, investigators choose a sample and collect new data generated from that sample. That is, the investigators “look forward in time.”\nIn retrospective observational studies, investigators “look backwards in time” and use data that have already been collected. Retrospective studies are often criticized for having more confounding and bias compared to prospective studies."
  },
  {
    "objectID": "ObservationalStudies.html#scientific-studies",
    "href": "ObservationalStudies.html#scientific-studies",
    "title": "Observational Studies",
    "section": "",
    "text": "Observational\n\nCollect data in a way that does not directly interfere with how the data arise, i.e. merely “observe”;\nBased on an observational study, we can only establish an association, in other words correlation, between the explanatory and response variables;\nWith an observational study you are just observing the data and collecting it after or as it occurs.\n\nExperimental\n\nRandomly assign subjects to treatments\nEstablish causal connections"
  },
  {
    "objectID": "ObservationalStudies.html#studies-and-conclusions",
    "href": "ObservationalStudies.html#studies-and-conclusions",
    "title": "Observational Studies",
    "section": "Studies and Conclusions",
    "text": "Studies and Conclusions"
  },
  {
    "objectID": "ObservationalStudies.html#why-use-observational-studies",
    "href": "ObservationalStudies.html#why-use-observational-studies",
    "title": "Observational Studies",
    "section": "Why use observational studies?",
    "text": "Why use observational studies?\nReasons why we must sometimes use an observational study instead of an experiment …\n\nIt is unethical or impossible to assign people to receive a specific treatment.\n\nFor example, if you want to know the impact of smoking on cancer you cannot design a study and assign some people to be smokers and other to be non-smokers. That is not ethical.\n\nCertain exposure variables are inherent traits and cannot be randomly assigned."
  },
  {
    "objectID": "ObservationalStudies.html#observational-studies",
    "href": "ObservationalStudies.html#observational-studies",
    "title": "Observational Studies",
    "section": "Observational studies",
    "text": "Observational studies\n\nObservational studies are very useful when it is not possible to design a study\nObervational studies often have large sample sizes\nThey are cheaper than designing a study (for example, clinical trials in medicine are very expensive)\nYou have to get to know the data a lot better with observational studies. You haven’t set up to study or controlled for influences other than the thing you are studying."
  },
  {
    "objectID": "ObservationalStudies.html#retrospective-vs-prospective-studies",
    "href": "ObservationalStudies.html#retrospective-vs-prospective-studies",
    "title": "Observational Studies",
    "section": "Retrospective Vs Prospective Studies",
    "text": "Retrospective Vs Prospective Studies\nIf an observational study uses data from the past, it is called retrospective study, whereas if data are collected throughout the study, it is called prospective;"
  },
  {
    "objectID": "ObservationalStudies.html#example-does-working-out-increase-energy-levels",
    "href": "ObservationalStudies.html#example-does-working-out-increase-energy-levels",
    "title": "Observational Studies",
    "section": "Example: Does working out increase energy levels?",
    "text": "Example: Does working out increase energy levels?\nWe want to evaluate if regularly working out has any impact on energy levels.\n\nIn an observational study, we sample two types of people from the population, those who choose to work out regularly and those who don’t.\nWe ask the people in each group to rate their energy levels from 1-10.\nThen, we find the average “energy level” for the two groups of people and compare.\n\n\nCan we conclude from this that working out is the cause of increased energy levels?\n\nThere may be other variables that we didn’t control for in this study that contribute to the observed difference.\nFor example, people who have young children might have less time to work out and also have lower energy levels.\nThis is known as confounding.\nThis study allows us to make correlation statements. But, we cannot make a causal statement attributing increased energy levels to working out!"
  },
  {
    "objectID": "ObservationalStudies.html#example-does-working-out-increase-energy-levels-1",
    "href": "ObservationalStudies.html#example-does-working-out-increase-energy-levels-1",
    "title": "Observational Studies",
    "section": "Example: Does working out increase energy levels?",
    "text": "Example: Does working out increase energy levels?\n\nCan we conclude from this that working out is the cause of increased energy levels?"
  },
  {
    "objectID": "ObservationalStudies.html#example-does-working-out-increase-energy-levels-2",
    "href": "ObservationalStudies.html#example-does-working-out-increase-energy-levels-2",
    "title": "Observational Studies",
    "section": "Example: Does working out increase energy levels?",
    "text": "Example: Does working out increase energy levels?\n\nThere may be other variables that we didn’t control for in this study that contribute to the observed difference.\nFor example, people who have young children might have less time to work out and also have lower energy levels.\nThis is known as confounding.\nThis study allows us to make correlation statements. But, we cannot make a causal statement attributing increased energy levels to working out!"
  },
  {
    "objectID": "ObservationalStudies.html#confounding-variables",
    "href": "ObservationalStudies.html#confounding-variables",
    "title": "Observational Studies",
    "section": "Confounding variables",
    "text": "Confounding variables\nConfounding variables: Extraneous variables that affect both the exposure (e.g., working out) and the outcome variables (e.g., increased energy), and that make it seem like there is a relationship between them are called confounding variables."
  },
  {
    "objectID": "ObservationalStudies.html#example",
    "href": "ObservationalStudies.html#example",
    "title": "Observational Studies",
    "section": "Example",
    "text": "Example\nMany years ago, investigators reported an association between coffee drinking and pancreatic cancer in an observational study (MacMahon B, Yen S, Trichopoulos D, Warren K, Nardi G. Coffee and cancer of the pancreas. N Eng J Med 1981; 304: 630-3).\n\nIf we take coffee as our exposure of interest and correlate it with an increased development of pancreatic cancer there is the potential, as was the case with these investigators, to be misled if there is a third causal factor, such as cigarette smoking, that was more common among those who reported drinking coffee.\n\nOnce the confounding variable, smoking is taken into account the correlation between coffee and pancreatic cancer disappears."
  },
  {
    "objectID": "ObservationalStudies.html#example-1",
    "href": "ObservationalStudies.html#example-1",
    "title": "Observational Studies",
    "section": "Example",
    "text": "Example\nIf we take coffee as our exposure of interest and correlate it with an increased development of pancreatic cancer there is the potential, as was the case with these investigators, to be misled if there is a third causal factor, such as cigarette smoking, that was more common among those who reported drinking coffee.\n\nOnce the confounding variable, smoking is taken into account the correlation between coffee and pancreatic cancer disappears."
  },
  {
    "objectID": "ObservationalStudies.html#reducing-confounding-matching",
    "href": "ObservationalStudies.html#reducing-confounding-matching",
    "title": "Observational Studies",
    "section": "Reducing confounding: Matching",
    "text": "Reducing confounding: Matching\nMatching is a technique that involves selecting study participants with similar characteristics outside the outcome or exposure variables.\n\nRather than using random assignment to equalize the experimental groups, the experimenters do it by matching observable characteristics.\nFor every participant in the exposed group, the researchers find a participant with comparable traits to include in the control group.\nMatching subjects facilitates valid comparisons between those groups.\nThe researchers use subject-area knowledge to identify characteristics that are critical to match."
  },
  {
    "objectID": "ObservationalStudies.html#reducing-confounding-multiple-regression",
    "href": "ObservationalStudies.html#reducing-confounding-multiple-regression",
    "title": "Observational Studies",
    "section": "Reducing confounding: Multiple Regression",
    "text": "Reducing confounding: Multiple Regression\nMultiple regression models specify the way in which different characteristics/variables (exposure and confounders) affects the outcome, thereby isolating the effect of each variable.\nchance of cancer = a x (coffee) + b x (smoking) + c x (gender) + d x (age)\n\nthis allows us to make a statement about what would happen if one variable (i.e., the exposure) were to change while all the others (i.e., the confounders) remained the same.\nObtaining isolated exposure effects conditional on the other variables remaining constant is said to adjust for (or control for) the effect of these confounders"
  },
  {
    "objectID": "ObservationalStudies.html#conditional-probability",
    "href": "ObservationalStudies.html#conditional-probability",
    "title": "Observational Studies",
    "section": "Conditional Probability",
    "text": "Conditional Probability\nYou and your friend are trying to find the perfect restaurant for dinner. You can’t decide so you want to instead rely on some observational data (i.e., restaurant reviews).\nYou find two worthy restaurants, Carla’s and Sophia’s each with 400 reviews and an indicator of whether the restaurant is recommended or not recommended.\nYou find that\n\nrecommended for Sophia’s = 250/400\nrecommended for Carla’s = 216/400\n\nSo what we have is a conditional probability:\np(recommended|Sophia’s) = 62.5%\np(recommended|Carla’s) = 54%"
  },
  {
    "objectID": "ObservationalStudies.html#conditional-probability-1",
    "href": "ObservationalStudies.html#conditional-probability-1",
    "title": "Observational Studies",
    "section": "Conditional Probability",
    "text": "Conditional Probability\nWhat if we consider age as a factor here?\n\nrecommended for 18-35 yr old diners at Sophia’s = 50/150\nrecommended for 35+ diners at Sophia’s = 200/250\nrecommended for 18-35 yr old diners at Carla’s = 180/360\nrecommended for 35+ diners at Carla’s = 36/40\n\nSo what we have is:\np(recommended|Sophia’s, younger) = 30%\np(recommended|Sophia’s, older) = 80%\np(recommended|Carla’s, younger) = 50%\np(recommended|Carla’s, older) = 90%"
  },
  {
    "objectID": "ObservationalStudies.html#whats-going-on",
    "href": "ObservationalStudies.html#whats-going-on",
    "title": "Observational Studies",
    "section": "What’s going on?",
    "text": "What’s going on?\nYou have unknowingly entered the world of Simpson’s Paradox, where a restaurant can be both better and worse than its competitor, exercise can lower and increase the risk of disease, and the same dataset can be used to prove two opposing arguments. Instead of going out to dinner, perhaps you and your friend should spend the evening discussing this fascinating statistical phenomenon.\nSimpson’s Paradox occurs when trends that appear when a dataset is separated into groups reverse when the data are aggregated."
  },
  {
    "objectID": "ObservationalStudies.html#simpsons-paradox-correlation-reversal",
    "href": "ObservationalStudies.html#simpsons-paradox-correlation-reversal",
    "title": "Observational Studies",
    "section": "Simpsons’ Paradox: Correlation Reversal",
    "text": "Simpsons’ Paradox: Correlation Reversal\nSay we have data on the number of hours of exercise per week versus the risk of developing a disease for two sets of patients, those below the age of 50 and those over the age of 50. Here are individual plots showing the relationship between exercise and risk of disease."
  },
  {
    "objectID": "ObservationalStudies.html#example-continued",
    "href": "ObservationalStudies.html#example-continued",
    "title": "Observational Studies",
    "section": "Example Continued",
    "text": "Example Continued\nWe clearly saw a negative correlation, indicating that increased levels of exercise per week are correlated with a lower risk of developing the disease for both groups. Now, let’s combine the data together on a single plot:"
  },
  {
    "objectID": "ObservationalStudies.html#resolving-the-paradox",
    "href": "ObservationalStudies.html#resolving-the-paradox",
    "title": "Observational Studies",
    "section": "Resolving the Paradox",
    "text": "Resolving the Paradox\nTo avoid Simpson’s Paradox leading us to two opposite conclusions, we need to choose to segregate the data in groups or aggregate it together. That seems simple enough, but how do we decide which to do?\nThe answer is to think causally: how was the data generated and based on this, what factors influence the results that we are not shown?\nIn the exercise vs disease example, we intuitively know that exercise is not the only factor affecting the risk of developing a disease. In the data, there are two different causes of disease yet by aggregating the data and looking at only risk vs exercise, we ignore the second cause - age - completely.\nIf we go ahead and plot risk vs age, we can see that the age of the patient is strongly positively correlated with disease risk.\n\n\n\n\n\n\n\n\n\nAs the patient increases in age, their risk of the disease increases which means older patients are more likely to develop the disease than younger patients even with the same amount of exercise. Therefore, to assess the effect of just exercise on disease, we would want to hold the age constant and change the amount of weekly exercise."
  },
  {
    "objectID": "ObservationalStudies.html#resolving-the-paradox-1",
    "href": "ObservationalStudies.html#resolving-the-paradox-1",
    "title": "Observational Studies",
    "section": "Resolving the Paradox",
    "text": "Resolving the Paradox\nIf we go ahead and plot risk vs age, we can see that the age of the patient is strongly positively correlated with disease risk.\n\n\n\n\n\n\n\n\n\nAs the patient increases in age, their risk of the disease increases which means older patients are more likely to develop the disease than younger patients even with the same amount of exercise. Therefore, to assess the effect of just exercise on disease, we would want to hold the age constant and change the amount of weekly exercise."
  },
  {
    "objectID": "3-MultipleRegression.html#takeaways",
    "href": "3-MultipleRegression.html#takeaways",
    "title": "Multiple Regression",
    "section": "Takeaways",
    "text": "Takeaways\n\nGeneralized linear models allow us to fit models to predict non-continuous outcomes\nPredicting binary outcomes requires modeling the log-odds of success, where p = probability of success"
  },
  {
    "objectID": "3-MultipleRegression.html#recap-logistic-regression",
    "href": "3-MultipleRegression.html#recap-logistic-regression",
    "title": "Multiple Regression",
    "section": "Recap: Logistic Regression",
    "text": "Recap: Logistic Regression\nLogistic regression is a generalized regression model where the outcome is a two-level categorical variable. The outcome, takes the value 1 or 0 with probability. Ultimately, it is the probability of the outcome taking the value 1 (i.e., being a “success”) that we model in relation to the predictor variables. For this to work, we transform the expected outcome in such a way that it will be bounded between 0 and 1, and hence our estimates will be sensical. The transformation we use is called the logit, and is the natural logarithm of the odds of success.\n\nModelling binary outcomes\n\n\\(y\\) takes on values 0 (failure) or 1 (success)\n\\(p\\): probability of success\n\\(1-p\\): probability of failure\nWe can’t model \\(y\\) directly, so instead we model \\(p\\)\n\nLinear model\n\\[\n\\hat{p}_i = \\beta_o + \\beta_1 \\times x\n\\]\n\nBut remember that \\(p\\) must be between 0 and 1\nWe need a link function that transforms the linear model to have an appropriate range\n\nLogit link function\nThe logit function takes values between 0 and 1 (probabilities) and maps them to values in the range negative infinity to positive infinity:\n\\[\nlogit(p) = log \\bigg( \\frac{p}{1 - p} \\bigg)\n\\]\nGeneralized linear model\n\nWe model the logit (log-odds) of \\(p\\) :\n\n\\[\nlogit(\\hat{p}) = log \\bigg( \\frac{\\hat{p}}{1 - \\hat{p}} \\bigg) = \\beta_o + \\beta_1 \\times x\n\\]\n\nThen take the inverse to obtain the predicted \\(p\\):\n\n\\[\n\\hat{p} = \\frac{e^{\\beta_o + \\beta_1 \\times x }}{1 + e^{\\beta_o + \\beta_1 \\times x }}\n\\]\nA logistic model visualized"
  },
  {
    "objectID": "3-MultipleRegression.html#multiple-logistic-regression",
    "href": "3-MultipleRegression.html#multiple-logistic-regression",
    "title": "Multiple Regression",
    "section": "Multiple Logistic Regression",
    "text": "Multiple Logistic Regression\nMultiple logistic regression is used to model the relationship between a binary outcome variable and two or more predictor variables. It extends simple logistic regression by including multiple independent variables, which can be continuous or categorical, to assess their combined effect on the probability of an event occurring. The model estimates odds ratios for each predictor while controlling for the effects of others, making it useful for understanding complex associations."
  },
  {
    "objectID": "3-MultipleRegression.html#example-irish-continued---including-more-predictors",
    "href": "3-MultipleRegression.html#example-irish-continued---including-more-predictors",
    "title": "Multiple Regression",
    "section": "Example: Irish continued - including more predictors",
    "text": "Example: Irish continued - including more predictors\nIt is frequently of interest to use multiple covariates to improve our predictive power. Let’s fit a logistic regression model including all four covariates as predictors in our model: \\[\\displaystyle\\log\\left(\\frac{p}{1-p}\\right)=\\beta_0+\\beta_1*\\mbox{Sepal.Length}+\\beta_2*\\mbox{Sepal.Width}+\\beta_3*\\mbox{Petal.Length}+\\beta_4*\\mbox{Petal.Width}\\]\n\niris_mod2 &lt;- glm(Species.binary ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,\n                 family = binomial, \n                 data = iris2)\niris_mod2 %&gt;% coef %&gt;% round(digits = 4)\n\n (Intercept) Sepal.Length  Sepal.Width Petal.Length  Petal.Width \n    -42.6378      -2.4652      -6.6809       9.4294      18.2861 \n\n\n\nClassification\n\nQuestion: How well did we do at classifying the Iris species?\n\n\niris_predict &lt;- iris2 %&gt;% \n                  mutate(p_hat = predict(iris_mod2, type = \"response\") %&gt;% round(2),\n                         Species_pred = ifelse(p_hat &gt;= 0.5,\"virginica\",\"versicolor\"))\n\nn_correct_full &lt;- sum(iris_predict$Species_pred == iris_predict$Species)\nn_correct_full\n\n[1] 98\n\n\nOur model correctly predicts the species class of 98 out of 100 observations."
  },
  {
    "objectID": "sampling.html",
    "href": "sampling.html",
    "title": "Sampling Principles and Strategies",
    "section": "",
    "text": "The first step in conducting research is to identify topics or questions that are to be investigated. A clearly laid out research question is helpful in identifying what subjects or cases should be studied and what variables are important. It is also important to consider how data are collected so that the data are reliable and help achieve the research goals."
  },
  {
    "objectID": "sampling.html#research-questions",
    "href": "sampling.html#research-questions",
    "title": "Untitled",
    "section": "",
    "text": "Most research questions actually break down into 2 parts:\n\nDescriptive Statistics: What relationship can we observe between the variables, in the sample?\nInferential Statistics: Supposing we see a relationship in the sample data, how much evidence is provided for a relationship in the population? Does the data provide lots of evidence for a relationship in the population, or could the relationship we see in the sample be due just to chance variation in the sampling process that gave us the data?\n\nResearch Question: In the Ireland, what is the mean height of adult males (18 years +)?\nPopulation: all Irish adult males.\nQ. Can we survey the entire population?\nA. This is nearly impossible! It would be much quicker and easier to measure only a subset of the population, a sample.\nQ. How can we ensure the sample is an accurate reflection of the population?"
  },
  {
    "objectID": "sampling.html#sampling",
    "href": "sampling.html#sampling",
    "title": "Sampling",
    "section": "Sampling",
    "text": "Sampling\n\nSuppose that we were able to choose an appropriate sample that provides an accurate representation of the Irish population of men.\nThen, we have two different means to consider:\nMean Height of the Sample\n\nStatistic - describes the sample\nCan be known, but it changes depending on the sample\nSymbol - \\(\\bar{x}\\) (pronounced “x bar”)\n\nMean Height of the Population\n\nParameter - describes the population\nUsually unknown - but we wish we knew it!\nSymbol - \\(\\mu\\) (pronounced “mu”)"
  },
  {
    "objectID": "sampling.html#sample-vs-population",
    "href": "sampling.html#sample-vs-population",
    "title": "Sampling",
    "section": "Sample vs Population",
    "text": "Sample vs Population\nA reminder of an important distinction that we want to make before discussing surveys is the distinction between a sample and a population.\nA population is the set of subjects of interest.\nA sample is the subset of the population for which we have data.\n\n\nOur goal is to use the information we’ve gathered from the sample to infer, or predict, something about the population.\nFor our example, we want to predict the population mean, using our knowledge of the sample.\nThe accuracy of our sample mean relies heavily upon how well our sample represents the population at large.\nIf our sample does a poor job at representing the population, then any inferences that we make about the population are also going to be poor.\n\nThus, it is very important to select a good sample!"
  },
  {
    "objectID": "sampling.html#random-sampling",
    "href": "sampling.html#random-sampling",
    "title": "Sampling",
    "section": "Random Sampling",
    "text": "Random Sampling\nThere are four different methods of random sampling that we will introduce:\n\nSimple Random Sampling (SRS)\nSystematic Sampling\nStratified Sampling\nCluster Sampling"
  },
  {
    "objectID": "sampling.html#example-data-fakeschool",
    "href": "sampling.html#example-data-fakeschool",
    "title": "Sampling Principles and Strategies",
    "section": "Example Data: FakeSchool",
    "text": "Example Data: FakeSchool\n\nWe will use the FakeSchool data to compare the sampling methods.\nThe dataset contains information on 28 students from FakeSchool. We will assume that this is the population from which we will sample.\n\nHere is a snippet of the data:\n\n\n# A tibble: 4 × 5\n  Students Sex   class   GPA Honors\n  &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; \n1 Alice    F     Fr     3.8  Yes   \n2 Brad     M     Fr     2.6  Yes   \n3 Caleb    M     Fr     2.25 No    \n4 Daisy    F     Fr     2.1  No    \n\n\n\nLet’s say that we are interested in mean GPA\nWe can compute the true mean GPA\n\n\nFakeSchool %&gt;% \n  pull(GPA) %&gt;% \n  mean\n\n[1] 2.766429\n\n\n\nRemember this value is not typically known!"
  },
  {
    "objectID": "sampling.html#simple-random-sampling",
    "href": "sampling.html#simple-random-sampling",
    "title": "Sampling Principles and Strategies",
    "section": "Simple Random Sampling",
    "text": "Simple Random Sampling\nIn simple random sampling (SRS), for a given sample size, n, each member of the population has an equal chance of being selected.\nLet’s select a simple random sample of 7 elements without replacement. We can accomplish this easily with the dplyr function sample_n() in R. This function requires two pieces of information:\n\nthe size of the sample\nthe dataset from which to draw the sample\n\n\nSimple Random Sampling in R\n\n## create a simple random sample (n = 7)\nsrs &lt;- FakeSchool %&gt;% \n          sample_n(7)\nsrs\n\n# A tibble: 7 × 5\n  Students Sex   class   GPA Honors\n  &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; \n1 Daisy    F     Fr      2.1 No    \n2 Bob      M     Sr      3.8 Yes   \n3 Frank    M     Sr      2   No    \n4 Garth    M     Jr      1.1 No    \n5 Eliott   M     Jr      1.9 No    \n6 Angela   F     Sr      4   Yes   \n7 Chris    M     So      4   Yes   \n\n## calculate the mean of the srs\nsrs %&gt;% \n  pull(GPA) %&gt;% \n  mean\n\n[1] 2.7\n\n\n\n\nSRS Strength vs Weaknesses\nStrengths\n\nThe selection of one element does not affect the selection of others.\nEach possible sample, of a given size, has an equal chance of being selected.\nSimple random samples tend to be good representations of the population.\nRequires little knowledge of the population.\n\nWeaknesses\n\nIf there are small subgroups within the population, a SRS may not give an accurate representation of that subgroup. In fact, it may not include it at all! This is especially true if the sample size is small.\nIf the population is large and widely dispersed, it can be costly (both in time and money) to collect the data."
  },
  {
    "objectID": "sampling.html#systematic-sampling",
    "href": "sampling.html#systematic-sampling",
    "title": "Sampling Principles and Strategies",
    "section": "Systematic Sampling",
    "text": "Systematic Sampling\nIn a systematic sample, the sample members from a larger population are selected according to a random starting point but with a fixed, periodic interval, i.\nThese are the two main steps required to implement systematic sampling:\n\nDivide the size of the target population “N” by sample size “n” to calculate the sampling interval “i”. If this value is in decimals, it must be rounded to the nearest whole number/integer.\nThen, a random starting point, “r”, may be chosen from where the sampling interval “i” is used in order to choose respondents from the target population.\n\nBefore selecting the sample group, researchers must ensure that the list of the sample frame is not organized in a cyclical or periodic way in order to avoid selecting a biased sample group.\n\n\nTo illustrate the idea, let’s take a 1-in-4 systematic sample from our FakeSchool population.\n\nSystematic Sampling in R\n\n# randomly selecting our starting element.\nstart=sample(1:4,1)\nstart\n\n[1] 3\n\n# Now find every 4th row index starting with start\nsample_rows &lt;- seq(start, nrow(FakeSchool), by = 4)\nsample_rows\n\n[1]  3  7 11 15 19 23 27\n\n# Now choose the data corresponding to the row indexes\nsys_samp &lt;- FakeSchool %&gt;% \n        filter(row_number() %in% sample_rows)\n\n\n# print the systematic sample\nsys_samp\n\n# A tibble: 7 × 5\n  Students Sex   class   GPA Honors\n  &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; \n1 Caleb    M     Fr     2.25 No    \n2 Georg    M     Fr     1.4  No    \n3 Dylan    M     So     3.5  Yes   \n4 Adam     M     Jr     3.98 Yes   \n5 Faith    F     Jr     2.5  Yes   \n6 Bob      M     Sr     3.8  Yes   \n7 Ed       M     Sr     1.5  No    \n\n# find the mean GPA from the sys_samp\nsys_samp %&gt;% \n  pull(GPA) %&gt;% \n  mean\n\n[1] 2.704286\n\n\n\n\nStrength vs Weaknesses\nStrengths\n\nAssures an even, random sampling of the population.\nIt is especially useful when the population that you are studying is arranged in time. For example, suppose you are interested in the average amount of money that people spend at the grocery store on a Wednesday evening. A systematic sample could be used by selecting every 10th person that walks into the store.\n\nWeaknesses\n\nNot every combination has an equal chance of being selected. Many combinations will never be selected using a systematic sample!\nBeware of periodicity in the population! If, the selections match some pattern then the sample may not be representative of the population.\n\n\n\nNoticing patterns in data\n\nThe FakeSchool data is ordered according to the student’s year in school (freshmen, sophomore, junior, senior) and then by GPA (highest - lowest)\nTaking a systematic sample ensures that we have a person from each class represented in our sample.\nBut, what would happen if we took a systematic sample where k = 7 and the sample started at 1?"
  },
  {
    "objectID": "sampling.html#stratified-sampling",
    "href": "sampling.html#stratified-sampling",
    "title": "Sampling Principles and Strategies",
    "section": "Stratified Sampling",
    "text": "Stratified Sampling\nIn a stratified sample, the population must first be separated into homogeneous groups, or strata. Each element only belongs to one stratum and the stratum consist of elements that are alike in some way. A simple random sample is then drawn from each stratum, which is combined to make the stratified sample.\nLet’s take a stratified sample of 7 elements from FakeSchool using the following strata: Honors, Not Honors.\n\nStratified Sampling in R\n\n# determine how many elements belong to each strata\nFakeSchool %&gt;% \n  count(Honors) \n\n# A tibble: 2 × 2\n  Honors     n\n  &lt;fct&gt;  &lt;int&gt;\n1 No        16\n2 Yes       12\n\n# get the data for each strata\n# honors\nhon_strata &lt;- FakeSchool %&gt;% \n                filter(Honors == \"Yes\")\n\n# not honors\nnonhon_strata &lt;- FakeSchool %&gt;% \n                filter(Honors == \"No\")\n\nTry to divide the sampling evenly, the sample size is odd so use the bigger number for the larger strata\n\nhon_samp &lt;- hon_strata %&gt;% \n              sample_n(3)\n\nnonhon_samp &lt;- nonhon_strata %&gt;% \n                sample_n(4)\n\nstrat_samp &lt;- full_join(hon_samp, nonhon_samp)\n\nJoining with `by = join_by(Students, Sex, class, GPA, Honors)`\n\n\n\n# print the stratified sample\nstrat_samp\n\n# A tibble: 7 × 5\n  Students Sex   class   GPA Honors\n  &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; \n1 Angela   F     Sr     4    Yes   \n2 Adam     M     Jr     3.98 Yes   \n3 Cassie   F     Jr     3.75 Yes   \n4 Garth    M     Jr     1.1  No    \n5 Brittany F     Jr     3.9  No    \n6 Frank    M     Sr     2    No    \n7 Eva      F     Fr     1.8  No    \n\n# get the mean GPA from the stratified sample\nstrat_samp %&gt;% \n  pull(GPA) %&gt;% \n  mean\n\n[1] 2.932857\n\n\n\n\nStrength vs Weaknesses\nStrengths\n\nRepresentative of the population, because elements from all strata are included in the sample.\nEnsures that specific groups are represented, sometimes even proportionally, in the sample.\nAllows comparisons to be made between strata, if necessary. For example, a stratified sample allows you to easily compare the mean GPA of Honors students to the mean GPA of non-Honors students.\n\nWeaknesses\n\nRequires prior knowledge of the population. You have to know something about the population to be able to split into strata!"
  },
  {
    "objectID": "sampling.html#cluster-sampling",
    "href": "sampling.html#cluster-sampling",
    "title": "Sampling Principles and Strategies",
    "section": "Cluster Sampling",
    "text": "Cluster Sampling\nCluster sampling is a sampling method used when natural groups are evident in the population. The clusters should all be similar each other: each cluster should be a small scale representation of the population. To take a cluster sample, a random sample of the clusters is chosen. The elements of the randomly chosen clusters make up the sample.\nLet’s take a cluster sample using the grade level (freshmen, sophomore, junior, senior) of FakeSchool as the clusters. Let’s take a random sample of 2 of them.\n\nCluster Sampling in R\n\ncluster_samp &lt;- FakeSchool %&gt;% \n                  group_nest(class) %&gt;% \n                  sample_n(size = 2) %&gt;% \n                  unnest(data)\n\n## what class groups were used \ncluster_samp$class %&gt;% unique()\n\n[1] Jr So\nLevels: Fr Jr So Sr\n\n# calculate the mean GPA from the cluster sample\ncluster_samp %&gt;% \n  pull(GPA) %&gt;% \n  mean\n\n[1] 3.057857\n\n\n\n\nStrength vs Weaknesses\nStrengths\nMakes it possible to sample if there is no list of the entire population, but there is a list of subpopulations. For example, there is not a list of all school members in the United States. However, there is a list of schools that you could sample and then acquire the members list from each of the selected schools.\nWeaknesses\nNot always representative of the population. Elements within clusters tend to be similar to one another based on some characteristic(s). This can lead to over-representation or under-representation of those characteristics in the sample."
  },
  {
    "objectID": "sampling.html#sampling-principles-and-strategies",
    "href": "sampling.html#sampling-principles-and-strategies",
    "title": "Sampling",
    "section": "Sampling Principles and Strategies",
    "text": "Sampling Principles and Strategies\n\nResearch Question(s)\nResearch Question: Over the last 5 years, how many MU Data Science or Statistics graduates have gone on to get a job in a field directly related to their degree.\nPopulation: All DS or Statistics graduates from MU from the last 5 years.\nQ. Can we survey the entire population?\nA. This would likely be very difficult. It is more realistic to assume that we can work with a fraction of the population.\nQ. How can we ensure the sample is an accurate reflection of the population?\nA. Appropriate sampling.\nMost research questions actually break down into 2 parts:\n\nDescriptive Statistics: What relationship can we observe between the variables in the sample?\nInferential Statistics: Supposing we see a relationship in the sample data, how much evidence is provided for a relationship in the population? Does the data provide lots of evidence for a relationship in the population, or could the relationship we see in the sample be due just to chance variation in the sampling process that gave us the data?\n\n\n\nAnecdotal Evidence\n“I met two students who did a Data Science degree in Maynooth but they are not working as data scientists. The degree must not get you a Data Science job.”\nThere are two problems here. First, the data only represent two cases. Second, and more importantly, it is unclear whether these cases are actually representative of the population. Data collected in this haphazard fashion are called anecdotal evidence."
  },
  {
    "objectID": "sampling.html#sampling-from-the-population",
    "href": "sampling.html#sampling-from-the-population",
    "title": "Sampling Principles and Strategies",
    "section": "Sampling from the population",
    "text": "Sampling from the population\nA population is the set of subjects of interest.\nA sample is the subset of the population for which we have data.\nSuppose that we were able to choose an appropriate sample that provides an accurate representation of the DS and Statistics Graduates:\n\nNow we have two different summaries to consider for our research question:\nProportion of the sample that went into a directly related field\n\nStatistic - describes the sample\nCan be known, but it changes depending on the sample\nSymbol - \\(\\hat{p}\\)\n\nProportion of the population that went into a directly related field*\n\nParameter - describes the population\nUsually unknown - but we wish we knew it!\nSymbol - \\(\\pi\\)\n\n\n\n\nOur goal is to use the information we’ve gathered from the sample to infer, or predict, something about the population.\nFor our example, we want to predict the population proportion, using our knowledge of the sample.\nThe accuracy of our sample proportion relies heavily upon how well our sample represents the population at large.\nIf our sample does a poor job at representing the population, then any inferences that we make about the population are also going to be poor."
  },
  {
    "objectID": "sampling.html#sampling-procedures",
    "href": "sampling.html#sampling-procedures",
    "title": "Sampling Principles and Strategies",
    "section": "Sampling Procedures",
    "text": "Sampling Procedures\nAlmost all statistical methods are based on the notion of implied randomness. If data are not collected in a random framework from a population, these statistical methods – the estimates and errors associated with the estimates – are not reliable.\nThere are four different methods of random sampling that we will introduce:\n\nSimple Random Sampling (SRS)\nSystematic Sampling\nStratified Sampling\nCluster Sampling"
  },
  {
    "objectID": "4-sampling.html",
    "href": "4-sampling.html",
    "title": "Sampling Principles and Strategies",
    "section": "",
    "text": "The first step in conducting research is to identify topics or questions that are to be investigated. A clearly laid out research question is helpful in identifying what subjects or cases should be studied and what variables are important. It is also important to consider how data are collected so that the data are reliable and help achieve the research goals."
  },
  {
    "objectID": "4-sampling.html#sampling-from-the-population",
    "href": "4-sampling.html#sampling-from-the-population",
    "title": "Sampling Principles and Strategies",
    "section": "Sampling from the population",
    "text": "Sampling from the population\nA population is the set of subjects of interest.\nA sample is the subset of the population for which we have data.\nSuppose that we were able to choose an appropriate sample that provides an accurate representation of the DS and Statistics Graduates:\n\nNow we have two different summaries to consider for our research question:\nProportion of the sample that went into a directly related field\n\nStatistic - describes the sample\nCan be known, but it changes depending on the sample\nSymbol - \\(\\hat{p}\\)\n\nProportion of the population that went into a directly related field\n\nParameter - describes the population\nUsually unknown - but we wish we knew it!\nSymbol - \\(\\pi\\)\n\n\n\n\nOur goal is to use the information we’ve gathered from the sample to infer, or predict, something about the population.\nFor our example, we want to predict the population proportion, using our knowledge of the sample.\nThe accuracy of our sample proportion relies heavily upon how well our sample represents the population at large.\nIf our sample does a poor job at representing the population, then any inferences that we make about the population are also going to be poor."
  },
  {
    "objectID": "4-sampling.html#sampling-procedures",
    "href": "4-sampling.html#sampling-procedures",
    "title": "Sampling Principles and Strategies",
    "section": "Sampling Procedures",
    "text": "Sampling Procedures\nAlmost all statistical methods are based on the notion of implied randomness. If data are not collected in a random framework from a population, these statistical methods – the estimates and errors associated with the estimates – are not reliable.\nThere are four different methods of random sampling that we will introduce:\n\nSimple Random Sampling (SRS)\nSystematic Sampling\nStratified Sampling\nCluster Sampling"
  },
  {
    "objectID": "4-sampling.html#example-data-fakeschool",
    "href": "4-sampling.html#example-data-fakeschool",
    "title": "Sampling Principles and Strategies",
    "section": "Example Data: FakeSchool",
    "text": "Example Data: FakeSchool\n\nWe will use the FakeSchool data to compare the sampling methods.\nThe dataset contains information on 28 students from FakeSchool. We will assume that this is the population from which we will sample.\n\n\nlibrary(tigerstats)\nlibrary(tidyverse)\ndata(\"FakeSchool\")\nFakeSchool &lt;- as_tibble(FakeSchool)\n\nHere is a snippet of the data:\n\n\n# A tibble: 4 × 5\n  Students Sex   class   GPA Honors\n  &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; \n1 Alice    F     Fr     3.8  Yes   \n2 Brad     M     Fr     2.6  Yes   \n3 Caleb    M     Fr     2.25 No    \n4 Daisy    F     Fr     2.1  No    \n\n\n\nLet’s say that we are interested in mean GPA\nWe can compute the true mean GPA\n\n\nFakeSchool %&gt;% \n  pull(GPA) %&gt;% \n  mean\n\n[1] 2.766429\n\n\n\nRemember this value is not typically known!"
  },
  {
    "objectID": "4-sampling.html#simple-random-sampling",
    "href": "4-sampling.html#simple-random-sampling",
    "title": "Sampling Principles and Strategies",
    "section": "Simple Random Sampling",
    "text": "Simple Random Sampling\nIn simple random sampling (SRS), for a given sample size, n, each member of the population has an equal chance of being selected.\nLet’s select a simple random sample of 7, without replacement. We can accomplish this easily with the dplyr function sample_n() in R. This function requires two pieces of information:\n\nthe size of the sample\nthe dataset from which to draw the sample\n\n\nSimple Random Sampling in R\n\n## create a simple random sample (n = 7)\nsrs &lt;- FakeSchool %&gt;% \n          sample_n(7)\nsrs\n\n# A tibble: 7 × 5\n  Students Sex   class   GPA Honors\n  &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; \n1 Daisy    F     Fr      2.1 No    \n2 Bob      M     Sr      3.8 Yes   \n3 Frank    M     Sr      2   No    \n4 Garth    M     Jr      1.1 No    \n5 Eliott   M     Jr      1.9 No    \n6 Angela   F     Sr      4   Yes   \n7 Chris    M     So      4   Yes   \n\n## calculate the mean of the srs\nsrs %&gt;% \n  pull(GPA) %&gt;% \n  mean\n\n[1] 2.7\n\n\n\n\nSRS Strength vs Weaknesses\nStrengths\n\nThe selection of one element does not affect the selection of others.\nEach possible sample, of a given size, has an equal chance of being selected.\nSimple random samples tend to be good representations of the population.\nRequires little knowledge of the population.\n\nWeaknesses\n\nIf there are small subgroups within the population, a SRS may not give an accurate representation of that subgroup. In fact, it may not include it at all! This is especially true if the sample size is small.\nIf the population is large and widely dispersed, it can be costly (both in time and money) to collect the data."
  },
  {
    "objectID": "4-sampling.html#systematic-sampling",
    "href": "4-sampling.html#systematic-sampling",
    "title": "Sampling Principles and Strategies",
    "section": "Systematic Sampling",
    "text": "Systematic Sampling\nIn a systematic sample, the sample members from a larger population are selected according to a random starting point but with a fixed, periodic interval, i.\nThese are the two main steps required to implement systematic sampling:\n\nDivide the size of the target population “N” by sample size “n” to calculate the sampling interval “i”. If this value is in decimals, it must be rounded to the nearest whole number/integer.\nThen, a random starting point, “r”, may be chosen from where the sampling interval “i” is used in order to choose respondents from the target population.\n\nBefore selecting the sample group, researchers must ensure that the list of the sample frame is not organized in a cyclical or periodic way in order to avoid selecting a biased sample group.\n\n\nTo illustrate the idea, let’s take a 1-in-4 systematic sample from our FakeSchool population.\n\nSystematic Sampling in R\n\n# randomly selecting our starting element.\nstart=sample(1:4,1)\nstart\n\n[1] 3\n\n# Now find every 4th row index starting with start\nsample_rows &lt;- seq(start, nrow(FakeSchool), by = 4)\nsample_rows\n\n[1]  3  7 11 15 19 23 27\n\n# Now choose the data corresponding to the row indexes\nsys_samp &lt;- FakeSchool %&gt;% \n        filter(row_number() %in% sample_rows)\n\n\n# print the systematic sample\nsys_samp\n\n# A tibble: 7 × 5\n  Students Sex   class   GPA Honors\n  &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; \n1 Caleb    M     Fr     2.25 No    \n2 Georg    M     Fr     1.4  No    \n3 Dylan    M     So     3.5  Yes   \n4 Adam     M     Jr     3.98 Yes   \n5 Faith    F     Jr     2.5  Yes   \n6 Bob      M     Sr     3.8  Yes   \n7 Ed       M     Sr     1.5  No    \n\n# find the mean GPA from the sys_samp\nsys_samp %&gt;% \n  pull(GPA) %&gt;% \n  mean\n\n[1] 2.704286\n\n\n\n\nStrength vs Weaknesses\nStrengths\n\nAssures an even, random sampling of the population.\nIt is especially useful when the population that you are studying is arranged in time. For example, suppose you are interested in the average amount of money that people spend at the grocery store on a Wednesday evening. A systematic sample could be used by selecting every 10th person that walks into the store.\n\nWeaknesses\n\nNot every combination has an equal chance of being selected. Many combinations will never be selected using a systematic sample!\nBeware of periodicity in the population! If, the selections match some pattern then the sample may not be representative of the population.\n\n\n\nNoticing patterns in data\n\nThe FakeSchool data is ordered according to the student’s year in school (freshmen, sophomore, junior, senior) and then by GPA (highest - lowest)\nTaking a systematic sample ensures that we have a person from each class represented in our sample.\nBut, what would happen if we took a systematic sample where k = 7 and the sample started at 1?"
  },
  {
    "objectID": "4-sampling.html#stratified-sampling",
    "href": "4-sampling.html#stratified-sampling",
    "title": "Sampling Principles and Strategies",
    "section": "Stratified Sampling",
    "text": "Stratified Sampling\nIn a stratified sample, the population must first be separated into homogeneous groups, or strata. Each element only belongs to one stratum and the stratum consist of elements that are alike in some way. A simple random sample is then drawn from each stratum, which is combined to make the stratified sample.\nLet’s take a stratified sample of 7 elements from FakeSchool using the following strata: Honors, Not Honors.\n\nStratified Sampling in R\n\n# determine how many elements belong to each strata\nFakeSchool %&gt;% \n  count(Honors) \n\n# A tibble: 2 × 2\n  Honors     n\n  &lt;fct&gt;  &lt;int&gt;\n1 No        16\n2 Yes       12\n\n# get the data for each strata\n# honors\nhon_strata &lt;- FakeSchool %&gt;% \n                filter(Honors == \"Yes\")\n\n# not honors\nnonhon_strata &lt;- FakeSchool %&gt;% \n                filter(Honors == \"No\")\n\nTry to divide the sampling evenly, the sample size is odd so use the bigger number for the larger strata\n\nhon_samp &lt;- hon_strata %&gt;% \n              sample_n(3)\n\nnonhon_samp &lt;- nonhon_strata %&gt;% \n                sample_n(4)\n\nstrat_samp &lt;- full_join(hon_samp, nonhon_samp)\n\nJoining with `by = join_by(Students, Sex, class, GPA, Honors)`\n\n\n\n# print the stratified sample\nstrat_samp\n\n# A tibble: 7 × 5\n  Students Sex   class   GPA Honors\n  &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; \n1 Angela   F     Sr     4    Yes   \n2 Adam     M     Jr     3.98 Yes   \n3 Cassie   F     Jr     3.75 Yes   \n4 Garth    M     Jr     1.1  No    \n5 Brittany F     Jr     3.9  No    \n6 Frank    M     Sr     2    No    \n7 Eva      F     Fr     1.8  No    \n\n# get the mean GPA from the stratified sample\nstrat_samp %&gt;% \n  pull(GPA) %&gt;% \n  mean\n\n[1] 2.932857\n\n\n\n\nStrength vs Weaknesses\nStrengths\n\nRepresentative of the population, because elements from all strata are included in the sample.\nEnsures that specific groups are represented, sometimes even proportionally, in the sample.\nAllows comparisons to be made between strata, if necessary. For example, a stratified sample allows you to easily compare the mean GPA of Honors students to the mean GPA of non-Honors students.\n\nWeaknesses\n\nRequires prior knowledge of the population. You have to know something about the population to be able to split into strata!"
  },
  {
    "objectID": "4-sampling.html#cluster-sampling",
    "href": "4-sampling.html#cluster-sampling",
    "title": "Sampling Principles and Strategies",
    "section": "Cluster Sampling",
    "text": "Cluster Sampling\nCluster sampling is a sampling method used when natural groups are evident in the population. The clusters should all be to similar each other: each cluster should be a small scale representation of the population. To take a cluster sample, a random sample of the clusters is chosen. The elements of the randomly chosen clusters make up the sample.\nLet’s assume that we have a cluster variable (with clusters 1-4) in the FakeSchool data.\n\n\n# A tibble: 28 × 6\n   Students Sex   class   GPA Honors cluster\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt;    &lt;int&gt;\n 1 Alice    F     Fr     3.8  Yes          1\n 2 Brad     M     Fr     2.6  Yes          1\n 3 Caleb    M     Fr     2.25 No           2\n 4 Daisy    F     Fr     2.1  No           4\n 5 Faye     F     Fr     2    No           2\n 6 Eva      F     Fr     1.8  No           4\n 7 Georg    M     Fr     1.4  No           2\n 8 Andrea   F     So     4    Yes          2\n 9 Betsy    F     So     4    Yes          1\n10 Chris    M     So     4    Yes          1\n# ℹ 18 more rows\n\n\n\nCluster Sampling in R\nLet’s take a random sample of 2 of two clusters.\n\ncluster_samp &lt;- FakeSchool %&gt;% \n                  group_nest(cluster) %&gt;% \n                  sample_n(size = 2) %&gt;% \n                  unnest(data)\n\n## what class groups were used \ncluster_samp$cluster %&gt;% unique()\n\n[1] 4 1\n\n# calculate the mean GPA from the cluster sample\ncluster_samp %&gt;% \n  pull(GPA) %&gt;% \n  mean\n\n[1] 2.82\n\n\n\n\nStrength vs Weaknesses\nStrengths\nMakes it possible to sample if there is no list of the entire population, but there is a list of subpopulations. For example, there is not a list of all school members in the United States. However, there is a list of schools that you could sample and then acquire the members list from each of the selected schools.\nWeaknesses\nNot always representative of the population. Elements within clusters tend to be similar to one another based on some characteristic(s). This can lead to over-representation or under-representation of those characteristics in the sample."
  },
  {
    "objectID": "5-experiments.html",
    "href": "5-experiments.html",
    "title": "Experimental Studies",
    "section": "",
    "text": "Studies where the researchers assign treatments to cases are called experiments. When this assignment includes randomization, e.g., using a coin flip to decide which treatment a patient receives, it is called a randomized experiment. Randomized experiments are fundamentally important when trying to show a causal connection between two variables."
  },
  {
    "objectID": "5-experiments.html#establishing-causality",
    "href": "5-experiments.html#establishing-causality",
    "title": "Experimental Studies",
    "section": "Establishing Causality",
    "text": "Establishing Causality\n\nA treatment will often be a binary variable that is either 0 or 1. It is 0 if the person is not treated, which is to say they are in the control group, and 1 if they are treated.\nWe will typically have some outcome of interest, Y, for each person or observational unit, and that could be categorical or continuous.\nA treatment is causal if the outcome for a person, given they were not treated, is different to their outcome given they were treated.\nIf we could both treat and control the one individual at the one time, then we would know that it was only the treatment that had caused any change. However, the fundamental problem of causal inference is that we cannot both treat and control the same individual at the same time.\n\nwe instead compare the average of two groups — all those treated and all those not.\nwe estimate the counterfactual at a group level because of the impossibility of doing it at an individual level.\nthis trade-off allows us to move forward but comes at the cost of certainty.\nwe must instead rely on randomization, probabilities, and expectations."
  },
  {
    "objectID": "5-experiments.html#controlled-experiments",
    "href": "5-experiments.html#controlled-experiments",
    "title": "Experimental Studies",
    "section": "Controlled Experiments",
    "text": "Controlled Experiments\nControlled experiments are a scientific test (or a series of tests) to verify how one or more conditions (treatments - variables that are controlled by the scientist) affect one or more outcome (response) variables. We usually consider a default of there being no effect and we look for evidence that would cause us to change our mind.\nDesign of experiments can produce an experiment that efficiently answers the questions of interest, optimizing the information for the available resources. The scientific method involves:\n(a) Stating a hypothesis\n(b) Planning an experiment to objectively test the hypothesis\n(c) Observing and carefully collecting data\n(d) Interpreting experimental results (test your hypothesis)"
  },
  {
    "objectID": "5-experiments.html#general-considerations",
    "href": "5-experiments.html#general-considerations",
    "title": "Experimental Studies",
    "section": "General Considerations",
    "text": "General Considerations\n\nBasic considerations of experimentation\n\nProvide a valid comparison between treatments\nProvide valid information on the relationship between variables of interest\n\nBasic requisites\n\nThe experimental conditions must represent real conditions of the problem of interest\nTreatment comparison must be made free from other possible explanations due to the presence of other variables (confounding)\nTreatment comparison must be made with the lowest possible influence from random variation\nThe uncertainty level of the conclusions must be known\nThe experiment must be the simplest possible"
  },
  {
    "objectID": "5-experiments.html#steps-of-experimentation",
    "href": "5-experiments.html#steps-of-experimentation",
    "title": "Experimental Studies",
    "section": "Steps of Experimentation",
    "text": "Steps of Experimentation\n\n1. Define the Problem and Objectives\n\nClearly state the research question and objectives.\n\nEstablish a logical progression: Objectives → Scientific Hypotheses → Statistical Hypotheses.\n\nExamples:\n\nInvestigate the effect of Vitamin C on odontoblast length (cells responsible for tooth growth).\n\nDetermine the lethal dose of a pesticide for an agricultural pest.\n\nIdentify the optimal temperature settings for efficient machine operation.\n\n\n\n\n2. Define Experimental Conditions\n\nControlled conditions: Experiments conducted in controlled environments (e.g., greenhouses, laboratories, experimental stations).\n\nLess controlled conditions: Field studies in natural settings (e.g., farms, forests).\n\n\n\n3. Identify Variables of Interest\n\nResponse Variable (dependent variable): The outcome being measured.\n\nExample: Odontoblast length in guinea pigs, blood pressure rates.\n\n\nTreatment Factors and Levels (independent variables): Variables manipulated in the experiment.\n\nQuantitative example: Vitamin C dose (0.5, 1, 2 mg/day).\n\nQualitative example: Diet type (natural vs. artificial).\n\n\nLocal Control (Blocking) Factors: Variables controlled to reduce variability (e.g., environmental conditions, batch effects).\n\n\n\n4. Identify Experimental and Observational Units\n\nExperimental Unit: The smallest unit to which a treatment is randomly assigned.\n\nExamples: 60 guinea pigs, a plot of land with 200 trees, a section of a laboratory bench with 20 Petri dishes.\n\n\nObservational Unit: The entity from which data is collected.\n\nExamples: A single insect, tree, or Petri dish.\n\n\n\n\n5. Define Observations to be Made\n\nQualitative Observations: Presence or absence of a feature (e.g., morphological traits).\n\nQuantitative Observations: Measurable data (e.g., weight, height, count, proportion).\n\nOrdered Observations: Ranked data with an inherent order (e.g., disease severity, grading scales).\n\n\n\n6. Select the Experimental Design\n\nChoose the simplest design that meets the study’s needs without oversimplifying.\n\n\n\n7. Conduct the Experiment\n\nEnsure bias-free procedures by considering:\n\nWho is conducting the experiment.\n\nThe location of the experiment.\n\nStart and end dates.\n\nThe relevance and feasibility of the experiment.\n\nAssociated costs.\n\n\n\n\n8. Analyze Data and Interpret Results\n\nConduct analysis according to the experimental design.\n\nInterpret results within the context of:\n\nExperimental conditions.\n\nTested hypotheses.\n\nEstablished scientific knowledge.\n\n\nConsider the potential consequences of incorrect conclusions."
  },
  {
    "objectID": "5-experiments.html#determination-of-the-levels-of-a-factor",
    "href": "5-experiments.html#determination-of-the-levels-of-a-factor",
    "title": "Experimental Studies",
    "section": "Determination of the levels of a factor",
    "text": "Determination of the levels of a factor\n\nSelection: obtain the best treatments within a big set of treatments\nComparison: a small group of treatments that qualitatively differ is compared to establish differences\n\ne.g. comparison between the effects of two different diets on blood pressure\ne.g., comparison of delivery method of vitamin C (orange juice or ascorbic acid)\n\nOptimization: find the optimal level within a group of treatments\n\ne.g. dose-response experiments\n\n\n(4) Identification of the experimental and observational unit\n\nExperimental unit: individual or group of individuals in which a treatment is randomly applied; may give rise to one or more experimental units\n\ne.g. 60 guinea pigs, a plot of land with 200 trees, a section of a laboratory bench with 20 Petri dishes, etc\n\nObservational unit: physical entity that produces a unique value for the response variable\n\ne.g. a single insect, a single tree, a single Petri dish\n\n\n(5) Definition of the observations to be made\n\nObservations: essential or accessory\nQualitative: presence or absence of a morphological feature,\nQuantitative: weight, counts, proportion survived, proportion damaged\nOrdered: degree of severity of a disease, grading scale \\(\\rightarrow\\) relationship of order\nImportant things to be aware of:\n\nThe way observations will be taken\nThe way they will be registered\nIf sampling: define the number and size of samples (consider representativeness)\n\n\n(6) Selection of the experimental scheme\n\nMust be the simplest possible\nSystematic experiments: must not be used\nRandomized experiments: allow for the comparison of treatments, free from confounding"
  },
  {
    "objectID": "5-experiments.html#the-three-key-principles-of-experimentation",
    "href": "5-experiments.html#the-three-key-principles-of-experimentation",
    "title": "Experimental Studies",
    "section": "The Three Key Principles of Experimentation",
    "text": "The Three Key Principles of Experimentation\n\nRandomization: is the assignment of treatments to experimental units so that every unit has the same probability of receiving each treatment.\nReplication: provides a measurement of uncontrolled variation; it is the application of each treatment several times, i.e. to several experimental units\nLocal control: is the grouping of experimental units into groups called BLOCKS, the units within a group being as similar as possible (e.g. different growth chambers, people, time periods, different trays in a lab bench, etc)\n\n\nRandomization\n\nThe key to telling a causal story is the counterfactual: what would have happened in the absence of the treatment.\n\nThis means that establishing the control group is critical because when we do that, we establish the counterfactual.\n\nWhat we hope to be able to do is to find treatment and control groups that are the same, but for the treatment.\n\nWe might be worried about, say, underlying trends, which is one issue with a before-and-after comparison, or selection bias, which could occur when we allow self-selection. Either of these issues could result in biased estimators.\nWe use randomization to go some way to addressing these.\n\n\n\n\nRandomization\nTo explore ideas of randomization, we simulate a population, and then randomly sample from it. We will set it up so that 20% of the population are smokers, and the rest are not.\n\nset.seed(853)\n\nnumber_of_people &lt;- 5000\n\npopulation &lt;-\n  tibble(\n    person = c(1:number_of_people),\n    smoking_status = sample(\n      x = c(\"Smoker\", \"Non-Smoker\"),\n      size  = number_of_people,\n      replace = TRUE,\n      prob = c(0.2,0.8)\n    )\n  )\n\nLet’s look at population characteristics\n\npopulation %&gt;% \n  count(smoking_status)\n\n# A tibble: 2 × 2\n  smoking_status     n\n  &lt;chr&gt;          &lt;int&gt;\n1 Non-Smoker      4003\n2 Smoker           997\n\n\nNow let’s sample from the population and randomly assign a treatment and control group.\n\nset.seed(853)\n\nsample_size &lt;- 1000\n\nsample &lt;-\n  population %&gt;% \n  sample_n(sample_size) %&gt;% \n  mutate(group = sample(\n    x = c(\"Treatment\", \"Control\"),\n    size  = sample_size,\n    replace = TRUE\n  ))\n\nNow let’s look at sample characteristics within each group (treatment and control). Is the distribution of population characteristics reflected within each group?\n\nsample %&gt;% \n  count(group,  smoking_status) %&gt;% \n  group_by(group) %&gt;% \n  mutate(prop = n / sum(n)) \n\n# A tibble: 4 × 4\n# Groups:   group [2]\n  group     smoking_status     n  prop\n  &lt;chr&gt;     &lt;chr&gt;          &lt;int&gt; &lt;dbl&gt;\n1 Control   Non-Smoker       364 0.747\n2 Control   Smoker           123 0.253\n3 Treatment Non-Smoker       415 0.809\n4 Treatment Smoker            98 0.191\n\n\n\n\nInternal validity\n\nIf the treated and control groups are the same in all ways and remain that way, but for the treatment, then we have internal validity, which is to say that our control will work as a counterfactual and our results can speak to a difference between the groups in that study.\nInternal validity means that our estimates of the effect of the treatment are speaking to the treatment and not some other aspect.\nThey mean that we can use our results to make claims about what happened in the experiment.\n\n\n\nExternal validity\n\nIf the group to which we applied our randomization were representative of the broader population, and the experimental set-up were fairly similar to outside conditions, then we further could have external validity.\n\nThat would mean that the difference we find does not just apply in our own experiment, but also in the broader population.\nExternal validity means that we can use our experiment to make claims about what would happen outside the experiment.\nIt is randomization that has allowed that to happen.\n\nBut this means we need randomization twice. Firstly, into the group that was subject to the experiment, and then secondly, between treatment and control.\n\n\n\nBlocking\n\nOften there are covariates in the experimental units that are known to affect the response variable and must be taken into account.\nIdeally an experimenter can group the experimental units into blocks where the within block variance is small, but the block to block variability is large.\n\nFor example, in testing a drug to prevent heart disease, we know that gender and age also impact the outcome. We may want to partition our study participants into gender and age groups and then randomly assign the treatment (placebo vs drug) within the group.\n\nOften blocking variables are not the variables that we are primarily interested in, but must nevertheless be considered. We call these nuisance variables.\n\n\n\nBlocking Example\nExample 1. An agricultural field study has three fields in which the researchers will evaluate the quality of three different varieties of barley. Due to how they harvest the barley, we can only create a maximum of three plots in each field. In this example we will block on field since there might be differences in soil type, drainage, etc from field to field. In each field, we will plant all three varieties so that we can tell the difference between varieties without the block effect of field confounding our inference. In this example, the varieties are nested within the fields.\n\n\n# A tibble: 9 × 4\n  Field  Plot Variety Quality\n  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1     1 A       value  \n2     1     2 B       .      \n3     1     3 C       .      \n4     2     1 A       .      \n5     2     2 B       .      \n6     2     3 C       .      \n7     3     1 A       .      \n8     3     2 B       .      \n9     3     3 C       .      \n\n\n\n\nMain types of blocks\n\nNatural divisions\n\nYoung animals – litters, egg masses\nPeople or animals – gender\nContinuous gradient of change\n\nPlots on the field – declivity, humidity, fertility\nPeople or animals – age, weight, size\nSeverity of disease on the field\n\nExperimental management\n\nLaboratory procedures – technician, day, stand\nMaterial availability\n\n\n\n\n\nRandomized Complete Block Design\n\nThe aim is to have heterogeneity between blocks and homogeneity within\n\ne.g. a greenhouse with a temperature gradient, different days, different observers\nBlock is the replicate\nThe number of experimental units per block is equal to the number of treatments and every treatment occurs once in each block, the order of the treatments within a block being randomized\n\n\n\n\n\n\n\nLaboratory chamber with a humidity gradient inside\n\nLaboratory chambers with homogeneous temperature and humidity inside\n\nA field with a fertility gradient\n\nA greenhouse with a temperature gradient during the day\n\nThe dataset oatvar in the faraway library contains information about an experiment on eight different varieties of oats.\n\nThe area in which the experiment was done had some systematic variability and the researchers divided the area up into five different blocks in which they felt the area inside a block was uniform while acknowledging that some blocks are likely superior to others for growing crops.\nWithin each block, the researchers created eight plots and randomly assigned a variety to a plot. This type of design is called a Randomized Complete Block Design (RCBD) because each block contains all possible levels of the factor of primary interest.\n\n\n\nRandomized Complete Block Design - Example\n\ndata('oatvar', package='faraway')\nggplot(oatvar, aes(y=yield, x=block, color=variety)) + \n    geom_point(size=5) +\n    geom_line(aes(x=as.integer(block)))\n\n\n\n\n\n\n\n\n\n\nFactorial Experiments\n\nThere may often be more than one factor of interest to the experimenter\nExperiments that involve more than one randomized or treatment factor are called factorial experiments\nIn general, the number of treatments in a factorial experiment is the product of the numbers of levels of the treatment factors.\nThe disadvantage of this is that the number of treatments increase very quickly.\n\nExample: Pest control\n\nFactor 1: two pesticides (A and B)\nFactor 2: two doses\nThe experiment has a total of \\(2\\times 2 = 4\\) treatments\n\nExample: The Tooth Growth data\n\nFactor 1: two deliveries of vitamin C (orange juice, ascorbic acid)\nFactor 2: three doses (0.5, 1, and 2 mg/day)\nThe experiment has a total of \\(2\\times 3 = 6\\) treatments\n\n\n\n\nFor the Pesticide example, suppose 3 replicates and a completely randomized design\n\nFor the Pesticide example, suppose 3 replicates and a randomized complete block design\n\n\nThe major advantage of factorial experiments is that they allow for the detection of interactions.\nTwo factors are said to interact if the effect of one, on the response variable, depends upon the level of the other.\nIf they do not interact, they are said to be independent.\nOther terms that are synonymous with “interacting factors” are dependent and nonadditive.\n\n\n\nUsing an Interaction Plot\n\n\nA set of parallel lines indicates no interaction\n\n\n\nClearly an interaction as lines have different slopes"
  },
  {
    "objectID": "5-experiments.html#steps-of-experimentation-1",
    "href": "5-experiments.html#steps-of-experimentation-1",
    "title": "Experimental Studies",
    "section": "Steps of Experimentation",
    "text": "Steps of Experimentation\n(7) Conduction of the experiment\n\nBias-free procedures\nAlso consider\n\nEntity carrying out the experiment\nPlace of execution\nStart and end dates\nExperiment relevance\nExpenses\n\n\n(8) Data analysis and interpretation of results\n\nAnalysis in accordance with the experimental design\nInterpretation of the results within the experimental conditions, tested hypotheses and related to the previously established facts\nConsequences and probabilities of a wrong decision"
  },
  {
    "objectID": "Tutorial1.html",
    "href": "Tutorial1.html",
    "title": "DS152 Tutorial Sheet 1",
    "section": "",
    "text": "Attempt the questions below before your tutorial in the week beginning 24th February 2025."
  },
  {
    "objectID": "Tutorial1.html#instructions",
    "href": "Tutorial1.html#instructions",
    "title": "DS152 Tutorial Sheet 1",
    "section": "",
    "text": "Attempt the questions below before your tutorial in the week beginning 24th February 2025."
  },
  {
    "objectID": "Tutorial1.html#exercise-1",
    "href": "Tutorial1.html#exercise-1",
    "title": "DS152 Tutorial Sheet 1",
    "section": "Exercise 1",
    "text": "Exercise 1\nThe table below displays the number of tuberculosis cases documented by the World Health Organization in Afghanistan, Brazil, and China between 1999 and 2000. The data contains values associated with four variables (country, year, cases, and population). The tidy format for the data is:\n\ntable1\n\n# A tibble: 6 × 4\n  country      year  cases population\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\n\n\nThe data table below organizes the same data in an untidy format.\n\n\nuntidy_tab1\n\n# A tibble: 12 × 4\n   country      year type            count\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;\n 1 Afghanistan  1999 cases             745\n 2 Afghanistan  1999 population   19987071\n 3 Afghanistan  2000 cases            2666\n 4 Afghanistan  2000 population   20595360\n 5 Brazil       1999 cases           37737\n 6 Brazil       1999 population  172006362\n 7 Brazil       2000 cases           80488\n 8 Brazil       2000 population  174504898\n 9 China        1999 cases          212258\n10 China        1999 population 1272915272\n11 China        2000 cases          213766\n12 China        2000 population 1280428583\n\n\n\nWhat are the characteristics of this dataset that make it not tidy?\nIn the code below, what should [A], [B], [C], [D] and [E] be replaced with to make this dataset tidy?\n\n\ntidy_tab1 &lt;- untidy_tab1 %&gt;% \n                pivot_[A]([B] = [C],\n                          [D] = [E])\n\n[A] =\n[B] =\n[C] =\n[D] =\n[E] =\n\nThe data table below, which includes only the cases data, is organized in an untidy format.\n\n\nuntidy_tab2a\n\n# A tibble: 3 × 3\n  country     `1999` `2000`\n  &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n1 Afghanistan    745   2666\n2 Brazil       37737  80488\n3 China       212258 213766\n\n\n\nWhat are the characteristics of this dataset that make it not tidy?\nIn the code below, what should [A], [B], [C], [D], [E] and [F] be replaced with to make this dataset tidy?\n\n\ntidy_tab2a &lt;- untidy_tab2a %&gt;%  \n                pivot_[A](-[B],\n                           [C] = [D],\n                           [E] = [F])\n\n[A] =\n[B] =\n[C] =\n[D] =\n[E] =\n[F] =\n\nOnce tidy_tab2a has been created you should make the year variable numeric. Replace [G] in the code below to achieve this.\n\n\ntidy_tab2a &lt;- tidy_tab2a %&gt;% mutate(year = [G](year))\n\n[G] =\n\nThe data table below includes the population data organized in a tidy format (note: China has an additional year of data):\n\n\ntidy_tab2b\n\n# A tibble: 7 × 3\n  country      year population\n  &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan  1999   19987071\n2 Afghanistan  2000   20595360\n3 Brazil       1999  172006362\n4 Brazil       2000  174504898\n5 China        1999 1272915272\n6 China        2000 1280428583\n7 China        2009 1339125595\n\n\nAssume you want to join tidy_tab2a and tidy_tab2b in order to produce table1. Would you use left_join or right_join? Give a reason for your answer."
  },
  {
    "objectID": "Tutorial1.html#exercise-2",
    "href": "Tutorial1.html#exercise-2",
    "title": "DS152 Tutorial Sheet 1",
    "section": "Exercise 2",
    "text": "Exercise 2\nIt is thought that the growth of a particular type of insect can be predicted by the temperature at which it is living in. In an experiment, eight insects of the same weight were given living temperatures ranging between 2C and 16C and their weight gain was recorded after three days. The data have been put into the following table.\n\ninsect_id &lt;- c(1, 2,3,4,5,6,7,8)\ntemperature &lt;- c(2 ,4 ,6 ,8 ,10,12,14,16)\nweight_gain &lt;- c(1.21,0.96,1.31,1.52,1.41,1.43,1.87,1.67)\n\ninsect_dat &lt;- tibble(insect_id, temperature, weight_gain)\ninsect_dat\n\n# A tibble: 8 × 3\n  insect_id temperature weight_gain\n      &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1         1           2        1.21\n2         2           4        0.96\n3         3           6        1.31\n4         4           8        1.52\n5         5          10        1.41\n6         6          12        1.43\n7         7          14        1.87\n8         8          16        1.67\n\n\n\nThe correlation between temperature and weight gain is 0.84. What code would you use to do this calculation in R?\nInterpret the correlation result.\nWhat does it mean to say that two variables are negatively correlated?\nWhy should you inspect a scatter plot of the data even though you have information on the correlation between two variables?"
  },
  {
    "objectID": "Assignment1.html",
    "href": "Assignment1.html",
    "title": "DS152 Introduction to Data Science (2)",
    "section": "",
    "text": "Answer all questions for continuous assessment. Due: 4pm on Friday, 28th February 2025."
  },
  {
    "objectID": "Assignment1.html#instructions",
    "href": "Assignment1.html#instructions",
    "title": "DS152 Introduction to Data Science (2)",
    "section": "",
    "text": "Answer all questions for continuous assessment. Due: 4pm on Friday, 28th February 2025."
  },
  {
    "objectID": "Assignment1.html#question",
    "href": "Assignment1.html#question",
    "title": "DS152 Introduction to Data Science (2)",
    "section": "Question",
    "text": "Question\nSynopsis: US Department of Commerce, National Oceanic & Atmospheric Administration provides information on fatalities and injuries associated with natural calamities/disasters across different US states.\nIf you want to view the data in R you can run the following:\n\nnat_disaster_dat &lt;- read_csv(\"https://www.dropbox.com/scl/fi/kepof8k55mzlefy7nzfrj/nat_disaster_dat.csv?rlkey=7nx78bcpnj6ufm0hdq91ke8np&raw=1\")\n\nA glimpse if the data is shown below\n\nglimpse(nat_disaster_dat)\n\nRows: 902,297\nColumns: 4\n$ STATE      &lt;chr&gt; \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\",…\n$ EVTYPE     &lt;chr&gt; \"TORNADO\", \"TORNADO\", \"TORNADO\", \"TORNADO\", \"TORNADO\", \"TOR…\n$ FATALITIES &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 4, 0, 0, 0, 0,…\n$ INJURIES   &lt;dbl&gt; 15, 0, 2, 2, 2, 6, 1, 0, 14, 0, 3, 3, 26, 12, 6, 50, 2, 0, …\n\n\nNote:\n\nSTATE = US State\nEVTYPE = event type\nFATALITIES = # of fatalities\nINJURIES = # if injuries.\n\n\nHow many observations are in the dataset?\nAssume you want to create the summary below, which sums up the number of fatalities within each event type and then arranges by the total fatalities, in descending order.\n\n\n\n# A tibble: 977 × 2\n   EVTYPE         total_fatalities\n   &lt;chr&gt;                     &lt;dbl&gt;\n 1 TORNADO                    5633\n 2 EXCESSIVE HEAT             1903\n 3 FLASH FLOOD                 978\n 4 HEAT                        937\n 5 LIGHTNING                   816\n 6 TSTM WIND                   504\n 7 FLOOD                       470\n 8 RIP CURRENT                 368\n 9 HIGH WIND                   248\n10 AVALANCHE                   224\n# ℹ 967 more rows\n\n\nIn the code below, what should [A], [B], [C] and [D] be replaced with to create this summary?\n\nnat_disaster__summary &lt;- nat_disaster_dat %&gt;% \n                          group_by([A]) %&gt;% \n                          [B](total_fatalities = [C])) %&gt;% \n                          arrange([D](total_fatalities))\n\n[A] =\n[B] =\n[C] =\n[D] =\n\nNow assume you want to filter the summarised data from (ii) so that you have a dataset with only events where the total fatalities are greater than 200, as shown.\n\n\n\n# A tibble: 12 × 2\n   EVTYPE         total_fatalities\n   &lt;chr&gt;                     &lt;dbl&gt;\n 1 TORNADO                    5633\n 2 EXCESSIVE HEAT             1903\n 3 FLASH FLOOD                 978\n 4 HEAT                        937\n 5 LIGHTNING                   816\n 6 TSTM WIND                   504\n 7 FLOOD                       470\n 8 RIP CURRENT                 368\n 9 HIGH WIND                   248\n10 AVALANCHE                   224\n11 WINTER STORM                206\n12 RIP CURRENTS                204\n\n\nIn the code below, what should [A] and [B] be replaced with to create the filtered dataet?\n\nnat_disaster_filter &lt;- nat_disaster_summary %&gt;% \n                        [A]([B])\n\n[A] =\n[B] =\n\nNow assume you want to create the following barplot which shows the total fatalities per event type, using the filtered data from part (iii).\n\n\n\n\n\n\n\n\n\n\nIn the code below, what should [A], [B] and [C] be replaced with to create the plot?\n\nggplot(nat_disaster_filter, aes(x = [A], y = [B])) +\n  [C](stat=\"identity\") +\n  theme(axis.text.x = element_text(angle = 90)) +\n  xlab(\"\") +\n  ylab(\"# fatalities\")\n\n[A] =\n[B] =\n[C] ="
  },
  {
    "objectID": "Tutorial1_soln.html",
    "href": "Tutorial1_soln.html",
    "title": "DS152 Tutorial Sheet 1 with Solutions",
    "section": "",
    "text": "The table below displays the number of tuberculosis cases documented by the World Health Organization in Afghanistan, Brazil, and China between 1999 and 2000. The data contains values associated with four variables (country, year, cases, and population). The tidy format for the data is:\n\n\n# A tibble: 6 × 4\n  country      year  cases population\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\n\n\nThe data table below organizes the same data in an untidy format.\n\n\nuntidy_tab1\n\n# A tibble: 12 × 4\n   country      year type            count\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;\n 1 Afghanistan  1999 cases             745\n 2 Afghanistan  1999 population   19987071\n 3 Afghanistan  2000 cases            2666\n 4 Afghanistan  2000 population   20595360\n 5 Brazil       1999 cases           37737\n 6 Brazil       1999 population  172006362\n 7 Brazil       2000 cases           80488\n 8 Brazil       2000 population  174504898\n 9 China        1999 cases          212258\n10 China        1999 population 1272915272\n11 China        2000 cases          213766\n12 China        2000 population 1280428583\n\n\n\nWhat are the characteristics of this dataset that make it not tidy?\n\nThe dataset is untidy because the observations are spread over multiple rows.\n\nIn the code below, what should [A], [B], [C], [D] and [E] be replaced with to make this dataset tidy?\n\n\ntidy_tab1 &lt;- untidy_tab1 %&gt;% \n                pivot_wider(names_from = type ,\n                            values_from = count)\ntidy_tab1\n\n# A tibble: 6 × 4\n  country      year  cases population\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\n\n[A] = wider, [B] = names_from, [C] = type, [D] = values_from, [E] = count,\n\nThe data table below, which includes the cases data, is organized in an untidy format.\n\n\nuntidy_tab2a\n\n# A tibble: 3 × 3\n  country     `1999` `2000`\n  &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n1 Afghanistan    745   2666\n2 Brazil       37737  80488\n3 China       212258 213766\n\n\n\nWhat are the characteristics of this dataset that make it not tidy?\n\nColumn names are values of the year variable.\nThe cases variable is spread over two columns.\n\nIn the code below, what should [A], [B], [C], [D], [E] and [F] be replaced with to make this dataset tidy?\n\n\ntidy_tab2a &lt;- untidy_tab2a %&gt;%  \n                pivot_longer(-country,\n                              names_to = \"year\",\n                              values_to = \"cases\")\ntidy_tab2a\n\n# A tibble: 6 × 3\n  country     year   cases\n  &lt;chr&gt;       &lt;chr&gt;  &lt;dbl&gt;\n1 Afghanistan 1999     745\n2 Afghanistan 2000    2666\n3 Brazil      1999   37737\n4 Brazil      2000   80488\n5 China       1999  212258\n6 China       2000  213766\n\n\n[A] = longer, [B] = country, [C] = names_to, [D] = “year” (note “” around year is important here because you are creating a new variable), [E] = values_to, [F] = “cases” (note as with year, “” around cases is important here)\n\nOnce tidy_tab2a has been created you should make the year variable numeric. Replace [G] in the code below to achieve this.\n\n\ntidy_tab2a &lt;- tidy_tab2a %&gt;% mutate(year = as.numeric(year))\n\n[G] = as.numeric\n\nThe data table below includes the population data organized in a tidy format (note: China has an additional year of data):\n\n\ntidy_tab2b\n\n# A tibble: 7 × 3\n  country      year population\n  &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan  1999   19987071\n2 Afghanistan  2000   20595360\n3 Brazil       1999  172006362\n4 Brazil       2000  174504898\n5 China        1999 1272915272\n6 China        2000 1280428583\n7 China        2009 1339125595\n\n\nAssume you want to join tidy_tab2a and tidy_tab2b in order to produce table1. Would you use left_join or right_join? Give a reason for your answer.\n\nleft_join(tidy_tab2a,tidy_tab2b)\n\nJoining with `by = join_by(country, year)`\n\n\n# A tibble: 6 × 4\n  country      year  cases population\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\n\nright_join would include the additional year for China with an NA for the cases data and so would not produce table1."
  },
  {
    "objectID": "Tutorial1_soln.html#exercise-2",
    "href": "Tutorial1_soln.html#exercise-2",
    "title": "DS152 Tutorial Sheet 1 with Solutions",
    "section": "Exercise 2",
    "text": "Exercise 2\nIt is thought that the growth of a particular type of insect can be predicted by the temperature at which it is living in. In an experiment, eight insects of the same weight were given living temperatures ranging between 2C and 16C and their weight gain was recorded after three days. The data have been put into the following table.\n\ninsect_id &lt;- c(1, 2,3,4,5,6,7,8)\ntemperature &lt;- c(2 ,4 ,6 ,8 ,10,12,14,16)\nweight_gain &lt;- c(1.21,0.96,1.31,1.52,1.41,1.43,1.87,1.67)\n\ninsect_dat &lt;- tibble(insect_id, temperature, weight_gain)\ninsect_dat\n\n# A tibble: 8 × 3\n  insect_id temperature weight_gain\n      &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1         1           2        1.21\n2         2           4        0.96\n3         3           6        1.31\n4         4           8        1.52\n5         5          10        1.41\n6         6          12        1.43\n7         7          14        1.87\n8         8          16        1.67\n\n\n\nThe correlation between temperature and weight gain is 0.84. What code would you use to do this calculation in R?\n\n\ncor(insect_dat$temperature, insect_dat$weight_gain)\n\n[1] 0.8397303\n\n\n\nInterpret the correlation result.\n\nThere is a strong positive correlation between temperature and weight gain.\n\nWhat does it mean to say that two variables are negatively correlated?\n\nAs one variable increases in value the other decreases.\n\nWhy should you inspect a scatter plot of the data even though you have information on the correlation between two variables?\n\n\nggplot(insect_dat, aes(x = temperature, y = weight_gain)) +\n  geom_point()\n\n\n\n\n\n\n\n\nInspecting a scatter plot of the data is valuable for several reasons, even if you already know the correlation between two variables:\n1. Visual Confirmation: While correlation coefficients provide a numerical measure of the strength and direction of the relationship between two variables, a scatter plot allows you to visually confirm this relationship. Sometimes, the correlation coefficient might indicate a weak relationship, but upon visual inspection, you might notice a clear pattern or non-linear trend in the data that was not apparent from the correlation alone.\n2. Outlier Detection: Scatter plots help in identifying outliers, which are data points that deviate significantly from the overall pattern of the data. Outliers can have a disproportionate influence on the correlation, potentially skewing the interpretation of the relationship between variables.\n3. Contextual Understanding: Viewing the actual data points on a scatter plot provides a richer understanding of the relationship between variables within the specific context of the dataset. This understanding can be crucial for making informed decisions or drawing meaningful conclusions from the data.\n4. Communication: Scatter plots are often used for communication purposes, as they provide a clear and intuitive way to visualize the relationship between variables. They can be included in reports, presentations, or academic papers to effectively convey insights from the data to a broader audience."
  },
  {
    "objectID": "Tutorial1_soln.html#exercise-1",
    "href": "Tutorial1_soln.html#exercise-1",
    "title": "DS152 Tutorial Sheet 1 with Solutions",
    "section": "",
    "text": "The table below displays the number of tuberculosis cases documented by the World Health Organization in Afghanistan, Brazil, and China between 1999 and 2000. The data contains values associated with four variables (country, year, cases, and population). The tidy format for the data is:\n\n\n# A tibble: 6 × 4\n  country      year  cases population\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\n\n\nThe data table below organizes the same data in an untidy format.\n\n\nuntidy_tab1\n\n# A tibble: 12 × 4\n   country      year type            count\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;\n 1 Afghanistan  1999 cases             745\n 2 Afghanistan  1999 population   19987071\n 3 Afghanistan  2000 cases            2666\n 4 Afghanistan  2000 population   20595360\n 5 Brazil       1999 cases           37737\n 6 Brazil       1999 population  172006362\n 7 Brazil       2000 cases           80488\n 8 Brazil       2000 population  174504898\n 9 China        1999 cases          212258\n10 China        1999 population 1272915272\n11 China        2000 cases          213766\n12 China        2000 population 1280428583\n\n\n\nWhat are the characteristics of this dataset that make it not tidy?\n\nThe dataset is untidy because the observations are spread over multiple rows.\n\nIn the code below, what should [A], [B], [C], [D] and [E] be replaced with to make this dataset tidy?\n\n\ntidy_tab1 &lt;- untidy_tab1 %&gt;% \n                pivot_wider(names_from = type ,\n                            values_from = count)\ntidy_tab1\n\n# A tibble: 6 × 4\n  country      year  cases population\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\n\n[A] = wider, [B] = names_from, [C] = type, [D] = values_from, [E] = count,\n\nThe data table below, which includes the cases data, is organized in an untidy format.\n\n\nuntidy_tab2a\n\n# A tibble: 3 × 3\n  country     `1999` `2000`\n  &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n1 Afghanistan    745   2666\n2 Brazil       37737  80488\n3 China       212258 213766\n\n\n\nWhat are the characteristics of this dataset that make it not tidy?\n\nColumn names are values of the year variable.\nThe cases variable is spread over two columns.\n\nIn the code below, what should [A], [B], [C], [D], [E] and [F] be replaced with to make this dataset tidy?\n\n\ntidy_tab2a &lt;- untidy_tab2a %&gt;%  \n                pivot_longer(-country,\n                              names_to = \"year\",\n                              values_to = \"cases\")\ntidy_tab2a\n\n# A tibble: 6 × 3\n  country     year   cases\n  &lt;chr&gt;       &lt;chr&gt;  &lt;dbl&gt;\n1 Afghanistan 1999     745\n2 Afghanistan 2000    2666\n3 Brazil      1999   37737\n4 Brazil      2000   80488\n5 China       1999  212258\n6 China       2000  213766\n\n\n[A] = longer, [B] = country, [C] = names_to, [D] = “year” (note “” around year is important here because you are creating a new variable), [E] = values_to, [F] = “cases” (note as with year, “” around cases is important here)\n\nOnce tidy_tab2a has been created you should make the year variable numeric. Replace [G] in the code below to achieve this.\n\n\ntidy_tab2a &lt;- tidy_tab2a %&gt;% mutate(year = as.numeric(year))\n\n[G] = as.numeric\n\nThe data table below includes the population data organized in a tidy format (note: China has an additional year of data):\n\n\ntidy_tab2b\n\n# A tibble: 7 × 3\n  country      year population\n  &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan  1999   19987071\n2 Afghanistan  2000   20595360\n3 Brazil       1999  172006362\n4 Brazil       2000  174504898\n5 China        1999 1272915272\n6 China        2000 1280428583\n7 China        2009 1339125595\n\n\nAssume you want to join tidy_tab2a and tidy_tab2b in order to produce table1. Would you use left_join or right_join? Give a reason for your answer.\n\nleft_join(tidy_tab2a,tidy_tab2b)\n\nJoining with `by = join_by(country, year)`\n\n\n# A tibble: 6 × 4\n  country      year  cases population\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\n\nright_join would include the additional year for China with an NA for the cases data and so would not produce table1."
  },
  {
    "objectID": "index.html#tutorial-sheets",
    "href": "index.html#tutorial-sheets",
    "title": "Welcome to Introduction to Data Science (2)!",
    "section": "Tutorial Sheets",
    "text": "Tutorial Sheets\nTutorial Sheet 1: Tidyverse Recap\nTutorial Sheet 2: Logistic Regression\nTutorial Sheet 3: Observational Studies\nTutorial Sheet 4: Experimental Studies\nTutorial Sheet 5: Predictive Analytics"
  },
  {
    "objectID": "5-experiments.html#randomization",
    "href": "5-experiments.html#randomization",
    "title": "Experimental Studies",
    "section": "Randomization",
    "text": "Randomization\n\nThe key to telling a causal story is the counterfactual: what would have happened in the absence of the treatment.\n\nThis means that establishing the control group is critical because when we do that, we establish the counterfactual.\n\nWhat we hope to be able to do is to find treatment and control groups that are the same, but for the treatment.\n\nWe might be worried about, say, underlying trends, which is one issue with a before-and-after comparison, or selection bias, which could occur when we allow self-selection. Either of these issues could result in biased estimators.\nWe use randomization to go some way to addressing these.\n\n\nTo explore ideas of randomization, we simulate a population, and then randomly sample from it. We will set it up so that 20% of the population are smokers, and the rest are not.\n\nset.seed(853)\n\nnumber_of_people &lt;- 5000\n\npopulation &lt;-\n  tibble(\n    person = c(1:number_of_people),\n    smoking_status = sample(\n      x = c(\"Smoker\", \"Non-Smoker\"),\n      size  = number_of_people,\n      replace = TRUE,\n      prob = c(0.2,0.8)\n    )\n  )\n\nLet’s look at population characteristics\n\npopulation %&gt;% \n  count(smoking_status)\n\n# A tibble: 2 × 2\n  smoking_status     n\n  &lt;chr&gt;          &lt;int&gt;\n1 Non-Smoker      4003\n2 Smoker           997\n\n\nNow let’s sample from the population and randomly assign a treatment and control group.\n\nset.seed(853)\n\nsample_size &lt;- 1000\n\nsample &lt;-\n  population %&gt;% \n  sample_n(sample_size) %&gt;% \n  mutate(group = sample(\n    x = c(\"Treatment\", \"Control\"),\n    size  = sample_size,\n    replace = TRUE\n  ))\n\nNow let’s look at sample characteristics within each group (treatment and control). Is the distribution of population characteristics reflected within each group?\n\nsample %&gt;% \n  count(group,  smoking_status) %&gt;% \n  group_by(group) %&gt;% \n  mutate(prop = n / sum(n)) \n\n# A tibble: 4 × 4\n# Groups:   group [2]\n  group     smoking_status     n  prop\n  &lt;chr&gt;     &lt;chr&gt;          &lt;int&gt; &lt;dbl&gt;\n1 Control   Non-Smoker       364 0.747\n2 Control   Smoker           123 0.253\n3 Treatment Non-Smoker       415 0.809\n4 Treatment Smoker            98 0.191\n\n\n\nInternal validity\n\nIf the treated and control groups are the same in all ways and remain that way, but for the treatment, then we have internal validity, which is to say that our control will work as a counterfactual and our results can speak to a difference between the groups in that study.\nInternal validity means that our estimates of the effect of the treatment are speaking to the treatment and not some other aspect.\nThey mean that we can use our results to make claims about what happened in the experiment.\n\n\n\nExternal validity\n\nIf the group to which we applied our randomization were representative of the broader population, and the experimental set-up were fairly similar to outside conditions, then we further could have external validity.\n\nThat would mean that the difference we find does not just apply in our own experiment, but also in the broader population.\nExternal validity means that we can use our experiment to make claims about what would happen outside the experiment.\nIt is randomization that has allowed that to happen.\n\nBut this means we need randomization twice. Firstly, into the group that was subject to the experiment, and then secondly, between treatment and control."
  },
  {
    "objectID": "5-experiments.html#blocking",
    "href": "5-experiments.html#blocking",
    "title": "Experimental Studies",
    "section": "Blocking",
    "text": "Blocking\n\nOften there are covariates in the experimental units that are known to affect the response variable and must be taken into account.\nIdeally an experimenter can group the experimental units into blocks where the within block variance is small, but the block to block variability is large.\n\nFor example, in testing a drug to prevent heart disease, we know that gender and age also impact the outcome. We may want to partition our study participants into gender and age groups and then randomly assign the treatment (placebo vs drug) within the group.\n\nOften blocking variables are not the variables that we are primarily interested in, but must nevertheless be considered. We call these nuisance variables.\n\n\nBlocking Example\nExample 1. An agricultural field study has three fields in which the researchers will evaluate the quality of three different varieties of barley. Due to how they harvest the barley, we can only create a maximum of three plots in each field. In this example we will block on field since there might be differences in soil type, drainage, etc from field to field. In each field, we will plant all three varieties so that we can tell the difference between varieties without the block effect of field confounding our inference. In this example, the varieties are nested within the fields.\n\n\n# A tibble: 9 × 4\n  Field  Plot Variety Quality\n  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1     1 A       value  \n2     1     2 B       .      \n3     1     3 C       .      \n4     2     1 A       .      \n5     2     2 B       .      \n6     2     3 C       .      \n7     3     1 A       .      \n8     3     2 B       .      \n9     3     3 C       .      \n\n\n\nMain types of blocks\n\nNatural divisions\n\nYoung animals – litters, egg masses\nPeople or animals – gender\nContinuous gradient of change\n\nPlots on the field – declivity, humidity, fertility\nPeople or animals – age, weight, size\nSeverity of disease on the field\n\nExperimental management\n\nLaboratory procedures – technician, day, stand\nMaterial availability\n\n\n\n\n\n\nRandomized Complete Block Design\n\nThe aim is to have heterogeneity between blocks and homogeneity within\n\ne.g. a greenhouse with a temperature gradient, different days, different observers\nBlock is the replicate\nThe number of experimental units per block is equal to the number of treatments and every treatment occurs once in each block, the order of the treatments within a block being randomized\n\n\n\n\n\n\n\nLaboratory chamber with a humidity gradient inside\n\nLaboratory chambers with homogeneous temperature and humidity inside\n\nA field with a fertility gradient\n\nA greenhouse with a temperature gradient during the day\n\nThe dataset oatvar in the faraway library contains information about an experiment on eight different varieties of oats.\n\nThe area in which the experiment was done had some systematic variability and the researchers divided the area up into five different blocks in which they felt the area inside a block was uniform while acknowledging that some blocks are likely superior to others for growing crops.\nWithin each block, the researchers created eight plots and randomly assigned a variety to a plot. This type of design is called a Randomized Complete Block Design (RCBD) because each block contains all possible levels of the factor of primary interest.\n\n\n\nRandomized Complete Block Design - Example\n\ndata('oatvar', package='faraway')\nggplot(oatvar, aes(y=yield, x=block, color=variety)) + \n    geom_point(size=5) +\n    geom_line(aes(x=as.integer(block)))"
  },
  {
    "objectID": "5-experiments.html#factorial-experiments",
    "href": "5-experiments.html#factorial-experiments",
    "title": "Experimental Studies",
    "section": "Factorial Experiments",
    "text": "Factorial Experiments\nExperiments that involve more than one treatment factor are called factorial experiments. In general, the number of treatments in a factorial experiment is the product of the numbers of levels of the treatment factors. The disadvantage of this is that the number of treatments increase very quickly.\nExample: Pest control\n\nFactor 1: two pesticides (A and B)\nFactor 2: two doses\nThe experiment has a total of \\(2\\times 2 = 4\\) treatments\n\nExample: The Tooth Growth data\n\nFactor 1: two deliveries of vitamin C (orange juice, ascorbic acid)\nFactor 2: three doses (0.5, 1, and 2 mg/day)\nThe experiment has a total of \\(2\\times 3 = 6\\) treatments\n\n\n\n\n\nDesigns\nFor the Pesticide example, suppose 3 replicates and a completely randomized design\n\nFor the Pesticide example, suppose 3 replicates and a randomized complete block design\n\n\n\nInteractions\nThe major advantage of factorial experiments is that they allow for the detection of interactions.\n\nTwo factors are said to interact if the effect of one, on the response variable, depends upon the level of the other.\nIf they do not interact, they are said to be independent.\n\n\nInteraction Plots\nA set of parallel lines indicates no interaction\n\nThe crossing over of lines indicates an interaction"
  },
  {
    "objectID": "5-experiments.html#principles-of-experimental-design",
    "href": "5-experiments.html#principles-of-experimental-design",
    "title": "Experimental Studies",
    "section": "Principles of Experimental Design",
    "text": "Principles of Experimental Design\nControlling. Researchers assign treatments to cases, and they do their best to control any other differences in the groups.\nRandomization. Researchers randomize patients into treatment groups to account for variables that cannot be controlled. For example, some patients may be more susceptible to a disease than others due to their dietary habits. In this example dietary habit is a confounding variable, which is defined as a variable that is associated with both the explanatory and response variables. Randomizing patients into the treatment or control group helps even out such differences.\n\nConfounding variables\nConfounding variables: Extraneous variables that affect both the exposure and the outcome variables, and that make it seem like there is a relationship between them are called confounding variables.\n\nReplication. The more cases researchers observe, the more accurately they can estimate the effect of the explanatory variable on the response. In a single study, we replicate by collecting a sufficiently large sample. What is considered sufficiently large varies from experiment to experiment, but at a minimum we want to have multiple subjects (experimental units) per treatment group.\nBlocking. Researchers sometimes know or suspect that variables, other than the treatment, influence the response. Under these circumstances, they may first group individuals based on this variable into blocks and then randomize cases within each block to the treatment groups. This strategy is often referred to as blocking. For instance, if we are looking at the effect of a drug on heart attacks, we might first split patients in the study into low-risk and high-risk blocks, then randomly assign half the patients from each block to the control group and the other half to the treatment group. This strategy ensures that each treatment group has the same number of low-risk patients and the same number of high-risk patients."
  },
  {
    "objectID": "5-experiments.html#more-on-randomization",
    "href": "5-experiments.html#more-on-randomization",
    "title": "Experimental Studies",
    "section": "More on Randomization",
    "text": "More on Randomization\nThe key to telling a causal story is the counterfactual: what would have happened in the absence of the treatment. This means that establishing the control group is critical because when we do that, we establish the counterfactual. What we hope to be able to do is to find treatment and control groups that are the same, but for the treatment.\n\nWe might be worried about, say, underlying trends, which is one issue with a before-and-after comparison, or selection bias, which could occur when we allow self-selection. Either of these issues could result in biased estimators.\nWe use randomization to go some way to addressing these.\n\nTo explore ideas of randomization, we simulate a population, and then randomly sample from it. We will set it up so that 20% of the population are smokers, and the rest are not.\n\nset.seed(853)\n\nnumber_of_people &lt;- 5000\n\npopulation &lt;-\n  tibble(\n    person = c(1:number_of_people),\n    smoking_status = sample(\n      x = c(\"Smoker\", \"Non-Smoker\"),\n      size  = number_of_people,\n      replace = TRUE,\n      prob = c(0.2,0.8)\n    )\n  )\n\nLet’s look at population characteristics\n\npopulation %&gt;% \n  count(smoking_status)\n\n# A tibble: 2 × 2\n  smoking_status     n\n  &lt;chr&gt;          &lt;int&gt;\n1 Non-Smoker      4003\n2 Smoker           997\n\n\nNow let’s sample from the population and randomly assign a treatment and control group.\n\nset.seed(853)\n\nsample_size &lt;- 1000\n\nsample &lt;-\n  population %&gt;% \n  sample_n(sample_size) %&gt;% \n  mutate(group = sample(\n    x = c(\"Treatment\", \"Control\"),\n    size  = sample_size,\n    replace = TRUE\n  ))\n\nNow let’s look at sample characteristics within each group (treatment and control). Is the distribution of population characteristics reflected within each group?\n\nsample %&gt;% \n  count(group,  smoking_status) %&gt;% \n  group_by(group) %&gt;% \n  mutate(prop = n / sum(n)) \n\n# A tibble: 4 × 4\n# Groups:   group [2]\n  group     smoking_status     n  prop\n  &lt;chr&gt;     &lt;chr&gt;          &lt;int&gt; &lt;dbl&gt;\n1 Control   Non-Smoker       364 0.747\n2 Control   Smoker           123 0.253\n3 Treatment Non-Smoker       415 0.809\n4 Treatment Smoker            98 0.191\n\n\n\n\nInternal Validity\n\nInternal validity is achieved when the only difference between the treatment and control groups is the treatment itself.\n\nThis ensures that the control group serves as a true counterfactual, allowing us to attribute differences in outcomes solely to the treatment.\n\nIn other words, our estimates reflect the true effect of the treatment rather than other confounding factors.\n\nWith strong internal validity, we can confidently make claims about causal relationships within the experiment.\n\n\n\nExternal Validity\n\nExternal validity refers to whether our experimental findings generalize beyond the study.\n\nThis requires:\n\nA sample that represents the broader population.\n\nAn experimental setup that mirrors real-world conditions.\n\n\nIf these conditions hold, our results are applicable outside the experiment.\n\nRandomization is key to achieving external validity:\n\nFirst, random selection ensures that the study group is representative.\n\nSecond, random assignment to treatment and control ensures comparability within the experiment.\n\n\n\n\n\nExample: Tooth Growth\nToothGrowth is a built-in R dataset from a study that examined the effect of Vitamin C dose and delivery on the length of the odontoplasts, the cells responsible for teeth growth, in 60 guinea pigs, where tooth length was the measured outcome variable.\n\nRandomization\nRandomization of subjects in an experiment helps spread any variability that exists naturally between subjects evenly across groups.\nIn the experiment that yielded the ToothGrowth dataset, guinea pigs were randomized to receive Vitamin C either through orange juice or ascorbic acid, indicated in the dataset by the supp variable.\n\ndata(\"ToothGrowth\")\n\n\n\nReplication\nReplication means you need to conduct an experiment with an adequate number of subjects to achieve an acceptable statistical power.\nLet’s examine the ToothGrowth dataset to make sure they followed the principle of replication. We’ll use a dplyr function called count to help us.\n\nToothGrowth %&gt;% count(supp)\n\n  supp  n\n1   OJ 30\n2   VC 30\n\n\n\n\nAnalysis\nSuppose you know from previous studies that the average length of a guinea pigs odontoplasts is 18 micrometers. Therefore, you hypothesize that odontoplast length is equal to 18. To “test” this hypothesis, let’s see how the value of 18 compares to our sample data by looking at the mean and standard deviation.\n\nToothGrowth %&gt;% pull(len) %&gt;% mean\n\n[1] 18.81333\n\n\nIt’s natural to wonder if there is a difference in tooth length by supplement type. Use group_by and summarise to explore this and create an appropriate visualization using ggplot.\n\nToothGrowth %&gt;%"
  },
  {
    "objectID": "5-experiments.html#more-on-blocking",
    "href": "5-experiments.html#more-on-blocking",
    "title": "Experimental Studies",
    "section": "More on Blocking",
    "text": "More on Blocking\nOften there are covariates in the experimental units that are known to affect the response variable and must be taken into account. Ideally an experimenter can group the experimental units into blocks where the within block variance is small, but the block to block variability is large.\n\nFor example, in testing a drug to prevent heart disease, we know that gender and age also impact the outcome. We may want to partition our study participants into gender and age groups and then randomly assign the treatment (placebo vs drug) within the group.\n\nOften blocking variables are not the variables that we are primarily interested in, but must nevertheless be considered.\n\nRandomized Complete Block Design (RCBD)\n\nThe goal of RCBD is to maximize differences between blocks while ensuring similarity within each block.\n\nThis design helps control for known sources of variability, such as:\n\nTemperature differences within a greenhouse.\n\nVariation across different days.\n\nVariation in fertility or drainage differences in a field\n\n\nKey features:\n\nEach block acts as a replicate.\n\nThe number of experimental units per block equals the number of treatments.\n\nEach treatment appears exactly once per block, with the order randomized within the block.\n\n\n\n\n\n\n\n\nExamples of blocks\n\nLaboratory chamber with a humidity gradient inside\n\n\n\nLaboratory chambers with homogeneous temperature and humidity inside\n\n\n\nA field with a fertility gradient\n\n\n\nA greenhouse with a temperature gradient during the day\n\n\n\n\n\nExample: Oatvar\nThe dataset oatvar in the faraway library contains information about an experiment on eight different varieties of oats.\n\nThe area in which the experiment was done had some systematic variability and the researchers divided the area up into five different blocks in which they felt the area inside a block was uniform while acknowledging that some blocks are likely superior to others for growing crops.\nWithin each block, the researchers created eight plots and randomly assigned a variety to a plot. This type of design is called a Randomized Complete Block Design (RCBD) because each block contains all possible levels of the factor of primary interest.\n\nVisualise the data\n\nggplot(oatvar, aes(y=yield, x=block, color=variety)) + \n    geom_point(size=5) +\n    geom_line(aes(x=as.integer(block)))\n\n\n\n\n\n\n\n\nUse group_by and summarise to look at the average yield within each variety.\n\noatvar %&gt;% \n\nLook at the results of using lm with variety and block as predictors.\n\nlm(....)"
  },
  {
    "objectID": "5-experiments.html#factorial-experiments-tooth-growth",
    "href": "5-experiments.html#factorial-experiments-tooth-growth",
    "title": "Experimental Studies",
    "section": "Factorial Experiments: Tooth Growth",
    "text": "Factorial Experiments: Tooth Growth\nWe’ve already seen to Tooth Growth data that examined the effect of Vitamin C delivery and dose on the length of the odontoplasts, the cells responsible for teeth growth, in 60 guinea pigs, where tooth length was the measured outcome variable.\nWe initially looked at how the Vitamin C delivery impacted tooth growth. Now lets consider what happens when we bring dose into the analysis. In this case we have two factors to consider instead of 1.\n\nVitamin C delivery has 2 levels\ndose has 3 levels (0.5, 1, and 2 mg/day)\n\n\ndata(\"ToothGrowth\")"
  },
  {
    "objectID": "4-sampling.html#research-questions",
    "href": "4-sampling.html#research-questions",
    "title": "Sampling Principles and Strategies",
    "section": "Research Question(s)",
    "text": "Research Question(s)\nResearch Question: Over the last 5 years, how many MU Data Science or Statistics graduates have gone on to get a job in a field directly related to their degree.\nPopulation: All DS or Statistics graduates from MU from the last 5 years.\nQ. Can we survey the entire population?\nA. This would likely be very difficult. It is more realistic to assume that we can work with a fraction of the population.\nQ. How can we ensure the sample is an accurate reflection of the population?\nA. Appropriate sampling.\nOnce we have an appropriate sample, most research questions actually break down into 2 parts:\n\nDescriptive Statistics: What relationship can we observe between the variables in the sample?\nInferential Statistics: Supposing we see a relationship in the sample data, how much evidence is provided for a relationship in the population? Does the data provide lots of evidence for a relationship in the population, or could the relationship we see in the sample be due just to chance variation in the sampling process that gave us the data?\n\n\nAnecdotal Evidence\n“I met two students who did a Data Science degree in Maynooth but they are not working as data scientists. The degree must not get you a Data Science job.”\nThere are two problems here. First, the data only represent two cases. Second, and more importantly, it is unclear whether these cases are actually representative of the population. Data collected in this haphazard fashion only provides anecdotal evidence."
  },
  {
    "objectID": "ObservationalStudies.html#observational-study",
    "href": "ObservationalStudies.html#observational-study",
    "title": "Observational Studies",
    "section": "",
    "text": "Observational Study: A study which observes individuals and measures variables, but does not attempt to influence the responses.\n\nAn observational study on individuals from a random sample allows one to generalize conclusions about the sample to the population.\nAn observational study cannot show cause-and-effect relationships because there is the possibility that the response is affected by some variable(s) other than the ones being measured. That is, confounding variables may be present. “It ain’t what you don’t know that gets you into trouble. It’s what you know for sure that just ain’t so.” - Mark Twain\nIn prospective observational studies, investigators choose a sample and collect new data generated from that sample. That is, the investigators “look forward in time.”\nIn retrospective observational studies, investigators “look backwards in time” and use data that have already been collected. Retrospective studies are often criticized for having more confounding and bias compared to prospective studies."
  },
  {
    "objectID": "Tutorial2.html",
    "href": "Tutorial2.html",
    "title": "DS152 Tutorial Sheet 2",
    "section": "",
    "text": "Attempt the questions below before your tutorial in the week beginning 3rd March 2025."
  },
  {
    "objectID": "Tutorial2.html#instructions",
    "href": "Tutorial2.html#instructions",
    "title": "DS152 Tutorial Sheet 2",
    "section": "",
    "text": "Attempt the questions below before your tutorial in the week beginning 3rd March 2025."
  },
  {
    "objectID": "Tutorial2.html#exercise-1",
    "href": "Tutorial2.html#exercise-1",
    "title": "DS152 Tutorial Sheet 2",
    "section": "Exercise 1",
    "text": "Exercise 1\nRun the code below to read a dataset called car_evaluation into R. Look at the data and the variables that you have to work with. More details about the data are given below.\n\nlibrary(tidyverse)\ncar_evaluation &lt;- read_csv(\"https://www.dropbox.com/s/s54upw5jhoe6r4q/car_evaluation.csv?raw=1\")\n\nThere are 1594 cars in this database that are classified as acceptable (acc) or unacceptable (unacc) according to the following attributes:\n\nbuying_price: buying price (low, medium, high, vhigh)\nmaintenance_cost: (“vhigh”, “high”, “med”, “low”)\ndoors: (“2”,“3”,“4”,“5more”)\npersons: capacity in terms of persons to carry (2,4,more)\nlugboot: the size of luggage boot (small, med, big)\nsafety: estimated safety of the car (low, med, high)\n\n(a) Use the code below to create a bar plot that shows the number of observations within each buying_price category. What do you learn from this visualisation?\n\nggplot(car_evaluation, aes(x = buying_price)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\nNow add fill = decision to the aes() of the plot. What do you learn from this visualisation?\nNext facet using the safety variable. What do you learn from this visualisation?\n\n(b) Run the following code which aims to fit a logistic regression model using buying_price and safety as predictor variables for the decision. This code will give you an error. What is causing the error?\n\nfit_logistic &lt;- glm(decision ~ buying_price + safety, family = \"binomial\", data = car_evaluation)\nfit_logistic\n\n(c) Complete the code below to create a variable in the dataset called decision_binary with “acc” as the reference group.\n\ncar_evaluation &lt;- car_evaluation %&gt;%\n  mutate(decision_binary = ??)\n\n\nNow run the logistic regression with decision_binary as the outcome. Does this give you an error? What do you note about the coefficients?\n\n\nfit_logistic &lt;- glm(??)\nfit_logistic\n\n\nOnce you have fit the model, run the following code to obtain the accuracy of the decision classification. (Note: The code is similar to the code you used in Lab 3 but here we use summarise when doing the calculation for percentage_correct). Change to eval = TRUE when you are ready to run this code. Did your model do a good job?\n\n\nthreshold &lt;- 0.5\n\ncar_predict &lt;- car_evaluation %&gt;%\n                   mutate(p_hat = predict(fit_logistic, type = \"response\") %&gt;% round(2),\n                          type_pred = ifelse(p_hat &gt;= threshold, 1,0))\n \ncar_predict %&gt;% summarise(n_correct = sum(type_pred == decision_binary),\n                          n_total = n(),\n                          percentage_correct = n_correct*100/n_total)\n\n\nNow use group_by to breakdown the accuracy results by decision category (Note: because we set up the code using summarise it’s easy to add group_by() in here and get the breakdown within each decision group). Change to eval = TRUE when you are ready to run this code. What do you learn from these results?\n\n\ncar_predict %&gt;% group_by(decision) %&gt;% \n                summarise(n_correct = sum(type_pred == decision_binary),\n                          n_total = n(),\n                          percentage_correct = n_correct*100/n_total)"
  },
  {
    "objectID": "Tutorial2.html#exercise",
    "href": "Tutorial2.html#exercise",
    "title": "DS152 Tutorial Sheet 2",
    "section": "Exercise",
    "text": "Exercise\nRun the code below to read a dataset called car_evaluation into R. Look at the data and the variables that you have to work with. More details about the data are given below.\n\nlibrary(tidyverse)\ncar_evaluation &lt;- read_csv(\"https://www.dropbox.com/s/s54upw5jhoe6r4q/car_evaluation.csv?raw=1\")\n\nThere are 1594 cars in this database that are classified as acceptable (acc) or unacceptable (unacc) according to the following attributes:\n\nbuying_price: buying price (low, medium, high, vhigh)\nmaintenance_cost: (“vhigh”, “high”, “med”, “low”)\ndoors: (“2”,“3”,“4”,“5more”)\npersons: capacity in terms of persons to carry (2,4,more)\nlugboot: the size of luggage boot (small, med, big)\nsafety: estimated safety of the car (low, med, high)\n\n(a) Complete the code below to create a bar plot that shows the number of observations within each buying_price category. What do you learn from this visualisation?\n\nggplot(car_evaluation, aes(??)) +\n  geom_??\n\n\nNow add fill = decision to the aes() of the plot. What do you learn from this visualisation?\nNext facet using the safety variable. What do you learn from this visualisation?\n\n(b) Run the following code which aims to fit a logistic regression model using buying_price and safety as predictor variables for the decision. This code will give you an error. What is causing the error?\n\nfit_logistic &lt;- glm(decision ~ buying_price + safety, \n                    family = \"binomial\", \n                    data = car_evaluation)\nfit_logistic\n\n(c) Complete the code below to create a variable in the dataset called decision_binary with “acc” as the reference group (there’s an example of this in your lecture notes).\n\ncar_evaluation &lt;- car_evaluation %&gt;%\n  mutate(decision_binary = ??)\n\n\nNow complete the code below to run the logistic regression with decision_binary as the outcome. Does this give you an error? What do you note about the coefficients?\n\n\nfit_logistic &lt;- glm(??)\nfit_logistic\n\n\nOnce you have fit the model, run the following code to obtain the accuracy of the decision classification. (Note: The code is similar to the code you used in Lab 3 but here we use summarise when doing the calculation for percentage_correct). Change to eval = TRUE when you are ready to run this code. Did your model do a good job?\n\n\nthreshold &lt;- 0.5\n\ncar_predict &lt;- car_evaluation %&gt;%\n                   mutate(p_hat = predict(fit_logistic, type = \"response\") %&gt;% round(2),\n                          type_pred = ifelse(p_hat &gt;= threshold, 1,0))\n \naccuracy_results &lt;- car_predict %&gt;% summarise(n_correct = sum(type_pred == decision_binary),\n                                              n_total = n(),\n                                              percentage_correct = n_correct*100/n_total)\naccuracy_results\n\n\nNow modify the summary code above to add a group_by function that will breakdown the accuracy results by decision category. Change to eval = TRUE when you are ready to run this code. What do you learn from these results?\n\n\naccuracy_results &lt;- car_predict %&gt;%"
  },
  {
    "objectID": "Tutorial2_soln.html",
    "href": "Tutorial2_soln.html",
    "title": "DS152 Tutorial Sheet 2 with Solutions",
    "section": "",
    "text": "Run the code below to read a dataset called car_evaluation into R.\n\nlibrary(tidyverse)\ncar_evaluation &lt;- read_csv(\"https://www.dropbox.com/s/s54upw5jhoe6r4q/car_evaluation.csv?raw=1\")\n\nThere are 1594 cars in this database that are classified as acceptable (acc) or unacceptable (unacc) according to the following attributes:\n\nbuying_price: buying price (low, medium, high, vhigh)\nmaintenance_cost: (“vhigh”, “high”, “med”, “low”)\ndoors: (“2”,“3”,“4”,“5more”)\npersons: capacity in terms of persons to carry (2,4,more)\nlugboot: the size of luggage boot (small, med, big)\nsafety: estimated safety of the car (low, med, high)\n\n(a) Complete the code below to create a bar plot that shows the number of observations within each buying_price category. What do you learn from this visualisation?\n\nggplot(car_evaluation, aes(x = buying_price)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nNote for Tutors: Key thing to mention here is that this plot clearly shows that there’s differences in counts within each buying price category.\n\nNow add fill = decision to the aes() of the plot. What do you learn from this visualisation?\n\n\nggplot(car_evaluation, aes(x = buying_price, fill = decision)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nNote for Tutors: Key thing to mention here is that the majority of the decisions are “unacceptable” but the proportion of “acceptable” seems to be lowest in the very high buying category. So, perhaps the buying price can be of some use as a predictor of the decision.\n\nNow facet using the safety variable. What do you learn from this visualisation?\n\n\nggplot(car_evaluation, aes(x = buying_price, fill = decision)) +\n  geom_bar() +\n  facet_wrap(~safety)\n\n\n\n\n\n\n\n\nNote for Tutors: Key things to mention here is that low safety results in a decision of “unacceptable”. Also having “high” safety seems to increase the proportion of “acceptable” in the “high” and “very high” buying categories, relative to medium safety. So perhaps both variables together would be useful as predictors of the decision.\n(b) Run the following code which aims to fit a logistic regression model using buying_price and safety as predictor variables for the decision. This code will give you an error. What is causing the error?\n\nfit_logistic &lt;- glm(decision ~ buying_price + safety, family = \"binomial\", data = car_evaluation)\nfit_logistic\n\nNote for Tutors: The problem was not having the decision variable as binary.\n(c) Complete the code below to create a variable in the dataset called decision_binary with “acc” as the reference group (there’s an example of this in your lecture notes).\n\ncar_evaluation &lt;- car_evaluation %&gt;%\n  mutate(decision_binary = as.numeric(decision == \"acc\"))\n\nNote for Tutors: This means that “acc” will be 1 and “unacc” will be 0.\n\nNow complete the code below to run the logistic regression with decision_binary as the outcome. Does this give you an error? What do you note about the coefficients?\n\n\nfit_logistic &lt;- glm(decision_binary ~ buying_price + safety, family = \"binomial\", data = car_evaluation)\nfit_logistic\n\n\nCall:  glm(formula = decision_binary ~ buying_price + safety, family = \"binomial\", \n    data = car_evaluation)\n\nCoefficients:\n      (Intercept)    buying_pricelow    buying_pricemed  buying_pricevhigh  \n          -0.2998             0.3018             0.4615            -0.5937  \n        safetylow          safetymed  \n         -19.3525            -0.4338  \n\nDegrees of Freedom: 1593 Total (i.e. Null);  1588 Residual\nNull Deviance:      1760 \nResidual Deviance: 1304     AIC: 1316\n\n\nNote for Tutors: Just give a broad overview of results here (i.e., don’t get into exponential transformations etc). Reminder that “acc” has been chosen is the reference group for the outcome. Mention that all the predictors are categorical and so a “reference” category is also chosen for each predictor. For the buying_price the reference group is “high”. So based on the output, moving from “high” buying price to the “low” buying price will increase the chance (technically speaking the log odds but don’t get wrapped up in that) off an “acceptable” decision (although the coefficient is small). Whereas, moving from the high buying price to the very high buy price will decrease the chance of an “acceptable” decision (but again the coefficient is small). Similarly, the reference category for the safety predictor is “high”. Results show that moving from “high” safety to “low” safety decreases the chance of an “acceptable” decision (large coefficient here). Moving from high to medium does not have as big of an impact (small coefficient).\n\nOnce you have fit the model, run the following code to obtain the accuracy of the decision classification. (Note: The code is similar to the code you used in Lab 3 but here we use summarise when doing the calculation for percentage_correct). Change to eval = TRUE when you are ready to run this code. Did your model do a good job?\n\n\nthreshold &lt;- 0.5\n\ncar_predict &lt;- car_evaluation %&gt;%\n                   mutate(p_hat = predict(fit_logistic, type = \"response\") %&gt;% round(2),\n                          type_pred = ifelse(p_hat &gt;= threshold, 1,0))\n \naccuracy_results &lt;- car_predict %&gt;% summarise(n_correct = sum(type_pred == decision_binary),\n                                              n_total = n(),\n                                              percentage_correct = n_correct*100/n_total)\naccuracy_results\n\n# A tibble: 1 × 3\n  n_correct n_total percentage_correct\n      &lt;int&gt;   &lt;int&gt;              &lt;dbl&gt;\n1      1195    1594               75.0\n\n\nNote for Tutors: Just talk through what summarise is doing here and note the accuracy.\n\nNow modify the summary code above to add a group_by function that will breakdown the accuracy results by decision category. Change to eval = TRUE when you are ready to run this code. What do you learn from these results?\n\n\naccuracy_results &lt;-car_predict %&gt;% \n                      group_by(decision) %&gt;% \n                      summarise(n_correct = sum(type_pred ==decision_binary),\n                                n_total = n(),\n                                percentage_correct = n_correct*100/n_total)\naccuracy_results\n\n# A tibble: 2 × 4\n  decision n_correct n_total percentage_correct\n  &lt;chr&gt;        &lt;int&gt;   &lt;int&gt;              &lt;dbl&gt;\n1 acc             89     384               23.2\n2 unacc         1106    1210               91.4\n\n\nNote for Tutors: Just talk through what the addition of group_by achieves and then explain that the accuracy is much better in the “unacceptable” group. Note to students that this happens because of the imbalance in the dataset (much higher proportion of “unacceptable” in the dataset) which was noted in one of the plots earlier."
  },
  {
    "objectID": "Tutorial2_soln.html#exercise",
    "href": "Tutorial2_soln.html#exercise",
    "title": "DS152 Tutorial Sheet 2 with Solutions",
    "section": "",
    "text": "Run the code below to read a dataset called car_evaluation into R.\n\nlibrary(tidyverse)\ncar_evaluation &lt;- read_csv(\"https://www.dropbox.com/s/s54upw5jhoe6r4q/car_evaluation.csv?raw=1\")\n\nThere are 1594 cars in this database that are classified as acceptable (acc) or unacceptable (unacc) according to the following attributes:\n\nbuying_price: buying price (low, medium, high, vhigh)\nmaintenance_cost: (“vhigh”, “high”, “med”, “low”)\ndoors: (“2”,“3”,“4”,“5more”)\npersons: capacity in terms of persons to carry (2,4,more)\nlugboot: the size of luggage boot (small, med, big)\nsafety: estimated safety of the car (low, med, high)\n\n(a) Complete the code below to create a bar plot that shows the number of observations within each buying_price category. What do you learn from this visualisation?\n\nggplot(car_evaluation, aes(x = buying_price)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nNote for Tutors: Key thing to mention here is that this plot clearly shows that there’s differences in counts within each buying price category.\n\nNow add fill = decision to the aes() of the plot. What do you learn from this visualisation?\n\n\nggplot(car_evaluation, aes(x = buying_price, fill = decision)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nNote for Tutors: Key thing to mention here is that the majority of the decisions are “unacceptable” but the proportion of “acceptable” seems to be lowest in the very high buying category. So, perhaps the buying price can be of some use as a predictor of the decision.\n\nNow facet using the safety variable. What do you learn from this visualisation?\n\n\nggplot(car_evaluation, aes(x = buying_price, fill = decision)) +\n  geom_bar() +\n  facet_wrap(~safety)\n\n\n\n\n\n\n\n\nNote for Tutors: Key things to mention here is that low safety results in a decision of “unacceptable”. Also having “high” safety seems to increase the proportion of “acceptable” in the “high” and “very high” buying categories, relative to medium safety. So perhaps both variables together would be useful as predictors of the decision.\n(b) Run the following code which aims to fit a logistic regression model using buying_price and safety as predictor variables for the decision. This code will give you an error. What is causing the error?\n\nfit_logistic &lt;- glm(decision ~ buying_price + safety, family = \"binomial\", data = car_evaluation)\nfit_logistic\n\nNote for Tutors: The problem was not having the decision variable as binary.\n(c) Complete the code below to create a variable in the dataset called decision_binary with “acc” as the reference group (there’s an example of this in your lecture notes).\n\ncar_evaluation &lt;- car_evaluation %&gt;%\n  mutate(decision_binary = as.numeric(decision == \"acc\"))\n\nNote for Tutors: This means that “acc” will be 1 and “unacc” will be 0.\n\nNow complete the code below to run the logistic regression with decision_binary as the outcome. Does this give you an error? What do you note about the coefficients?\n\n\nfit_logistic &lt;- glm(decision_binary ~ buying_price + safety, family = \"binomial\", data = car_evaluation)\nfit_logistic\n\n\nCall:  glm(formula = decision_binary ~ buying_price + safety, family = \"binomial\", \n    data = car_evaluation)\n\nCoefficients:\n      (Intercept)    buying_pricelow    buying_pricemed  buying_pricevhigh  \n          -0.2998             0.3018             0.4615            -0.5937  \n        safetylow          safetymed  \n         -19.3525            -0.4338  \n\nDegrees of Freedom: 1593 Total (i.e. Null);  1588 Residual\nNull Deviance:      1760 \nResidual Deviance: 1304     AIC: 1316\n\n\nNote for Tutors: Just give a broad overview of results here (i.e., don’t get into exponential transformations etc). Reminder that “acc” has been chosen is the reference group for the outcome. Mention that all the predictors are categorical and so a “reference” category is also chosen for each predictor. For the buying_price the reference group is “high”. So based on the output, moving from “high” buying price to the “low” buying price will increase the chance (technically speaking the log odds but don’t get wrapped up in that) off an “acceptable” decision (although the coefficient is small). Whereas, moving from the high buying price to the very high buy price will decrease the chance of an “acceptable” decision (but again the coefficient is small). Similarly, the reference category for the safety predictor is “high”. Results show that moving from “high” safety to “low” safety decreases the chance of an “acceptable” decision (large coefficient here). Moving from high to medium does not have as big of an impact (small coefficient).\n\nOnce you have fit the model, run the following code to obtain the accuracy of the decision classification. (Note: The code is similar to the code you used in Lab 3 but here we use summarise when doing the calculation for percentage_correct). Change to eval = TRUE when you are ready to run this code. Did your model do a good job?\n\n\nthreshold &lt;- 0.5\n\ncar_predict &lt;- car_evaluation %&gt;%\n                   mutate(p_hat = predict(fit_logistic, type = \"response\") %&gt;% round(2),\n                          type_pred = ifelse(p_hat &gt;= threshold, 1,0))\n \naccuracy_results &lt;- car_predict %&gt;% summarise(n_correct = sum(type_pred == decision_binary),\n                                              n_total = n(),\n                                              percentage_correct = n_correct*100/n_total)\naccuracy_results\n\n# A tibble: 1 × 3\n  n_correct n_total percentage_correct\n      &lt;int&gt;   &lt;int&gt;              &lt;dbl&gt;\n1      1195    1594               75.0\n\n\nNote for Tutors: Just talk through what summarise is doing here and note the accuracy.\n\nNow modify the summary code above to add a group_by function that will breakdown the accuracy results by decision category. Change to eval = TRUE when you are ready to run this code. What do you learn from these results?\n\n\naccuracy_results &lt;-car_predict %&gt;% \n                      group_by(decision) %&gt;% \n                      summarise(n_correct = sum(type_pred ==decision_binary),\n                                n_total = n(),\n                                percentage_correct = n_correct*100/n_total)\naccuracy_results\n\n# A tibble: 2 × 4\n  decision n_correct n_total percentage_correct\n  &lt;chr&gt;        &lt;int&gt;   &lt;int&gt;              &lt;dbl&gt;\n1 acc             89     384               23.2\n2 unacc         1106    1210               91.4\n\n\nNote for Tutors: Just talk through what the addition of group_by achieves and then explain that the accuracy is much better in the “unacceptable” group. Note to students that this happens because of the imbalance in the dataset (much higher proportion of “unacceptable” in the dataset) which was noted in one of the plots earlier."
  },
  {
    "objectID": "ObservationalStudies.html#example-1-student-happiness",
    "href": "ObservationalStudies.html#example-1-student-happiness",
    "title": "Observational Studies",
    "section": "Example 1: Student Happiness",
    "text": "Example 1: Student Happiness\nThe gcfeeling data contains results of a survey conducted by Georgetown College students on 47 Georgetown College upper-class students in relation to feelings about Georgetown College.\n\n# Load necessary packages\nlibrary(tidyverse)\nlibrary(tigerstats)\n\n# Load the dataset\ndata(\"gcfeeling\")\n\n# View basic structure\nglimpse(gcfeeling)\n\nRows: 47\nColumns: 6\n$ rating.fresh &lt;int&gt; 9, 8, 5, 5, 8, 7, 9, 9, 7, 9, 8, 10, 8, 8, 9, 9, 6, 10, 1…\n$ rating.js    &lt;int&gt; 7, 10, 8, 8, 10, 9, 9, 8, 8, 8, 8, 10, 8, 10, 9, 7, 7, 10…\n$ greek        &lt;fct&gt; y, n, y, n, n, y, y, y, y, y, n, n, n, n, n, n, n, y, n, …\n$ athlete      &lt;fct&gt; n, n, n, n, n, n, n, n, n, n, n, n, n, n, n, n, n, y, y, …\n$ rating.diff  &lt;int&gt; -2, 2, 3, 3, 2, 2, 0, -1, 1, -1, 0, 0, 0, 2, 0, -2, 1, 0,…\n$ happier      &lt;fct&gt; NO, YES, YES, YES, YES, YES, YES, NO, YES, NO, YES, YES, …\n\n\n\n1. Exploring Categorical Variables\ngcfeeling contains categorical variables. We can visualize their distributions:\n\n# Count and visualize categorical variables\ngcfeeling %&gt;%\n  select_if(is.factor) %&gt;% \n  pivot_longer(everything(),names_to = \"Variable\", values_to = \"Value\") %&gt;%\n  ggplot(aes(x = Value)) +\n  geom_bar() +\n  facet_wrap(~ Variable, scales = \"free\") +\n  theme_minimal() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n2. Exploring Numeric Variables\ngcfeeling contains numeric variables. We can visualize their distributions:\n\n# Check numeric variable distributions\ngcfeeling %&gt;%\n  select_if(is.numeric) %&gt;%\n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"Value\") %&gt;%\n  ggplot(aes(x = Variable,y = Value)) +\n  geom_boxplot() +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n3. Relationships Between Variables\n\nContingency Table (For Categorical Variables)\nA contingency table shows the relationship between two categorical variables by displaying their frequency distribution.\n\ngcfeeling %&gt;%\n  select(happier, athlete) %&gt;% \n  table()\n\n       athlete\nhappier  n  y\n    NO  10  1\n    YES 25 11\n\n\n\n\nPairwise Correlation (For Numeric Variables)\n\n# Compute correlation matrix\ncor(gcfeeling$rating.fresh, gcfeeling$rating.js)\n\n[1] 0.402741\n\n\n\n\nScatterplots (For Numeric Variables)\n\nggplot(gcfeeling, aes(x = rating.fresh, y = rating.js)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\nBoxplots of Numerical Variables by Categories\n\n# Boxplots grouped by a categorical variable (assuming `groupvar` is categorical)\ngcfeeling %&gt;%\n  ggplot(aes(x = athlete, y = rating.js)) +\n  geom_boxplot() +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n4. Modelling\nWe can use multiple regression to model student happiness.\n\nlm(rating.js ~ rating.fresh + athlete + greek, data = gcfeeling)\n\n\nCall:\nlm(formula = rating.js ~ rating.fresh + athlete + greek, data = gcfeeling)\n\nCoefficients:\n (Intercept)  rating.fresh      athletey        greeky  \n      5.0287        0.3277        0.7594        0.8272"
  },
  {
    "objectID": "ObservationalStudies.html#example-2-does-working-out-increase-energy-levels",
    "href": "ObservationalStudies.html#example-2-does-working-out-increase-energy-levels",
    "title": "Observational Studies",
    "section": "Example 2: Does working out increase energy levels?",
    "text": "Example 2: Does working out increase energy levels?\nWe want to evaluate if regularly working out has any impact on energy levels.\n\nIn an observational study, we sample two types of people from the population, those who choose to work out regularly and those who don’t.\nWe ask the people in each group to rate their energy levels from 1-10.\nThen, we find the average “energy level” for the two groups of people and compare.\n\n\nCan we conclude from this that working out is the cause of increased energy levels?\n\nThere may be other variables that we didn’t control for in this study that contribute to the observed difference.\nFor example, people who have young children might have less time to work out and also have lower energy levels.\nThis is known as confounding.\nThis study allows us to make correlation statements. But, we cannot make a causal statement attributing increased energy levels to working out!\n\n\nConfounding variables\nConfounding variables: Extraneous variables that affect both the exposure (e.g., working out) and the outcome variables (e.g., increased energy), and that make it seem like there is a relationship between them are called confounding variables."
  },
  {
    "objectID": "ObservationalStudies.html#example-3",
    "href": "ObservationalStudies.html#example-3",
    "title": "Observational Studies",
    "section": "Example 3",
    "text": "Example 3\nMany years ago, investigators reported an association between coffee drinking and pancreatic cancer in an observational study (MacMahon B, Yen S, Trichopoulos D, Warren K, Nardi G. Coffee and cancer of the pancreas. N Eng J Med 1981; 304: 630-3).\n\nIf we take coffee as our exposure of interest and correlate it with an increased development of pancreatic cancer there is the potential, as was the case with these investigators, to be misled if there is a third causal factor, such as cigarette smoking, that was more common among those who reported drinking coffee.\n\nOnce the confounding variable, smoking is taken into account the correlation between coffee and pancreatic cancer disappears.\n\nReducing confounding: Matching\nMatching is a technique that involves selecting study participants with similar characteristics outside the outcome or exposure variables.\n\nRather than using random assignment to equalize the experimental groups, the experimenters do it by matching observable characteristics.\nFor every participant in the exposed group, the researchers find a participant with comparable traits to include in the control group.\nMatching subjects facilitates valid comparisons between those groups.\nThe researchers use subject-area knowledge to identify characteristics that are critical to match.\n\n\n\nReducing confounding: Multiple Regression\nMultiple regression models specify the way in which different characteristics/variables (exposure and confounders) affects the outcome, thereby isolating the effect of each variable.\nchance of cancer = a x (coffee) + b x (smoking) + c x (gender) + d x (age)\n\nthis allows us to make a statement about what would happen if one variable (i.e., the exposure) were to change while all the others (i.e., the confounders) remained the same.\nObtaining isolated exposure effects conditional on the other variables remaining constant is said to adjust for (or control for) the effect of these confounders"
  },
  {
    "objectID": "ObservationalStudies.html#example-4",
    "href": "ObservationalStudies.html#example-4",
    "title": "Observational Studies",
    "section": "Example 4",
    "text": "Example 4\nYou and your friend are trying to find the perfect restaurant for dinner. You can’t decide so you want to instead rely on some observational data (i.e., restaurant reviews).\nYou find two worthy restaurants, Carla’s and Sophia’s each with 400 reviews and an indicator of whether the restaurant is recommended or not recommended.\nYou find that\n\nrecommended for Sophia’s = 250/400\nrecommended for Carla’s = 216/400\n\nSo what we have is a conditional probability:\n\np(recommended|Sophia’s) = 62.5%\np(recommended|Carla’s) = 54%\n\n\nWhat if we consider age as a factor here?\n\nrecommended for 18-35 yr old diners at Sophia’s = 50/150\nrecommended for 35+ diners at Sophia’s = 200/250\nrecommended for 18-35 yr old diners at Carla’s = 180/360\nrecommended for 35+ diners at Carla’s = 36/40\n\nSo what we have is:\n\np(recommended|Sophia’s, younger) = 30%\np(recommended|Sophia’s, older) = 80%\np(recommended|Carla’s, younger) = 50%\np(recommended|Carla’s, older) = 90%"
  },
  {
    "objectID": "ObservationalStudies.html#example-5",
    "href": "ObservationalStudies.html#example-5",
    "title": "Observational Studies",
    "section": "Example 5",
    "text": "Example 5\nSay we have data on the number of hours of exercise per week versus the risk of developing a disease for two sets of patients, those below the age of 50 and those over the age of 50. Here are individual plots showing the relationship between exercise and risk of disease.\n\n\n\n\n\n\n\n\n\nWe clearly see a negative correlation, indicating that increased levels of exercise per week are correlated with a lower risk of developing the disease for both groups. Now, let’s combine the data together on a single plot:\n\n\n\n\n\n\n\n\n\n❌ Surprise! The overall correlation is positive: More exercise → Higher risk.\n\nExplanation of the Paradox:\nWithin each age group: More exercise is associated with lower risk (negative correlation).\nAcross both groups: Older individuals exercise more…\n\n\n\n\n\n\n\n\n\n…but have higher baseline risk due to age.\n\n\n\n\n\n\n\n\n\nWhen aggregated, the higher risk of the older group skews the data, making it seem like more exercise increases risk. This is Simpson’s Paradox — where a trend appears in subgroups but reverses when the data is combined!"
  },
  {
    "objectID": "ObservationalStudies.html#example-3-pancreatic-cancer-study",
    "href": "ObservationalStudies.html#example-3-pancreatic-cancer-study",
    "title": "Observational Studies",
    "section": "Example 3: Pancreatic Cancer Study",
    "text": "Example 3: Pancreatic Cancer Study\nMany years ago, investigators reported an association between coffee drinking and pancreatic cancer in an observational study (MacMahon B, Yen S, Trichopoulos D, Warren K, Nardi G. Coffee and cancer of the pancreas. N Eng J Med 1981; 304: 630-3).\n\nIf we take coffee as our exposure of interest and correlate it with an increased development of pancreatic cancer there is the potential, as was the case with these investigators, to be misled if there is a third causal factor, such as cigarette smoking, that was more common among those who reported drinking coffee.\n\nOnce the confounding variable, smoking is taken into account the correlation between coffee and pancreatic cancer disappears.\n\nReducing confounding: Matching\nMatching is a technique that involves selecting study participants with similar characteristics outside the outcome or exposure variables.\n\nRather than using random assignment to equalize the experimental groups, the experimenters do it by matching observable characteristics.\nFor every participant in the exposed group, the researchers find a participant with comparable traits to include in the control group.\nMatching subjects facilitates valid comparisons between those groups.\nThe researchers use subject-area knowledge to identify characteristics that are critical to match.\n\n\n\nReducing confounding: Multiple Regression\nMultiple regression models specify the way in which different characteristics/variables (exposure and confounders) affects the outcome, thereby isolating the effect of each variable.\nchance of cancer = a x (coffee) + b x (smoking) + c x (gender) + d x (age)\n\nthis allows us to make a statement about what would happen if one variable (i.e., the exposure) were to change while all the others (i.e., the confounders) remained the same.\nObtaining isolated exposure effects conditional on the other variables remaining constant is said to adjust for (or control for) the effect of these confounders"
  },
  {
    "objectID": "ObservationalStudies.html#example-4-restaurant-reviews",
    "href": "ObservationalStudies.html#example-4-restaurant-reviews",
    "title": "Observational Studies",
    "section": "Example 4: Restaurant Reviews",
    "text": "Example 4: Restaurant Reviews\nYou and your friend are trying to find the perfect restaurant for dinner. You can’t decide so you want to instead rely on some observational data (i.e., restaurant reviews).\nYou find two worthy restaurants, Carla’s and Sophia’s each with 400 reviews and an indicator of whether the restaurant is recommended or not recommended.\nYou find that\n\nrecommended for Sophia’s = 250/400\nrecommended for Carla’s = 216/400\n\nSo what we have is a conditional probability:\n\np(recommended|Sophia’s) = 62.5%\np(recommended|Carla’s) = 54%\n\n\nWhat if we consider age as a factor here?\n\nrecommended for 18-35 yr old diners at Sophia’s = 50/150\nrecommended for 35+ diners at Sophia’s = 200/250\nrecommended for 18-35 yr old diners at Carla’s = 180/360\nrecommended for 35+ diners at Carla’s = 36/40\n\nSo what we have is:\n\np(recommended|Sophia’s, younger) = 30%\np(recommended|Sophia’s, older) = 80%\np(recommended|Carla’s, younger) = 50%\np(recommended|Carla’s, older) = 90%"
  },
  {
    "objectID": "ObservationalStudies.html#example-5-exercise-and-disease",
    "href": "ObservationalStudies.html#example-5-exercise-and-disease",
    "title": "Observational Studies",
    "section": "Example 5: Exercise and Disease",
    "text": "Example 5: Exercise and Disease\nSay we have (made up) data on the number of hours of exercise per week versus the risk of developing a disease for two sets of patients, those below the age of 50 and those over the age of 50. Here are individual plots showing the relationship between exercise and risk of disease.\n\n\n\n\n\n\n\n\n\nWe clearly see a negative correlation, indicating that increased levels of exercise per week are correlated with a lower risk of developing the disease for both groups. Now, let’s combine the data together on a single plot:\n\n\n\n\n\n\n\n\n\n❌ Surprise! The overall correlation is positive: More exercise → Higher risk.\n\nExplanation of the Paradox:\nWithin each age group: More exercise is associated with lower risk (negative correlation).\nAcross both groups: Older individuals exercise more…\n\n\n\n\n\n\n\n\n\n…but have higher baseline risk due to age.\n\n\n\n\n\n\n\n\n\nWhen aggregated, the higher risk of the older group skews the data, making it seem like more exercise increases risk. This is Simpson’s Paradox — where a trend appears in subgroups but reverses when the data is combined!"
  },
  {
    "objectID": "4-sampling.html#non-random-sampling",
    "href": "4-sampling.html#non-random-sampling",
    "title": "Sampling Principles and Strategies",
    "section": "Non random sampling",
    "text": "Non random sampling\n\nExpert Elicitation\nExpert elicitation is a form of non-random survey sampling where experts in a specific field are intentionally selected to provide insights or judgments on a topic.\n\n✅ Used when empirical data is scarce or uncertain (e.g., climate change risks).\n❌ Relies on expert judgment, which can introduce biases based on individual perspectives.\n\n\nExample: Estimating global mean sea-level rise and its uncertainties by 2100 and 2300 from an expert survey\n\nA survey selected experts who (co-)authored sea-level related papers (&gt;6).\n\nTo objectively select sea-level experts, we used the scientific publication database Web of Science of Clarivate to identify the most active publishers of sea-level papers.\nOn 15 February 2019, we searched for all papers published in peer-reviewed journals since (and including) 2014 where the term “sea level” appeared in the title, keywords or “KeyWords Plus” (an algorithm used to review words or phrases that appear in the cited references of an article) to identify scientists who (co-)authored the greatest number of these papers.\nWe obtained a sample of 878 experts who published at least six papers on “sea level” since 2014.\nWe found e-mail addresses for 817 of these experts and accordingly invited them to participate in the survey on 18 March 2019, using a unique identifier to ensure anonymity and avoid duplicate responses.\nA total of 458 experts opened the e-mail invitation, and of these 112 completed the survey, which is typical for this type of internet survey.\nThe main reason given for declining to participate was a (perceived) lack of expertise in projecting GMSL rise.\nWe closed the survey on 30 June 2019. We could not analyze six responses from participants because they either left all boxes blank or filled with a question mark. Not all survey respondents completed every percentile box.\n\n\nThus, a total of 106 sea-level experts from 817 invites (13%) provided their probabilistic assessment of GMSL rise, given two temperature projection scenarios.\nThe paper can be found here.\n\n\nAnalysis\n\nglimpse(expert_survey_dat)\n\nRows: 112\nColumns: 23\n$ name         &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17…\n$ Expertise_A  &lt;fct&gt; 1) Statistical or physical process modeling, 1) Statistic…\n$ Expertise    &lt;chr&gt; \"Ice-sheet modeling, Glacial-isostatic adjustment modelin…\n$ Blue_95_2100 &lt;dbl&gt; 80, 80, NA, 100, 126, 10, 75, 60, 55, 50, 60, NA, 55, 100…\n$ Blue_83_2100 &lt;dbl&gt; NA, 68, 59, 90, 98, 8, 67, 50, 45, 40, 55, NA, NA, 60, 70…\n$ Blue_50_2100 &lt;dbl&gt; 45, 50, 43, 70, 69, 5, 50, 40, 40, 30, 45, NA, 40, 50, 50…\n$ Blue_17_2100 &lt;dbl&gt; NA, 41, 29, 40, 49, 3, 37, 30, 35, 20, 35, NA, NA, 40, 30…\n$ Blue_5_2100  &lt;dbl&gt; 25, 35, NA, 21, 36, 1, 25, 20, 30, 10, 30, NA, 25, 30, 20…\n$ Red_95_2100  &lt;dbl&gt; 210, 200, NA, 125, 238, 300, 150, 80, 150, 200, 190, NA, …\n$ Red_83_2100  &lt;dbl&gt; NA, 160, 110, 110, 174, 200, 125, 70, 120, 120, 170, NA, …\n$ Red_50_2100  &lt;dbl&gt; 100, 100, 84, 80, 111, 100, 100, 60, 80, 80, 110, NA, 70,…\n$ Red_17_2100  &lt;dbl&gt; NA, 70, 61, 50, 79, 50, 75, 50, 50, 50, 100, NA, NA, 80, …\n$ Red_5_2100   &lt;dbl&gt; 60, 50, NA, 40, 62, 30, 50, 40, 40, 30, 85, NA, 55, 60, 8…\n$ Blue_95_2300 &lt;dbl&gt; NA, 250, NA, 130, 300, 20, 150, 60, 180, 120, 190, NA, 80…\n$ Blue_83_2300 &lt;dbl&gt; NA, 180, 110, 90, 230, 10, 125, 50, 140, 100, 170, NA, NA…\n$ Blue_50_2300 &lt;dbl&gt; NA, 100, 85, 70, 142, 5, 100, 40, 120, 80, 150, NA, 50, 1…\n$ Blue_17_2300 &lt;dbl&gt; NA, 70, 60, 30, 83, 3, 75, 30, 100, 60, 135, NA, NA, 80, …\n$ Blue_5_2300  &lt;dbl&gt; 25, 50, NA, 20, 50, 2, 50, 20, 80, 40, 100, NA, 30, 50, 3…\n$ Red_95_2300  &lt;dbl&gt; NA, 1000, NA, 450, 700, 250, 250, 120, 700, 6, 750, NA, 1…\n$ Red_83_2300  &lt;dbl&gt; NA, 800, 540, 400, 672, 200, 225, 100, 500, 4, 650, NA, N…\n$ Red_50_2300  &lt;dbl&gt; NA, 500, 385, 290, 466, 100, 200, 80, 300, 3, 500, NA, 14…\n$ Red_17_2300  &lt;dbl&gt; NA, 380, 230, 100, 336, 50, 150, 60, 150, 2, 475, NA, NA,…\n$ Red_5_2300   &lt;dbl&gt; 140, 300, NA, 90, 220, 30, 125, 40, 100, 1, 400, NA, 55, …\n\nexpert_survey_dat_long &lt;- expert_survey_dat %&gt;% \n                            pivot_longer(Blue_95_2100:Red_5_2300,\n                                         names_to = \"scenario\",\n                                         values_to = \"prediction\") %&gt;% \n  separate(col = scenario, into = c(\"Scenario\",\"Percentile\",\"Year\")) \n\n  \n  \nexpert_survey_dat_long %&gt;% filter(Scenario == \"Red\",Year == 2100) %&gt;% \n  ggplot(aes(x=Percentile,y=prediction)) +\n  geom_boxplot(fill=\"firebrick\")+\n  labs(x=\"Percentile\",y=\"GMSL Rise (cm)\",caption=\"Red 2100\")+\n  ylim(-200,600)+\n  theme_bw()\n\n\n\n\nParticipants were asked to estimate likely (17th to 83rd percentiles) and very likely (5th to 95th percentiles) sea-level rise under a high emission temperature scenarios for 2100.\n\n\n\n\n\n\n\nSnowball Sampling\nSnowball sampling is a non-random sampling technique where existing participants help recruit new participants, forming a growing “snowball” effect.\n\n✅ Useful for hard-to-reach populations\n❌ Relies on social networks, which can lead to bias since participants are likely to refer similar individuals.\n\n\nExample: Global survey shows planners use widely varying sea-level rise projections for coastal adaptation\n\nCollaborating researchers known to be involved in sea level rise planning were contacted, sometimes targeting specific regions and cities.\nRegional leads sent emails to their contact lists.\n\nMore details for this snowball sampling method can be found here.\n\n\nAnalysis\n\nsl_planning_dat\n\n# A tibble: 21 × 4\n   Continent relative     n group\n   &lt;fct&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n 1 Asia          9.09     1 B    \n 2 Europe        5        1 D    \n 3 Oceania       3.57     1 B    \n 4 Africa       33.3      2 C    \n 5 Asia         18.2      2 C    \n 6 Oceania       7.14     2 C    \n 7 Oceania      10.7      3 D    \n 8 Africa       66.7      4 A    \n 9 Europe       20        4 C    \n10 Europe       25        5 B    \n# ℹ 11 more rows\n\n## create barplot with % in each category \n\n## The colour palette\ncbPalette &lt;- c(\"#E69F00\",\"#009E73\",\"#999999\",\"#56B4E9\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")\n\n## The plot\nggplot(sl_planning_dat, aes(x = fct_rev(Continent),y = relative, fill = group)) + \n  geom_bar(stat = \"identity\")+\n  geom_text(aes(x = Continent, label = paste0(round(relative,1),'% \\n (',n,')')),\n            colour = 'white', position=position_stack(vjust=0.5), size = 3) +\n  ggtitle('')+\n  coord_flip() +\n  ylab(\"Percentage (Count)\")+\n  xlab(\"\")+\n  labs(fill = \"Structure\") +\n  scale_y_reverse() +\n  theme_classic() +\n  theme(legend.position = \"bottom\",\n        plot.title = element_text(size=12),\n        axis.text.x=element_blank(),\n        axis.ticks.x=element_blank()) +\n  scale_fill_manual(values=cbPalette) \n\n\n\n\nRespondents formally structure the use of sea-level rise projections for planning purposes in four ways: A is a singular estimate, B is a low and a high estimate, C is a low, intermediate, and high estimate, and D is a low, intermediate, high, and high-end estimate. Shown are aggregated responses for five distinct geographical regions and the globe."
  },
  {
    "objectID": "4-sampling.html#survey-example",
    "href": "4-sampling.html#survey-example",
    "title": "Sampling Principles and Strategies",
    "section": "Survey Example",
    "text": "Survey Example\n\nA survey selected experts who (co-)authored sea-level related &gt;6 papers.\n\nTo objectively select sea-level experts, we used the scientific publication database Web of Science of Clarivate to identify the most active publishers of sea-level papers.\nOn 15 February 2019, we searched for all papers published in peer-reviewed journals since (and including) 2014 where the term “sea level” appeared in the title, keywords or “KeyWords Plus” (an algorithm used to review words or phrases that appear in the cited references of an article) to identify scientists who (co-)authored the greatest number of these papers.\nWe obtained a sample of 878 experts who published at least six papers on “sea level” since 2014.\nWe found e-mail addresses for 817 of these experts and accordingly invited them to participate in the survey on 18 March 2019, using a unique identifier to ensure anonymity and avoid duplicate responses.\nA total of 458 experts opened the e-mail invitation, and of these 112 completed the survey, which is typical for this type of internet survey.\nThe main reason given for declining to participate was a (perceived) lack of expertise in projecting GMSL rise.\nWe closed the survey on 30 June 2019. We could not analyze six responses from participants because they either left all boxes blank or filled with a question mark. Not all survey respondents completed every percentile box.\n\n\nThus, a total of 106 sea-level experts from 817 invites (13%) provided their probabilistic assessment of GMSL rise, given two temperature scenarios derived from the upper and lower extremes of the RCP scenarios.\nhttps://www.nature.com/articles/s41612-020-0121-5\n\nexpert_survey_dat &lt;- readRDS(\"data/expert_survey_dat.rds\")\nglimpse(expert_survey_dat)\n\nRows: 112\nColumns: 23\n$ name         &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17…\n$ Expertise_A  &lt;fct&gt; 1) Statistical or physical process modeling, 1) Statistic…\n$ Expertise    &lt;chr&gt; \"Ice-sheet modeling, Glacial-isostatic adjustment modelin…\n$ Blue_95_2100 &lt;dbl&gt; 80, 80, NA, 100, 126, 10, 75, 60, 55, 50, 60, NA, 55, 100…\n$ Blue_83_2100 &lt;dbl&gt; NA, 68, 59, 90, 98, 8, 67, 50, 45, 40, 55, NA, NA, 60, 70…\n$ Blue_50_2100 &lt;dbl&gt; 45, 50, 43, 70, 69, 5, 50, 40, 40, 30, 45, NA, 40, 50, 50…\n$ Blue_17_2100 &lt;dbl&gt; NA, 41, 29, 40, 49, 3, 37, 30, 35, 20, 35, NA, NA, 40, 30…\n$ Blue_5_2100  &lt;dbl&gt; 25, 35, NA, 21, 36, 1, 25, 20, 30, 10, 30, NA, 25, 30, 20…\n$ Red_95_2100  &lt;dbl&gt; 210, 200, NA, 125, 238, 300, 150, 80, 150, 200, 190, NA, …\n$ Red_83_2100  &lt;dbl&gt; NA, 160, 110, 110, 174, 200, 125, 70, 120, 120, 170, NA, …\n$ Red_50_2100  &lt;dbl&gt; 100, 100, 84, 80, 111, 100, 100, 60, 80, 80, 110, NA, 70,…\n$ Red_17_2100  &lt;dbl&gt; NA, 70, 61, 50, 79, 50, 75, 50, 50, 50, 100, NA, NA, 80, …\n$ Red_5_2100   &lt;dbl&gt; 60, 50, NA, 40, 62, 30, 50, 40, 40, 30, 85, NA, 55, 60, 8…\n$ Blue_95_2300 &lt;dbl&gt; NA, 250, NA, 130, 300, 20, 150, 60, 180, 120, 190, NA, 80…\n$ Blue_83_2300 &lt;dbl&gt; NA, 180, 110, 90, 230, 10, 125, 50, 140, 100, 170, NA, NA…\n$ Blue_50_2300 &lt;dbl&gt; NA, 100, 85, 70, 142, 5, 100, 40, 120, 80, 150, NA, 50, 1…\n$ Blue_17_2300 &lt;dbl&gt; NA, 70, 60, 30, 83, 3, 75, 30, 100, 60, 135, NA, NA, 80, …\n$ Blue_5_2300  &lt;dbl&gt; 25, 50, NA, 20, 50, 2, 50, 20, 80, 40, 100, NA, 30, 50, 3…\n$ Red_95_2300  &lt;dbl&gt; NA, 1000, NA, 450, 700, 250, 250, 120, 700, 6, 750, NA, 1…\n$ Red_83_2300  &lt;dbl&gt; NA, 800, 540, 400, 672, 200, 225, 100, 500, 4, 650, NA, N…\n$ Red_50_2300  &lt;dbl&gt; NA, 500, 385, 290, 466, 100, 200, 80, 300, 3, 500, NA, 14…\n$ Red_17_2300  &lt;dbl&gt; NA, 380, 230, 100, 336, 50, 150, 60, 150, 2, 475, NA, NA,…\n$ Red_5_2300   &lt;dbl&gt; 140, 300, NA, 90, 220, 30, 125, 40, 100, 1, 400, NA, 55, …\n\nexpert_survey_dat_long &lt;- expert_survey_dat %&gt;% \n                            pivot_longer(Blue_95_2100:Red_5_2300,\n                                         names_to = \"scenario\",\n                                         values_to = \"prediction\") %&gt;% \n  separate(col = scenario, into = c(\"Scenario\",\"Percentile\",\"Year\")) \n\n  \n  \nexpert_survey_dat_long %&gt;% filter(Scenario == \"Red\",Year == 2100) %&gt;% ggplot(aes(x=Percentile,y=prediction))+\n  geom_boxplot(fill=\"firebrick\")+\n  labs(x=\"Percentile\",y=\"GMSL Rise (cm)\",caption=\"Blue 2100\")+\n  ylim(-200,600)+\n  theme_bw()\n\nWarning: Removed 75 rows containing non-finite outside the scale range\n(`stat_boxplot()`)."
  },
  {
    "objectID": "Assignment2.html",
    "href": "Assignment2.html",
    "title": "DS152 Introduction to Data Science (2)",
    "section": "",
    "text": "Answer all questions for continuous assessment. Due: 4pm on Friday, 7th March 2025."
  },
  {
    "objectID": "Assignment2.html#instructions",
    "href": "Assignment2.html#instructions",
    "title": "DS152 Introduction to Data Science (2)",
    "section": "",
    "text": "Answer all questions for continuous assessment. Due: 4pm on Friday, 7th March 2025."
  },
  {
    "objectID": "Assignment2.html#exercise",
    "href": "Assignment2.html#exercise",
    "title": "DS152 Introduction to Data Science (2)",
    "section": "Exercise",
    "text": "Exercise\nFor this exercise, we will work with the Cars93 data frame from package MASS. Open an R session in the R Studio Server, and type in the code below to glimpse the dataset and access the help file to see more information on the data.\n\nlibrary(tidyverse)\nCars93 &lt;- MASS::Cars93\n\nglimpse(Cars93)\n?Cars93\n\n\nHow many observations and how many variables are in the Cars93 dataset?\nSuppose we would like to predict the Price of the cars. Why would logistic regression not be suitable in this case?\nAssume you want to fit a simple linear regression model to predict Price using Horsepower as the predictor. How would you fill the gaps, [A], [B], [C] and [D] in the code below to fit the linear regression model?\n\n\nlm_mod1 &lt;-  [A]([B] ~ [C], data = [D])\n\n[A] =\n[B] =\n[C] =\n[D] =\n\nAfter fitting the linear regression model and inspecting the estimated coefficients, we obtain the following results in R:\n\n## Coefficients:\n## (Intercept)   Horsepower\n##     -1.3988       0.1454\nWhat would the predicted Price be if Horsepower was 100?\n\nBriefly explain, in your own words, why the plot being created with the code below is useful.\n\n\nCars93_pred &lt;- Cars93 %&gt;%  mutate(price_pred = predict(lm_mod1))\n\nggplot(data = Cars93_pred,\n       mapping = aes(x = Price, y = price_pred)) +\n  theme_bw() +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1) +\n  xlab(\"Observed CL\") + \n  ylab(\"Predicted CL\")\n\n\nNow fit a multiple linear regression using the predictor variables: MPG.city, MPG.highway, EngineSize, Horsepower, RPM, Rev.per.mile, Fuel.tank.capacity, and Width. Save this model as lm_mod2. Look at the estimated coefficients. Which ones seem to be negatively related to the response Price?\nCreate the plot shown in (e) but instead use lm_mod2 to get your predictions. Which model appears to perform better in terms of prediction, give a reason for your answer.\nBelow we present the sum of the squared residuals (discrepancy) for both model fits. Which one (model A or B) is more likely to correspond to the multiple linear regression (lm_mod2)? Justify your answer.\n\n\n\n model A  model B \n2755.807 3250.881"
  },
  {
    "objectID": "5-ObservationalStudies.html",
    "href": "5-ObservationalStudies.html",
    "title": "Observational Studies",
    "section": "",
    "text": "Exposure: A variable that represents a factor of interest that may influence an outcome, such as a risk factor, treatment, behavior, or environmental condition (e.g., smoking, diet, air pollution, or a medical intervention).\nOutcome: The event or condition that is being studied as the possible effect of the exposure, such as disease occurrence, recovery, mortality, or any measurable health-related change (e.g., lung cancer, weight loss, or blood pressure levels).\nIn retrospective observational studies, investigators “look backwards in time” and use data that have already been collected. Retrospective studies are often criticized for having more confounding and bias compared to prospective studies.\nIn prospective observational studies, investigators choose a sample and collect new data generated from that sample. That is, the investigators “look forward in time.”\n\n\nIn observational studies, researchers examine the relationship between exposure and outcome without intervening, aiming to identify associations while controlling for confounders (more on this later).\n\nAn observational study on individuals from a random sample allows one to generalize conclusions about the sample to the population.\nAn observational study cannot show cause-and-effect relationships because there is the possibility that the response is affected by some variable(s) other than the ones being measured. That is, confounding variables may be present. “It ain’t what you don’t know that gets you into trouble. It’s what you know for sure that just ain’t so.” - Mark Twain"
  },
  {
    "objectID": "5-ObservationalStudies.html#observational-study",
    "href": "5-ObservationalStudies.html#observational-study",
    "title": "Observational Studies",
    "section": "",
    "text": "Exposure: A variable that represents a factor of interest that may influence an outcome, such as a risk factor, treatment, behavior, or environmental condition (e.g., smoking, diet, air pollution, or a medical intervention).\nOutcome: The event or condition that is being studied as the possible effect of the exposure, such as disease occurrence, recovery, mortality, or any measurable health-related change (e.g., lung cancer, weight loss, or blood pressure levels).\n\nIn observational studies, researchers examine the relationship between exposure and outcome without intervening, aiming to identify associations while controlling for confounders (more on this later).\n\nAn observational study on individuals from a random sample allows one to generalize conclusions about the sample to the population.\nAn observational study cannot show cause-and-effect relationships because there is the possibility that the response is affected by some variable(s) other than the ones being measured. That is, confounding variables may be present. “It ain’t what you don’t know that gets you into trouble. It’s what you know for sure that just ain’t so.” - Mark Twain\nIn prospective observational studies, investigators choose a sample and collect new data generated from that sample. That is, the investigators “look forward in time.”\nIn retrospective observational studies, investigators “look backwards in time” and use data that have already been collected. Retrospective studies are often criticized for having more confounding and bias compared to prospective studies."
  },
  {
    "objectID": "5-ObservationalStudies.html#example-1-student-happiness",
    "href": "5-ObservationalStudies.html#example-1-student-happiness",
    "title": "Observational Studies",
    "section": "Example 1: Student Happiness",
    "text": "Example 1: Student Happiness\nThe gcfeeling data contains results of a survey conducted by Georgetown College students on 47 Georgetown College students in relation to feelings about Georgetown College.\n\n# Load necessary packages\nlibrary(tidyverse)\nlibrary(tigerstats)\n\n# Load the dataset\ndata(\"gcfeeling\")\n\n# View basic structure\nglimpse(gcfeeling)\n\nRows: 47\nColumns: 6\n$ rating.fresh &lt;int&gt; 9, 8, 5, 5, 8, 7, 9, 9, 7, 9, 8, 10, 8, 8, 9, 9, 6, 10, 1…\n$ rating.js    &lt;int&gt; 7, 10, 8, 8, 10, 9, 9, 8, 8, 8, 8, 10, 8, 10, 9, 7, 7, 10…\n$ greek        &lt;fct&gt; y, n, y, n, n, y, y, y, y, y, n, n, n, n, n, n, n, y, n, …\n$ athlete      &lt;fct&gt; n, n, n, n, n, n, n, n, n, n, n, n, n, n, n, n, n, y, y, …\n$ rating.diff  &lt;int&gt; -2, 2, 3, 3, 2, 2, 0, -1, 1, -1, 0, 0, 0, 2, 0, -2, 1, 0,…\n$ happier      &lt;fct&gt; NO, YES, YES, YES, YES, YES, YES, NO, YES, NO, YES, YES, …\n\n\n\n1. Exploring Categorical Variables\ngcfeeling contains categorical variables. We can visualize their distributions:\n\n# Count and visualize categorical variables\ngcfeeling %&gt;%\n  select_if(is.factor) %&gt;% \n  pivot_longer(everything(),names_to = \"Variable\", values_to = \"Value\") %&gt;%\n  ggplot(aes(x = Value)) +\n  geom_bar() +\n  facet_wrap(~ Variable, scales = \"free\") +\n  theme_minimal() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n2. Exploring Numeric Variables\ngcfeeling contains numeric variables. We can visualize their distributions:\n\n# Check numeric variable distributions\ngcfeeling %&gt;%\n  select_if(is.numeric) %&gt;%\n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"Value\") %&gt;%\n  ggplot(aes(x = Variable,y = Value)) +\n  geom_boxplot() +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n3. Relationships Between Variables\n\nContingency Table (For Categorical Variables)\nA contingency table shows the relationship between two categorical variables by displaying their frequency distribution.\n\ngcfeeling %&gt;%\n  select(athlete, happier) %&gt;% \n  table()\n\n       happier\nathlete NO YES\n      n 10  25\n      y  1  11\n\n\n\n\nBarplots (For Categorical Variables)\nWe can visualise conditional distributions, for example, given the student is an athlete what is the chance they were happier?\n\ngcfeeling %&gt;%\n  select(athlete, happier) %&gt;% \n  count(athlete, happier) %&gt;% \n  ggplot(aes(x = athlete, fill = happier, weight = n)) +\n  geom_bar(position = \"fill\") \n\n\n\n\n\n\n\n\n\n\nPairwise Correlation (For Numeric Variables)\nAs we’ve seen before, correlation measures the strength and direction of the relationship between two variables, indicating how changes in one variable are associated with changes in another.\n\n# Compute correlation matrix\ncor(gcfeeling$rating.fresh, gcfeeling$rating.diff)\n\n[1] -0.6694201\n\n\n\n\nScatterplots (For Numeric Variables)\nWe can visualise the relationship between two numerical variables, for example, current happiness level vs past happiness level.\n\nggplot(gcfeeling, aes(x = rating.fresh, y = rating.diff)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\nBoxplots of Numerical Variables by Categories\nWe can visualise the relationship between a categorical and a numerical variable, for example, current happiness level broken down by athlete categories.\n\n# Boxplots grouped by a categorical variable\ngcfeeling %&gt;%\n  ggplot(aes(x = athlete, y = rating.diff)) +\n  geom_boxplot() +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n4. Modelling\n\nNumerical outcome\nWe can use multiple linear regression to model student happiness.\n\nlm(rating.diff ~ rating.fresh + athlete + greek, data = gcfeeling)\n\n\nCall:\nlm(formula = rating.diff ~ rating.fresh + athlete + greek, data = gcfeeling)\n\nCoefficients:\n (Intercept)  rating.fresh      athletey        greeky  \n      5.0287       -0.6723        0.7594        0.8272  \n\n\n\n\nBinary outcome\nWe can use multiple logisitc regression to model student happiness.\n\nglm(happier ~ rating.fresh + athlete + greek, data = gcfeeling, family = \"binomial\")\n\n\nCall:  glm(formula = happier ~ rating.fresh + athlete + greek, family = \"binomial\", \n    data = gcfeeling)\n\nCoefficients:\n (Intercept)  rating.fresh      athletey        greeky  \n      4.6555       -0.4595        1.7066       -0.5962  \n\nDegrees of Freedom: 46 Total (i.e. Null);  43 Residual\nNull Deviance:      51.15 \nResidual Deviance: 43.37    AIC: 51.37"
  },
  {
    "objectID": "5-ObservationalStudies.html#example-2-does-working-out-increase-energy-levels",
    "href": "5-ObservationalStudies.html#example-2-does-working-out-increase-energy-levels",
    "title": "Observational Studies",
    "section": "Example 2: Does working out increase energy levels?",
    "text": "Example 2: Does working out increase energy levels?\nWe want to evaluate if regularly working out has any impact on energy levels.\n\nIn an observational study, we sample two types of people from the population, those who choose to work out regularly and those who don’t.\nWe ask the people in each group to rate their energy levels from 1-10.\nThen, we find the average “energy level” for the two groups of people and compare.\n\n\nCan we conclude from this that working out is the cause of increased energy levels?\n\nThere may be other variables that we didn’t control for in this study that contribute to the observed difference.\nFor example, people who have young children might have less time to work out and also have lower energy levels.\nThis is known as confounding.\nThis study allows us to make correlation statements. But, we cannot make a causal statement attributing increased energy levels to working out!\n\n\nConfounding variables\nConfounding variables: Extraneous variables that affect both the exposure (e.g., working out) and the outcome variables (e.g., increased energy), and that make it seem like there is a relationship between them are called confounding variables."
  },
  {
    "objectID": "5-ObservationalStudies.html#example-3-pancreatic-cancer-study",
    "href": "5-ObservationalStudies.html#example-3-pancreatic-cancer-study",
    "title": "Observational Studies",
    "section": "Example 3: Pancreatic Cancer Study",
    "text": "Example 3: Pancreatic Cancer Study\nMany years ago, investigators reported an association between coffee drinking and pancreatic cancer in an observational study (MacMahon B, Yen S, Trichopoulos D, Warren K, Nardi G. Coffee and cancer of the pancreas. N Eng J Med 1981; 304: 630-3).\n\nIf we take coffee as our exposure of interest and correlate it with the development of pancreatic cancer there is the potential, as was the case with these investigators, to be misled. There is a third causal factor, cigarette smoking, that was more common among those who reported drinking coffee and those with pancreatic cancer.\n\nOnce the confounding variable, smoking is taken into account the correlation between coffee and pancreatic cancer disappears.\n\nReducing confounding: Matching\nMatching is a technique used in observational studies to reduce confounding by ensuring that compared groups have similar distributions of key variables. Since observational studies lack randomization of the exposure, confounders—variables that are related to both the exposure and the outcome—can introduce bias. Matching helps control for these confounders by pairing or grouping subjects with similar characteristics across different exposure levels.\n\n\nReducing confounding: Multiple Regression\nMultiple regression models specify the way in which different characteristics/variables (exposure and confounders) affects the outcome, thereby isolating the effect of each variable.\nchance of cancer = a x (coffee) + b x (smoking) + c x (gender) + d x (age)\n\nthis allows us to make a statement about what would happen if one variable (i.e., the exposure) were to change while all the others (i.e., the confounders) remained the same.\nObtaining isolated exposure effects conditional on the other variables remaining constant is said to adjust for (or control for) the effect of these confounders"
  },
  {
    "objectID": "5-ObservationalStudies.html#example-4-restaurant-reviews",
    "href": "5-ObservationalStudies.html#example-4-restaurant-reviews",
    "title": "Observational Studies",
    "section": "Example 4: Restaurant Reviews",
    "text": "Example 4: Restaurant Reviews\nYou and your friend are trying to find the perfect restaurant for dinner. You can’t decide so you want to instead rely on some observational data (i.e., restaurant reviews).\nYou find two worthy restaurants, Carla’s and Sophia’s each with 400 reviews and an indicator of whether the restaurant is recommended or not recommended.\nYou find that\n\nrecommended for Sophia’s = 250/400\nrecommended for Carla’s = 216/400\n\nSo what we have is a conditional probability:\n\np(recommended|Sophia’s) = 62.5%\np(recommended|Carla’s) = 54%\n\n\nWhat if we consider age as a factor here?\n\nrecommended for 18-35 yr old diners at Sophia’s = 50/150\nrecommended for 35+ diners at Sophia’s = 200/250\nrecommended for 18-35 yr old diners at Carla’s = 180/360\nrecommended for 35+ diners at Carla’s = 36/40\n\nSo what we have is:\n\np(recommended|Sophia’s, younger) = 30%\np(recommended|Sophia’s, older) = 80%\np(recommended|Carla’s, younger) = 50%\np(recommended|Carla’s, older) = 90%"
  },
  {
    "objectID": "5-ObservationalStudies.html#whats-going-on",
    "href": "5-ObservationalStudies.html#whats-going-on",
    "title": "Observational Studies",
    "section": "What’s going on?",
    "text": "What’s going on?\nYou have unknowingly entered the world of Simpson’s Paradox, where a restaurant can be both better and worse than its competitor, exercise can lower and increase the risk of disease, and the same dataset can be used to prove two opposing arguments. Instead of going out to dinner, perhaps you and your friend should spend the evening discussing this fascinating statistical phenomenon.\nSimpson’s Paradox occurs when trends that appear when a dataset is separated into groups reverse when the data are aggregated."
  },
  {
    "objectID": "5-ObservationalStudies.html#example-5-exercise-and-disease",
    "href": "5-ObservationalStudies.html#example-5-exercise-and-disease",
    "title": "Observational Studies",
    "section": "Example 5: Exercise and Disease",
    "text": "Example 5: Exercise and Disease\nSay we have (made up) data on the number of hours of exercise per week versus the risk of developing a disease for two sets of patients, those below the age of 50 and those over the age of 50. Here are individual plots showing the relationship between exercise and risk of disease.\n\n\n\n\n\n\n\n\n\nWe clearly see a negative correlation, indicating that increased levels of exercise per week are correlated with a lower risk of developing the disease for both groups. Now, let’s combine the data together on a single plot:\n\n\n\n\n\n\n\n\n\n❌ Surprise! The overall correlation is positive: More exercise → Higher risk.\n\nExplanation of the Paradox:\nWithin each age group: More exercise is associated with lower risk (negative correlation).\nAcross both groups: Older individuals exercise more…\n\n\n\n\n\n\n\n\n\n…but have higher baseline risk due to age.\n\n\n\n\n\n\n\n\n\nWhen aggregated, the higher risk of the older group skews the data, making it seem like more exercise increases risk. This is Simpson’s Paradox — where a trend appears in subgroups but reverses when the data is combined!"
  },
  {
    "objectID": "Assignment1_soln.html#question",
    "href": "Assignment1_soln.html#question",
    "title": "DS152 Introduction to Data Science (2)",
    "section": "Question",
    "text": "Question\n\nHow many observations are in the dataset? [2 Mark]\n\n\n902,297\n\n\nAssume you want to create the summary below, which sums up the number of fatalities within each event type and then arranges by the total fatalities, in descending order. [8 Marks]\n\n\nnat_disaster_summary &lt;- nat_disaster_dat %&gt;% \n                          group_by(EVTYPE) %&gt;% \n                          summarise(total_fatalities = sum(FATALITIES)) %&gt;% \n                          arrange(desc(total_fatalities))\nnat_disaster_summary \n\n# A tibble: 977 × 2\n   EVTYPE         total_fatalities\n   &lt;chr&gt;                     &lt;dbl&gt;\n 1 TORNADO                    5633\n 2 EXCESSIVE HEAT             1903\n 3 FLASH FLOOD                 978\n 4 HEAT                        937\n 5 LIGHTNING                   816\n 6 TSTM WIND                   504\n 7 FLOOD                       470\n 8 RIP CURRENT                 368\n 9 HIGH WIND                   248\n10 AVALANCHE                   224\n# ℹ 967 more rows\n\n\nIn the code below, what should [A], [B], [C] and [D] be replaced with to create this summary?\n\nnat_disaster__summary &lt;- nat_disaster_dat %&gt;% \n                          group_by([A]) %&gt;% \n                          [B](total_fatalities = [C])) %&gt;% \n                          arrange([D](total_fatalities))\n\n[A] = EVTYPE\n[B] = summarise\n[C] = sum(FATALITIES)\n[D] = desc\n\nNow assume you want to filter the summarised data from (ii) so that you have a dataset with only events where the total fatalities are greater than 200, as shown.\n\n\nnat_disaster_filter &lt;- nat_disaster_summary %&gt;% \n                        filter(total_fatalities &gt; 200)\nnat_disaster_filter\n\n# A tibble: 12 × 2\n   EVTYPE         total_fatalities\n   &lt;chr&gt;                     &lt;dbl&gt;\n 1 TORNADO                    5633\n 2 EXCESSIVE HEAT             1903\n 3 FLASH FLOOD                 978\n 4 HEAT                        937\n 5 LIGHTNING                   816\n 6 TSTM WIND                   504\n 7 FLOOD                       470\n 8 RIP CURRENT                 368\n 9 HIGH WIND                   248\n10 AVALANCHE                   224\n11 WINTER STORM                206\n12 RIP CURRENTS                204\n\n\nIn the code below, what should [A] and [B] be replaced with to create the filtered dataet? [4 Marks]\n\nnat_disaster_filter &lt;- nat_disaster_summary %&gt;% \n                        [A]([B])\n\n[A] = filter\n[B] = total_facilities &gt; 200\n\nNow assume you want to create the following barplot which shows the total fatalities per event type, using the filtered data from part (iii).\n\n\nggplot(nat_disaster_filter, aes(x = EVTYPE, y = total_fatalities)) +\n  geom_bar(stat=\"identity\") +\n  theme(axis.text.x = element_text(angle = 90)) +\n  xlab(\"\") +\n  ylab(\"# fatalities\")\n\n\n\n\n\n\n\n\nIn the code below, what should [A], [B] and [C] be replaced with to create the plot? [6 Marks]\n\nggplot(nat_disaster_filter, aes(x = [A], y = [B])) +\n  [C](stat=\"identity\") +\n  theme(axis.text.x = element_text(angle = 90)) +\n  xlab(\"\") +\n  ylab(\"# fatalities\") \n\n[A] = EVTYPE\n[B] = total_fatalities\n[C] = geom_bar"
  },
  {
    "objectID": "Assignment1_soln.html",
    "href": "Assignment1_soln.html",
    "title": "DS152 Introduction to Data Science (2)",
    "section": "",
    "text": "How many observations are in the dataset? [2 Mark]\n\n\n902,297\n\n\nAssume you want to create the summary below, which sums up the number of fatalities within each event type and then arranges by the total fatalities, in descending order. [8 Marks]\n\n\nnat_disaster_summary &lt;- nat_disaster_dat %&gt;% \n                          group_by(EVTYPE) %&gt;% \n                          summarise(total_fatalities = sum(FATALITIES)) %&gt;% \n                          arrange(desc(total_fatalities))\nnat_disaster_summary \n\n# A tibble: 977 × 2\n   EVTYPE         total_fatalities\n   &lt;chr&gt;                     &lt;dbl&gt;\n 1 TORNADO                    5633\n 2 EXCESSIVE HEAT             1903\n 3 FLASH FLOOD                 978\n 4 HEAT                        937\n 5 LIGHTNING                   816\n 6 TSTM WIND                   504\n 7 FLOOD                       470\n 8 RIP CURRENT                 368\n 9 HIGH WIND                   248\n10 AVALANCHE                   224\n# ℹ 967 more rows\n\n\nIn the code below, what should [A], [B], [C] and [D] be replaced with to create this summary?\n\nnat_disaster__summary &lt;- nat_disaster_dat %&gt;% \n                          group_by([A]) %&gt;% \n                          [B](total_fatalities = [C])) %&gt;% \n                          arrange([D](total_fatalities))\n\n[A] = EVTYPE\n[B] = summarise\n[C] = sum(FATALITIES)\n[D] = desc\n\nNow assume you want to filter the summarised data from (ii) so that you have a dataset with only events where the total fatalities are greater than 200, as shown.\n\n\nnat_disaster_filter &lt;- nat_disaster_summary %&gt;% \n                        filter(total_fatalities &gt; 200)\nnat_disaster_filter\n\n# A tibble: 12 × 2\n   EVTYPE         total_fatalities\n   &lt;chr&gt;                     &lt;dbl&gt;\n 1 TORNADO                    5633\n 2 EXCESSIVE HEAT             1903\n 3 FLASH FLOOD                 978\n 4 HEAT                        937\n 5 LIGHTNING                   816\n 6 TSTM WIND                   504\n 7 FLOOD                       470\n 8 RIP CURRENT                 368\n 9 HIGH WIND                   248\n10 AVALANCHE                   224\n11 WINTER STORM                206\n12 RIP CURRENTS                204\n\n\nIn the code below, what should [A] and [B] be replaced with to create the filtered dataet? [4 Marks]\n\nnat_disaster_filter &lt;- nat_disaster_summary %&gt;% \n                        [A]([B])\n\n[A] = filter\n[B] = total_facilities &gt; 200\n\nNow assume you want to create the following barplot which shows the total fatalities per event type, using the filtered data from part (iii).\n\n\nggplot(nat_disaster_filter, aes(x = EVTYPE, y = total_fatalities)) +\n  geom_bar(stat=\"identity\") +\n  theme(axis.text.x = element_text(angle = 90)) +\n  xlab(\"\") +\n  ylab(\"# fatalities\")\n\n\n\n\n\n\n\n\nIn the code below, what should [A], [B] and [C] be replaced with to create the plot? [6 Marks]\n\nggplot(nat_disaster_filter, aes(x = [A], y = [B])) +\n  [C](stat=\"identity\") +\n  theme(axis.text.x = element_text(angle = 90)) +\n  xlab(\"\") +\n  ylab(\"# fatalities\") \n\n[A] = EVTYPE\n[B] = total_fatalities\n[C] = geom_bar"
  },
  {
    "objectID": "Assignment1_soln.html#solutions-total-20-marks",
    "href": "Assignment1_soln.html#solutions-total-20-marks",
    "title": "DS152 Introduction to Data Science (2)",
    "section": "",
    "text": "How many observations are in the dataset? [2 Mark]\n\n\n902,297\n\n\nAssume you want to create the summary below, which sums up the number of fatalities within each event type and then arranges by the total fatalities, in descending order. [8 Marks]\n\n\nnat_disaster_summary &lt;- nat_disaster_dat %&gt;% \n                          group_by(EVTYPE) %&gt;% \n                          summarise(total_fatalities = sum(FATALITIES)) %&gt;% \n                          arrange(desc(total_fatalities))\nnat_disaster_summary \n\n# A tibble: 977 × 2\n   EVTYPE         total_fatalities\n   &lt;chr&gt;                     &lt;dbl&gt;\n 1 TORNADO                    5633\n 2 EXCESSIVE HEAT             1903\n 3 FLASH FLOOD                 978\n 4 HEAT                        937\n 5 LIGHTNING                   816\n 6 TSTM WIND                   504\n 7 FLOOD                       470\n 8 RIP CURRENT                 368\n 9 HIGH WIND                   248\n10 AVALANCHE                   224\n# ℹ 967 more rows\n\n\nIn the code below, what should [A], [B], [C] and [D] be replaced with to create this summary?\n\nnat_disaster__summary &lt;- nat_disaster_dat %&gt;% \n                          group_by([A]) %&gt;% \n                          [B](total_fatalities = [C])) %&gt;% \n                          arrange([D](total_fatalities))\n\n[A] = EVTYPE\n[B] = summarise\n[C] = sum(FATALITIES)\n[D] = desc\n\nNow assume you want to filter the summarised data from (ii) so that you have a dataset with only events where the total fatalities are greater than 200, as shown.\n\n\nnat_disaster_filter &lt;- nat_disaster_summary %&gt;% \n                        filter(total_fatalities &gt; 200)\nnat_disaster_filter\n\n# A tibble: 12 × 2\n   EVTYPE         total_fatalities\n   &lt;chr&gt;                     &lt;dbl&gt;\n 1 TORNADO                    5633\n 2 EXCESSIVE HEAT             1903\n 3 FLASH FLOOD                 978\n 4 HEAT                        937\n 5 LIGHTNING                   816\n 6 TSTM WIND                   504\n 7 FLOOD                       470\n 8 RIP CURRENT                 368\n 9 HIGH WIND                   248\n10 AVALANCHE                   224\n11 WINTER STORM                206\n12 RIP CURRENTS                204\n\n\nIn the code below, what should [A] and [B] be replaced with to create the filtered dataet? [4 Marks]\n\nnat_disaster_filter &lt;- nat_disaster_summary %&gt;% \n                        [A]([B])\n\n[A] = filter\n[B] = total_facilities &gt; 200\n\nNow assume you want to create the following barplot which shows the total fatalities per event type, using the filtered data from part (iii).\n\n\nggplot(nat_disaster_filter, aes(x = EVTYPE, y = total_fatalities)) +\n  geom_bar(stat=\"identity\") +\n  theme(axis.text.x = element_text(angle = 90)) +\n  xlab(\"\") +\n  ylab(\"# fatalities\")\n\n\n\n\n\n\n\n\nIn the code below, what should [A], [B] and [C] be replaced with to create the plot? [6 Marks]\n\nggplot(nat_disaster_filter, aes(x = [A], y = [B])) +\n  [C](stat=\"identity\") +\n  theme(axis.text.x = element_text(angle = 90)) +\n  xlab(\"\") +\n  ylab(\"# fatalities\") \n\n[A] = EVTYPE\n[B] = total_fatalities\n[C] = geom_bar"
  },
  {
    "objectID": "Tutorial3_soln.html",
    "href": "Tutorial3_soln.html",
    "title": "DS152 Tutorial Sheet 3 with Solutions",
    "section": "",
    "text": "A breast cancer study was conducted by Dr William Wolberg from the University of Wisconsin-Madison. He assessed biopsies of breast tumours for 699 patients up to 15 July 1992, and recorded nine different attributes, which are scores based on a scale from 1 to 10 on different features of the tumours. The response variable is whether the tumour was “benign” or “malignant”. A glimpse of the data is shown below.\n\nbiopsy &lt;- MASS::biopsy\nglimpse(biopsy)\n\nRows: 699\nColumns: 11\n$ ID    &lt;chr&gt; \"1000025\", \"1002945\", \"1015425\", \"1016277\", \"1017023\", \"1017122\"…\n$ V1    &lt;int&gt; 5, 5, 3, 6, 4, 8, 1, 2, 2, 4, 1, 2, 5, 1, 8, 7, 4, 4, 10, 6, 7, …\n$ V2    &lt;int&gt; 1, 4, 1, 8, 1, 10, 1, 1, 1, 2, 1, 1, 3, 1, 7, 4, 1, 1, 7, 1, 3, …\n$ V3    &lt;int&gt; 1, 4, 1, 8, 1, 10, 1, 2, 1, 1, 1, 1, 3, 1, 5, 6, 1, 1, 7, 1, 2, …\n$ V4    &lt;int&gt; 1, 5, 1, 1, 3, 8, 1, 1, 1, 1, 1, 1, 3, 1, 10, 4, 1, 1, 6, 1, 10,…\n$ V5    &lt;int&gt; 2, 7, 2, 3, 2, 7, 2, 2, 2, 2, 1, 2, 2, 2, 7, 6, 2, 2, 4, 2, 5, 6…\n$ V6    &lt;int&gt; 1, 10, 2, 4, 1, 10, 10, 1, 1, 1, 1, 1, 3, 3, 9, 1, 1, 1, 10, 1, …\n$ V7    &lt;int&gt; 3, 3, 3, 3, 3, 9, 3, 3, 1, 2, 3, 2, 4, 3, 5, 4, 2, 3, 4, 3, 5, 7…\n$ V8    &lt;int&gt; 1, 2, 1, 7, 1, 7, 1, 1, 1, 1, 1, 1, 4, 1, 5, 3, 1, 1, 1, 1, 4, 1…\n$ V9    &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 4, 1, 1, 1, 2, 1, 4, 1…\n$ class &lt;fct&gt; benign, benign, benign, benign, benign, malignant, benign, benig…\n\n\nIf you would like to see more information, type this in R:\n\n?biopsy\n\nAnswer the following questions.\n(a) Is this an observational study? Why or why not?\n Yes, because the data are simply being observed. Dr Wolberg does not control or influence the attributes of the patients’ tumours. \n(b) Is this a retrospective or prospective study? Or isn’t there enough information to tell? Justify your answer.\n Given the way the data is presented, this seems to be a retrospective study, since Dr Wolberg obtained the information on the patients after their breast tumours had been detected, and no extra data on the patients is recorded, so probably this isn’t a follow-up study. \n(c) Below is a function you have not met before called summarise_if. What do you think this function is doing when being used with group_by as shown below? Run this code. what do you learn from the output?\n\nlibrary(tidyverse)\nbiopsy %&gt;% group_by(class) %&gt;% summarise_if(is.numeric, mean)\n\n# A tibble: 2 × 10\n  class        V1    V2    V3    V4    V5    V6    V7    V8    V9\n  &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 benign     2.96  1.33  1.44  1.36  2.12    NA  2.10  1.29  1.06\n2 malignant  7.20  6.57  6.56  5.55  5.30    NA  5.98  5.86  2.59\n\n\n This function is only applying the summary to columns in the dataset if they are numeric. In this case the chosen summary is the mean. The output indicates that on average there appears to be differences in variables V1 - V9 across the benign and malignant groups. (Note: try showing them the summary when you use median instead of mean) \n(d) Note when you run the code above that the summary for V6 has NAs. Try adding na.rm = TRUE to the summarise_if function and see what happens. What do you think this achieves?\n\nbiopsy %&gt;% group_by(class) %&gt;% summarise_if(is.numeric, mean, na.rm = TRUE)\n\n# A tibble: 2 × 10\n  class        V1    V2    V3    V4    V5    V6    V7    V8    V9\n  &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 benign     2.96  1.33  1.44  1.36  2.12  1.35  2.10  1.29  1.06\n2 malignant  7.20  6.57  6.56  5.55  5.30  7.63  5.98  5.86  2.59\n\n\n It doesn’t remove the V6 column as might be expected. What it does is calculate the mean based on only the rows that have data and not NAs \n(e) Suppose you would like to predict, based on the attributes, whether the tumour was benign or malignant. Why would linear regression not be suitable in this case?\n Because our response would be bounded between 0 and 1, and the linear regression model would fit a line ranging from \\(-\\infty\\) and \\(+\\infty\\), which doesn’t make sense in this case. \n(f) What is the code below doing and why?\n\nbiopsy &lt;- biopsy %&gt;% mutate(malignant = as.numeric(class == \"malignant\"))\n\nTurning the class variable into a new variable call malignant which has a value of 1 if the tumour was malignant and 0 if it was benign. The glm function will only work with values between 0 and 1 or if the outcome is coded as a factor (which isn’t always the case). In this case the class variable is a factor so glm will work using malignant or class as the outcome.\n(g) Carry out a multiple logistic regression with this data using the binary response variable called malignant and predictors V1 - V9. What are the values of the coefficients?\n\nglm(malignant ~ V1 + V2 + V3 + V4 + V5 + V7 + V8 + V9,\n      family = binomial,\n      data = biopsy)\n\n\nCall:  glm(formula = malignant ~ V1 + V2 + V3 + V4 + V5 + V7 + V8 + \n    V9, family = binomial, data = biopsy)\n\nCoefficients:\n(Intercept)           V1           V2           V3           V4           V5  \n   -9.94564      0.57757     -0.01155      0.56794      0.31368      0.13056  \n         V7           V8           V9  \n    0.57995      0.12319      0.60785  \n\nDegrees of Freedom: 698 Total (i.e. Null);  690 Residual\nNull Deviance:      900.5 \nResidual Deviance: 140.7    AIC: 158.7\n\n\n(h) The predictor V3 is a scale referring to the uniformity of cell shape. How would an increase of 1 unit in this scale affect the prediction of this model as to whether the tumour is malignant or benign?\n It would increase the log-odds of it being malignant by 0.5679. Broadly speaking this means that an increase in V3 increases the chance of a malignant tumor."
  },
  {
    "objectID": "Tutorial3_soln.html#exercise",
    "href": "Tutorial3_soln.html#exercise",
    "title": "DS152 Tutorial Sheet 3 with Solutions",
    "section": "",
    "text": "A breast cancer study was conducted by Dr William Wolberg from the University of Wisconsin-Madison. He assessed biopsies of breast tumours for 699 patients up to 15 July 1992, and recorded nine different attributes, which are scores based on a scale from 1 to 10 on different features of the tumours. The response variable is whether the tumour was “benign” or “malignant”. A glimpse of the data is shown below.\n\nbiopsy &lt;- MASS::biopsy\nglimpse(biopsy)\n\nRows: 699\nColumns: 11\n$ ID    &lt;chr&gt; \"1000025\", \"1002945\", \"1015425\", \"1016277\", \"1017023\", \"1017122\"…\n$ V1    &lt;int&gt; 5, 5, 3, 6, 4, 8, 1, 2, 2, 4, 1, 2, 5, 1, 8, 7, 4, 4, 10, 6, 7, …\n$ V2    &lt;int&gt; 1, 4, 1, 8, 1, 10, 1, 1, 1, 2, 1, 1, 3, 1, 7, 4, 1, 1, 7, 1, 3, …\n$ V3    &lt;int&gt; 1, 4, 1, 8, 1, 10, 1, 2, 1, 1, 1, 1, 3, 1, 5, 6, 1, 1, 7, 1, 2, …\n$ V4    &lt;int&gt; 1, 5, 1, 1, 3, 8, 1, 1, 1, 1, 1, 1, 3, 1, 10, 4, 1, 1, 6, 1, 10,…\n$ V5    &lt;int&gt; 2, 7, 2, 3, 2, 7, 2, 2, 2, 2, 1, 2, 2, 2, 7, 6, 2, 2, 4, 2, 5, 6…\n$ V6    &lt;int&gt; 1, 10, 2, 4, 1, 10, 10, 1, 1, 1, 1, 1, 3, 3, 9, 1, 1, 1, 10, 1, …\n$ V7    &lt;int&gt; 3, 3, 3, 3, 3, 9, 3, 3, 1, 2, 3, 2, 4, 3, 5, 4, 2, 3, 4, 3, 5, 7…\n$ V8    &lt;int&gt; 1, 2, 1, 7, 1, 7, 1, 1, 1, 1, 1, 1, 4, 1, 5, 3, 1, 1, 1, 1, 4, 1…\n$ V9    &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 4, 1, 1, 1, 2, 1, 4, 1…\n$ class &lt;fct&gt; benign, benign, benign, benign, benign, malignant, benign, benig…\n\n\nIf you would like to see more information, type this in R:\n\n?biopsy\n\nAnswer the following questions.\n(a) Is this an observational study? Why or why not?\n Yes, because the data are simply being observed. Dr Wolberg does not control or influence the attributes of the patients’ tumours. \n(b) Is this a retrospective or prospective study? Or isn’t there enough information to tell? Justify your answer.\n Given the way the data is presented, this seems to be a retrospective study, since Dr Wolberg obtained the information on the patients after their breast tumours had been detected, and no extra data on the patients is recorded, so probably this isn’t a follow-up study. \n(c) Below is a function you have not met before called summarise_if. What do you think this function is doing when being used with group_by as shown below? Run this code. what do you learn from the output?\n\nlibrary(tidyverse)\nbiopsy %&gt;% group_by(class) %&gt;% summarise_if(is.numeric, mean)\n\n# A tibble: 2 × 10\n  class        V1    V2    V3    V4    V5    V6    V7    V8    V9\n  &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 benign     2.96  1.33  1.44  1.36  2.12    NA  2.10  1.29  1.06\n2 malignant  7.20  6.57  6.56  5.55  5.30    NA  5.98  5.86  2.59\n\n\n This function is only applying the summary to columns in the dataset if they are numeric. In this case the chosen summary is the mean. The output indicates that on average there appears to be differences in variables V1 - V9 across the benign and malignant groups. (Note: try showing them the summary when you use median instead of mean) \n(d) Note when you run the code above that the summary for V6 has NAs. Try adding na.rm = TRUE to the summarise_if function and see what happens. What do you think this achieves?\n\nbiopsy %&gt;% group_by(class) %&gt;% summarise_if(is.numeric, mean, na.rm = TRUE)\n\n# A tibble: 2 × 10\n  class        V1    V2    V3    V4    V5    V6    V7    V8    V9\n  &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 benign     2.96  1.33  1.44  1.36  2.12  1.35  2.10  1.29  1.06\n2 malignant  7.20  6.57  6.56  5.55  5.30  7.63  5.98  5.86  2.59\n\n\n It doesn’t remove the V6 column as might be expected. What it does is calculate the mean based on only the rows that have data and not NAs \n(e) Suppose you would like to predict, based on the attributes, whether the tumour was benign or malignant. Why would linear regression not be suitable in this case?\n Because our response would be bounded between 0 and 1, and the linear regression model would fit a line ranging from \\(-\\infty\\) and \\(+\\infty\\), which doesn’t make sense in this case. \n(f) What is the code below doing and why?\n\nbiopsy &lt;- biopsy %&gt;% mutate(malignant = as.numeric(class == \"malignant\"))\n\nTurning the class variable into a new variable call malignant which has a value of 1 if the tumour was malignant and 0 if it was benign. The glm function will only work with values between 0 and 1 or if the outcome is coded as a factor (which isn’t always the case). In this case the class variable is a factor so glm will work using malignant or class as the outcome.\n(g) Carry out a multiple logistic regression with this data using the binary response variable called malignant and predictors V1 - V9. What are the values of the coefficients?\n\nglm(malignant ~ V1 + V2 + V3 + V4 + V5 + V7 + V8 + V9,\n      family = binomial,\n      data = biopsy)\n\n\nCall:  glm(formula = malignant ~ V1 + V2 + V3 + V4 + V5 + V7 + V8 + \n    V9, family = binomial, data = biopsy)\n\nCoefficients:\n(Intercept)           V1           V2           V3           V4           V5  \n   -9.94564      0.57757     -0.01155      0.56794      0.31368      0.13056  \n         V7           V8           V9  \n    0.57995      0.12319      0.60785  \n\nDegrees of Freedom: 698 Total (i.e. Null);  690 Residual\nNull Deviance:      900.5 \nResidual Deviance: 140.7    AIC: 158.7\n\n\n(h) The predictor V3 is a scale referring to the uniformity of cell shape. How would an increase of 1 unit in this scale affect the prediction of this model as to whether the tumour is malignant or benign?\n It would increase the log-odds of it being malignant by 0.5679. Broadly speaking this means that an increase in V3 increases the chance of a malignant tumor."
  },
  {
    "objectID": "Tutorial3.html",
    "href": "Tutorial3.html",
    "title": "DS152 Tutorial Sheet 3",
    "section": "",
    "text": "A breast cancer study was conducted by Dr William Wolberg from the University of Wisconsin-Madison. He assessed biopsies of breast tumours for 699 patients up to 15 July 1992, and recorded nine different attributes, which are scores based on a scale from 1 to 10 on different features of the tumours. The response variable is whether the tumour was “benign” or “malignant”. A glimpse of the data is shown below.\n\nbiopsy &lt;- MASS::biopsy\nglimpse(biopsy)\n\nRows: 699\nColumns: 11\n$ ID    &lt;chr&gt; \"1000025\", \"1002945\", \"1015425\", \"1016277\", \"1017023\", \"1017122\"…\n$ V1    &lt;int&gt; 5, 5, 3, 6, 4, 8, 1, 2, 2, 4, 1, 2, 5, 1, 8, 7, 4, 4, 10, 6, 7, …\n$ V2    &lt;int&gt; 1, 4, 1, 8, 1, 10, 1, 1, 1, 2, 1, 1, 3, 1, 7, 4, 1, 1, 7, 1, 3, …\n$ V3    &lt;int&gt; 1, 4, 1, 8, 1, 10, 1, 2, 1, 1, 1, 1, 3, 1, 5, 6, 1, 1, 7, 1, 2, …\n$ V4    &lt;int&gt; 1, 5, 1, 1, 3, 8, 1, 1, 1, 1, 1, 1, 3, 1, 10, 4, 1, 1, 6, 1, 10,…\n$ V5    &lt;int&gt; 2, 7, 2, 3, 2, 7, 2, 2, 2, 2, 1, 2, 2, 2, 7, 6, 2, 2, 4, 2, 5, 6…\n$ V6    &lt;int&gt; 1, 10, 2, 4, 1, 10, 10, 1, 1, 1, 1, 1, 3, 3, 9, 1, 1, 1, 10, 1, …\n$ V7    &lt;int&gt; 3, 3, 3, 3, 3, 9, 3, 3, 1, 2, 3, 2, 4, 3, 5, 4, 2, 3, 4, 3, 5, 7…\n$ V8    &lt;int&gt; 1, 2, 1, 7, 1, 7, 1, 1, 1, 1, 1, 1, 4, 1, 5, 3, 1, 1, 1, 1, 4, 1…\n$ V9    &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 4, 1, 1, 1, 2, 1, 4, 1…\n$ class &lt;fct&gt; benign, benign, benign, benign, benign, malignant, benign, benig…\n\n\nIf you would like to see more information, type this in R:\n\n?biopsy\n\nAnswer the following questions.\n(a) Is this an observational study? Why or why not?\n(b) Is this a retrospective or prospective study? Or isn’t there enough information to tell? Justify your answer.\n(c) Below is a function you have not met before called summarise_if. What do you think this function is doing when being used with group_by as shown below? Run this code. what do you learn from the output?\n\nlibrary(tidyverse)\nbiopsy %&gt;% group_by(class) %&gt;% summarise_if(is.numeric, mean)\n\n# A tibble: 2 × 10\n  class        V1    V2    V3    V4    V5    V6    V7    V8    V9\n  &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 benign     2.96  1.33  1.44  1.36  2.12    NA  2.10  1.29  1.06\n2 malignant  7.20  6.57  6.56  5.55  5.30    NA  5.98  5.86  2.59\n\n\n(d) Note, when you run the code above, the summary for V6 has NAs. Try adding na.rm = TRUE to the summarise_if function and see what happens. What do you think this achieves?\n(e) Suppose you would like to predict, based on the attributes, whether the tumour was benign or malignant. Why would linear regression not be suitable in this case?\n(f) What is the code below doing and why?\n\nbiopsy &lt;- biopsy %&gt;% mutate(malignant = as.numeric(class == \"malignant\"))\n\n(g) Carry out a multiple logistic regression with this data using the binary response variable called malignant and predictors V1 - V9. What are the values of the coefficients?\n(h) The predictor V3 is a scale referring to the uniformity of cell shape. How would an increase of 1 unit in this scale affect the prediction of this model as to whether the tumour is malignant or benign?"
  },
  {
    "objectID": "Tutorial3.html#exercise",
    "href": "Tutorial3.html#exercise",
    "title": "DS152 Tutorial Sheet 3",
    "section": "",
    "text": "A breast cancer study was conducted by Dr William Wolberg from the University of Wisconsin-Madison. He assessed biopsies of breast tumours for 699 patients up to 15 July 1992, and recorded nine different attributes, which are scores based on a scale from 1 to 10 on different features of the tumours. The response variable is whether the tumour was “benign” or “malignant”. A glimpse of the data is shown below.\n\nbiopsy &lt;- MASS::biopsy\nglimpse(biopsy)\n\nRows: 699\nColumns: 11\n$ ID    &lt;chr&gt; \"1000025\", \"1002945\", \"1015425\", \"1016277\", \"1017023\", \"1017122\"…\n$ V1    &lt;int&gt; 5, 5, 3, 6, 4, 8, 1, 2, 2, 4, 1, 2, 5, 1, 8, 7, 4, 4, 10, 6, 7, …\n$ V2    &lt;int&gt; 1, 4, 1, 8, 1, 10, 1, 1, 1, 2, 1, 1, 3, 1, 7, 4, 1, 1, 7, 1, 3, …\n$ V3    &lt;int&gt; 1, 4, 1, 8, 1, 10, 1, 2, 1, 1, 1, 1, 3, 1, 5, 6, 1, 1, 7, 1, 2, …\n$ V4    &lt;int&gt; 1, 5, 1, 1, 3, 8, 1, 1, 1, 1, 1, 1, 3, 1, 10, 4, 1, 1, 6, 1, 10,…\n$ V5    &lt;int&gt; 2, 7, 2, 3, 2, 7, 2, 2, 2, 2, 1, 2, 2, 2, 7, 6, 2, 2, 4, 2, 5, 6…\n$ V6    &lt;int&gt; 1, 10, 2, 4, 1, 10, 10, 1, 1, 1, 1, 1, 3, 3, 9, 1, 1, 1, 10, 1, …\n$ V7    &lt;int&gt; 3, 3, 3, 3, 3, 9, 3, 3, 1, 2, 3, 2, 4, 3, 5, 4, 2, 3, 4, 3, 5, 7…\n$ V8    &lt;int&gt; 1, 2, 1, 7, 1, 7, 1, 1, 1, 1, 1, 1, 4, 1, 5, 3, 1, 1, 1, 1, 4, 1…\n$ V9    &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 4, 1, 1, 1, 2, 1, 4, 1…\n$ class &lt;fct&gt; benign, benign, benign, benign, benign, malignant, benign, benig…\n\n\nIf you would like to see more information, type this in R:\n\n?biopsy\n\nAnswer the following questions.\n(a) Is this an observational study? Why or why not?\n(b) Is this a retrospective or prospective study? Or isn’t there enough information to tell? Justify your answer.\n(c) Below is a function you have not met before called summarise_if. What do you think this function is doing when being used with group_by as shown below? Run this code. what do you learn from the output?\n\nlibrary(tidyverse)\nbiopsy %&gt;% group_by(class) %&gt;% summarise_if(is.numeric, mean)\n\n# A tibble: 2 × 10\n  class        V1    V2    V3    V4    V5    V6    V7    V8    V9\n  &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 benign     2.96  1.33  1.44  1.36  2.12    NA  2.10  1.29  1.06\n2 malignant  7.20  6.57  6.56  5.55  5.30    NA  5.98  5.86  2.59\n\n\n(d) Note, when you run the code above, the summary for V6 has NAs. Try adding na.rm = TRUE to the summarise_if function and see what happens. What do you think this achieves?\n(e) Suppose you would like to predict, based on the attributes, whether the tumour was benign or malignant. Why would linear regression not be suitable in this case?\n(f) What is the code below doing and why?\n\nbiopsy &lt;- biopsy %&gt;% mutate(malignant = as.numeric(class == \"malignant\"))\n\n(g) Carry out a multiple logistic regression with this data using the binary response variable called malignant and predictors V1 - V9. What are the values of the coefficients?\n(h) The predictor V3 is a scale referring to the uniformity of cell shape. How would an increase of 1 unit in this scale affect the prediction of this model as to whether the tumour is malignant or benign?"
  },
  {
    "objectID": "5-ObservationalStudies.html#about-observational-studies",
    "href": "5-ObservationalStudies.html#about-observational-studies",
    "title": "Observational Studies",
    "section": "",
    "text": "Exposure: A variable that represents a factor of interest that may influence an outcome, such as a risk factor, treatment, behavior, or environmental condition (e.g., smoking, diet, air pollution, or a medical intervention).\nOutcome: The event or condition that is being studied as the possible effect of the exposure, such as disease occurrence, recovery, mortality, or any measurable health-related change (e.g., lung cancer, weight loss, or blood pressure levels).\nIn retrospective observational studies, investigators “look backwards in time” and use data that have already been collected. Retrospective studies are often criticized for having more confounding and bias compared to prospective studies.\nIn prospective observational studies, investigators choose a sample and collect new data generated from that sample. That is, the investigators “look forward in time.”\n\n\nIn observational studies, researchers examine the relationship between exposure and outcome without intervening, aiming to identify associations while controlling for confounders (more on this later).\n\nAn observational study on individuals from a random sample allows one to generalize conclusions about the sample to the population.\nAn observational study cannot show cause-and-effect relationships because there is the possibility that the response is affected by some variable(s) other than the ones being measured. That is, confounding variables may be present. “It ain’t what you don’t know that gets you into trouble. It’s what you know for sure that just ain’t so.” - Mark Twain"
  },
  {
    "objectID": "6-experiments.html",
    "href": "6-experiments.html",
    "title": "Experimental Studies",
    "section": "",
    "text": "Studies where the researchers assign treatments to cases are called experiments. When this assignment includes randomization, e.g., using a coin flip to decide which treatment a patient receives, it is called a randomized experiment. Randomized experiments are fundamentally important when trying to show a causal connection between two variables."
  },
  {
    "objectID": "6-experiments.html#establishing-causality",
    "href": "6-experiments.html#establishing-causality",
    "title": "Experimental Studies",
    "section": "Establishing Causality",
    "text": "Establishing Causality\n\nA treatment (exposure variable) will often be a binary variable that is either 0 or 1. It is 0 if the person is not treated, which is to say they are in the control group, and 1 if they are treated.\nWe will typically have some outcome of interest, Y, for each person or observational unit, and that could be categorical or continuous.\nA treatment is causal if the outcome for a person, given they were not treated, is different to their outcome given they were treated.\nIf we could both treat and control the one individual at the one time, then we would know that it was only the treatment that had caused any change. However, the fundamental problem of causal inference is that we cannot both treat and control the same individual at the same time.\n\nwe instead compare the average of two groups — all those treated and all those not.\nwe estimate the counterfactual at a group level because of the impossibility of doing it at an individual level.\nthis trade-off allows us to move forward but comes at the cost of certainty.\nwe must instead rely on randomization, probabilities, and expectations."
  },
  {
    "objectID": "6-experiments.html#controlled-experiments",
    "href": "6-experiments.html#controlled-experiments",
    "title": "Experimental Studies",
    "section": "Controlled Experiments",
    "text": "Controlled Experiments\nControlled experiments are a scientific test (or a series of tests) to verify how one or more conditions (treatments - variables that are controlled by the scientist) effect one or more outcome (response) variables. We usually consider a default of there being no effect and we look for evidence that would cause us to change our mind.\nDesign of experiments can produce an experiment that efficiently answers the questions of interest. The scientific method involves:\n(a) Stating a hypothesis\n(b) Planning an experiment to objectively test the hypothesis\n(c) Observing and carefully collecting data\n(d) Interpreting experimental results"
  },
  {
    "objectID": "6-experiments.html#principles-of-experimental-design",
    "href": "6-experiments.html#principles-of-experimental-design",
    "title": "Experimental Studies",
    "section": "Principles of Experimental Design",
    "text": "Principles of Experimental Design\n\nRandomization. Subjects should be randomly selected from the population (where possible) and randomly divided into treatment groups to avoid unintentional selection bias in the groups and to account for variables that cannot be controlled. For example, some patients may be more susceptible to a disease than others due to their dietary habits. In this example dietary habit is a confounding variable, which is defined as a variable that is associated with both the exposure and outcome variables. Randomizing patients into the treatment or control group helps even out such differences.\n\n\n\nReplication. A sufficient number of subjects should be used to ensure that randomization creates groups that resemble each other closely and to increase the chances of detecting differences among the treatments when such differences actually exist. In a single study, we replicate by collecting a sufficiently large sample. What is considered sufficiently large varies from experiment to experiment, but at a minimum we want to have multiple subjects per treatment group.\nLocal Control (Blocking). Researchers sometimes know or suspect that variables, other than the treatment, influence the response. Under these circumstances, they may first group individuals based on this variable into blocks and then randomize cases within each block to the treatment groups. This strategy is often referred to as blocking. For instance, if we are looking at the effect of a drug on heart attacks, we might first split patients in the study into low-risk and high-risk blocks, then randomly assign half the patients from each block to the control group and the other half to the treatment group. This strategy ensures that each treatment group has the same number of low-risk patients and the same number of high-risk patients."
  },
  {
    "objectID": "6-experiments.html#steps-of-experimentation",
    "href": "6-experiments.html#steps-of-experimentation",
    "title": "Experimental Studies",
    "section": "Steps of Experimentation",
    "text": "Steps of Experimentation\n\n1. Define the Problem and Objectives\n\nClearly state the research question and objectives.\nEstablish a logical progression: Objectives → Scientific Hypotheses → Statistical Hypotheses.\nExamples:\n\nInvestigate the effect of Vitamin C on odontoblast length (cells responsible for tooth growth).\nDetermine the lethal dose of a pesticide for an agricultural pest.\nIdentify the optimal temperature settings for efficient machine operation.\n\n\n\n\n2. Define Experimental Conditions\n\nControlled conditions: Experiments conducted in controlled environments (e.g., greenhouses, laboratories, experimental stations).\n\nLess controlled conditions: Field studies in natural settings (e.g., farms, forests).\n\n\n\n3. Identify Variables of Interest\n\nOutcome Variable (response variable): The outcome being measured.\n\nExample: Odontoblast length in guinea pigs, blood pressure rates.\n\nTreatment Factors and Levels (exposure variables): Variables manipulated in the experiment.\n\nQuantitative example: Vitamin C dose (0.5, 1, 2 mg/day).\nQualitative example: Diet type (natural vs. artificial).\n\nLocal Control (Blocking) Factors: Variables controlled to reduce variability (e.g., environmental conditions, batch effects).\n\n\n\n4. Identify Experimental and Observational Units\n\nExperimental Unit: The smallest unit to which a treatment is randomly assigned.\n\nExamples: 60 guinea pigs, a plot of land with 200 trees, a section of a laboratory bench with 20 Petri dishes.\n\nObservational Unit: The entity from which data is collected.\n\nExamples: A single insect, tree, or Petri dish.\n\n\n\n\n5. Define Observations to be Made\n\nQualitative Observations: Presence or absence of a feature (e.g., morphological traits).\n\nQuantitative Observations: Measurable data (e.g., weight, height, count, proportion).\n\nOrdered Observations: Ranked data with an inherent order (e.g., disease severity, grading scales).\n\n\n\n6. Select the Experimental Design\n\nChoose the simplest design that meets the study’s needs without oversimplifying.\n\n\n\n7. Conduct the Experiment\n\nEnsure bias-free procedures by considering:\n\nWho is conducting the experiment.\nThe location of the experiment.\nStart and end dates.\nThe relevance and feasibility of the experiment.\nAssociated costs.\n\n\n\n\n8. Analyze Data and Interpret Results\n\nConduct analysis according to the experimental design.\nInterpret results within the context of:\n\nExperimental conditions.\nTested hypotheses.\nEstablished scientific knowledge.\n\nConsider the potential consequences of incorrect conclusions."
  },
  {
    "objectID": "6-experiments.html#more-on-randomization",
    "href": "6-experiments.html#more-on-randomization",
    "title": "Experimental Studies",
    "section": "More on Randomization",
    "text": "More on Randomization\nThe key to telling a causal story is the counterfactual: what would have happened in the absence of the treatment. This means that establishing the control group is critical because when we do that, we establish the counterfactual. What we hope to be able to do is to find treatment and control groups that are the same, but for the treatment.\n\nThe benefits to randomization are:\n\nIf a random assignment of treatment and controls groups is done then significant results can be concluded as causal or cause and effect conclusions. That is, that the treatment caused the result.\nIf random selection is done where the subjects are randomly selected from some population, then the results can be extended to that population. The random assignment is required for an experiment. When both random assignment and random selection are part of the study then we have a completely randomized experiment. Without random assignment (i.e., an observational study) then the treatment can only be referred to as being related to the outcome.\n\nTo explore ideas of randomization, we simulate a population, and then randomly sample from it. We will set it up so that 20% of the population are smokers, and the rest are not.\n\nset.seed(853)\n\nnumber_of_people &lt;- 5000\n\npopulation &lt;-\n  tibble(\n    person = c(1:number_of_people),\n    smoking_status = sample(\n      x = c(\"Smoker\", \"Non-Smoker\"),\n      size  = number_of_people,\n      replace = TRUE,\n      prob = c(0.2,0.8)\n    )\n  )\n\nLet’s look at population characteristics\n\npopulation %&gt;% \n  count(smoking_status)\n\n# A tibble: 2 × 2\n  smoking_status     n\n  &lt;chr&gt;          &lt;int&gt;\n1 Non-Smoker      4003\n2 Smoker           997\n\n\nNow let’s sample from the population and randomly assign a treatment and control group.\n\nset.seed(853)\n\nsample_size &lt;- 1000\n\nsample &lt;-\n  population %&gt;% \n  sample_n(sample_size) %&gt;% \n  mutate(group = sample(\n    x = c(\"Treatment\", \"Control\"),\n    size  = sample_size,\n    replace = TRUE\n  ))\n\nNow let’s look at sample characteristics within each group (treatment and control). Is the distribution of population characteristics reflected within each group?\n\nsample %&gt;% \n  count(group,  smoking_status) %&gt;% \n  group_by(group) %&gt;% \n  mutate(prop = n / sum(n)) \n\n# A tibble: 4 × 4\n# Groups:   group [2]\n  group     smoking_status     n  prop\n  &lt;chr&gt;     &lt;chr&gt;          &lt;int&gt; &lt;dbl&gt;\n1 Control   Non-Smoker       364 0.747\n2 Control   Smoker           123 0.253\n3 Treatment Non-Smoker       415 0.809\n4 Treatment Smoker            98 0.191\n\n\n\n\n\nInternal Validity\n\nInternal validity is achieved when the only difference between the treatment and control groups is the treatment itself.\n\nThis ensures that the control group serves as a true counterfactual, allowing us to attribute differences in outcomes solely to the treatment.\n\nIn other words, our estimates reflect the true effect of the treatment rather than other confounding factors.\n\nWith strong internal validity, we can confidently make claims about causal relationships within the experiment.\n\n\n\nExternal Validity\n\nExternal validity refers to whether our experimental findings generalize beyond the study.\n\nThis requires:\n\nA sample that represents the broader population.\n\nAn experimental setup that mirrors real-world conditions.\n\n\nIf these conditions hold, our results are applicable outside the experiment.\n\nRandomization is key to achieving external validity:\n\nFirst, random selection ensures that the study group is representative.\n\nSecond, random assignment to treatment and control ensures comparability within the experiment.\n\n\n\n\n\nExample: Tooth Growth\nToothGrowth is a built-in R dataset from a study that examined the effect of Vitamin C dose and delivery on the length of the odontoplasts, the cells responsible for teeth growth, in 60 guinea pigs, where tooth length was the measured outcome variable.\n\nRandomization\nRandomization of subjects in an experiment helps spread any variability that exists naturally between subjects evenly across groups.\nIn the experiment that yielded the ToothGrowth dataset, guinea pigs were randomized to receive Vitamin C either through orange juice or ascorbic acid, indicated in the dataset by the supp variable.\n\ndata(\"ToothGrowth\")\n\n\n\nReplication\nReplication means you need to conduct an experiment with an adequate number of subjects to achieve an acceptable statistical power.\nLet’s examine the ToothGrowth dataset to make sure they followed the principle of replication. We’ll use a dplyr function called count to help us.\n\nToothGrowth %&gt;% count(supp)\n\n  supp  n\n1   OJ 30\n2   VC 30\n\n\n\n\nAnalysis\nSuppose you know from previous studies that the average length of a guinea pigs odontoplasts is 18 micrometers. Therefore, you hypothesize that odontoplast length is equal to 18. To “test” this hypothesis, let’s see how the value of 18 compares to our sample data by looking at the mean and standard deviation.\n\nToothGrowth %&gt;% pull(len) %&gt;% mean\n\n[1] 18.81333\n\n\nIt’s natural to wonder if there is a difference in tooth length by supplement type. Use group_by and summarise to explore this and create an appropriate visualization using ggplot.\n\nToothGrowth %&gt;%"
  },
  {
    "objectID": "6-experiments.html#more-on-blocking",
    "href": "6-experiments.html#more-on-blocking",
    "title": "Experimental Studies",
    "section": "More on Blocking",
    "text": "More on Blocking\nOften there are covariates in the experimental units that are known to affect the response variable and must be taken into account. Ideally an experimenter can group the experimental units into blocks where the within block variance is small, but the block to block variability is large.\n\nFor example, in testing a drug to prevent heart disease, we know that gender and age also impact the outcome. We may want to partition our study participants into gender and age groups and then randomly assign the treatment (placebo vs drug) within the group.\n\nOften blocking variables are not the variables that we are primarily interested in, but must nevertheless be considered.\n\nRandomized Complete Block Design (RCBD)\n\nThe goal of RCBD is to maximize differences between blocks while ensuring similarity within each block.\n\nThis design helps control for known sources of variability, such as:\n\nTemperature differences within a greenhouse.\n\nVariation across different days.\n\nVariation in fertility or drainage differences in a field\n\n\nKey features:\n\nEach block acts as a replicate.\n\nThe number of observational units per block equals the number of treatments.\n\nEach treatment appears exactly once per block, with the order randomized within the block.\n\n\n\n\n\n\n\n\nExamples of blocks\n\nLaboratory chamber with a humidity gradient inside\n\n\n\nLaboratory chambers with homogeneous temperature and humidity inside\n\n\n\nA field with a fertility gradient\n\n\n\nA greenhouse with a temperature gradient during the day\n\n\n\n\n\nExample: Oatvar\nThe dataset oatvar in the faraway library contains information about an experiment on eight different varieties of oats.\n\nThe area in which the experiment was done had some systematic variability and the researchers divided the area up into five different blocks in which they felt the area inside a block was uniform while acknowledging that some blocks are likely superior to others for growing crops.\nWithin each block, the researchers created eight plots and randomly assigned a variety to a plot. This type of design is called a Randomized Complete Block Design (RCBD) because each block contains all possible levels of the factor of primary interest.\n\nVisualise the data\n\noatvar &lt;- faraway::oatvar\n\nggplot(oatvar, aes(y=yield, x=block, colour = variety, group = variety)) + \n  geom_point(size = 5) +\n  geom_line()\n\n\n\n\n\n\n\n\nUse group_by and summarise to look at the average yield within each variety.\n\noatvar %&gt;% \n\nLook at the results of using lm with variety and block as predictors.\n\nlm(....)"
  },
  {
    "objectID": "6-experiments.html#factorial-experiments",
    "href": "6-experiments.html#factorial-experiments",
    "title": "Experimental Studies",
    "section": "Factorial Experiments",
    "text": "Factorial Experiments\nExperiments that involve more than one treatment factor are called factorial experiments. In general, the number of treatments in a factorial experiment is the product of the numbers of levels of the treatment factors. The disadvantage of this is that the number of treatments increase very quickly.\nExample: Pest control\n\nFactor 1: two pesticides (A and B)\nFactor 2: two doses\nThe experiment has a total of \\(2\\times 2 = 4\\) treatments\n\nExample: The Tooth Growth data\n\nFactor 1: two deliveries of vitamin C (orange juice, ascorbic acid)\nFactor 2: three doses (0.5, 1, and 2 mg/day)\nThe experiment has a total of \\(2\\times 3 = 6\\) treatments\n\n\n\n\n\nDesigns\nFor the Pesticide example, suppose 3 replicates and a completely randomized design\n\nFor the Pesticide example, suppose 3 replicates and a randomized complete block design\n\n\n\nInteractions\nThe major advantage of factorial experiments is that they allow for the detection of interactions.\n\nTwo factors are said to interact if the effect of one, on the response variable, depends upon the level of the other.\nIf they do not interact, they are said to be independent.\n\n\nInteraction Plots\nA set of parallel lines indicates no interaction\n\nThe crossing over of lines indicates an interaction"
  },
  {
    "objectID": "6-experiments.html#factorial-experiments-tooth-growth",
    "href": "6-experiments.html#factorial-experiments-tooth-growth",
    "title": "Experimental Studies",
    "section": "Factorial Experiments: Tooth Growth",
    "text": "Factorial Experiments: Tooth Growth\nWe’ve already seen to Tooth Growth data that examined the effect of Vitamin C delivery and dose on the length of the odontoplasts, the cells responsible for teeth growth, in 60 guinea pigs, where tooth length was the measured outcome variable.\nWe initially looked at how the Vitamin C delivery impacted tooth growth. Now lets consider what happens when we bring dose into the analysis. In this case we have two factors to consider instead of 1.\n\nVitamin C delivery has 2 levels\ndose has 3 levels (0.5, 1, and 2 mg/day)\n\n\ndata(\"ToothGrowth\")\n\nggplot(ToothGrowth, aes(x = as.factor(dose), y = len, colour = supp)) +\n  geom_boxplot()"
  },
  {
    "objectID": "Assignment2_soln.html#exercise",
    "href": "Assignment2_soln.html#exercise",
    "title": "DS152 Introduction to Data Science (2)",
    "section": "Exercise",
    "text": "Exercise\nFor this exercise, we will work with the Cars93 data frame from package MASS. Open an R session in the R Studio Server, and type in the code below to glimpse the dataset and access the help file to see more information on the data.\n\nlibrary(tidyverse)\nCars93 &lt;- MASS::Cars93\n\nglimpse(Cars93)\n?Cars93\n\n\nHow many observations and how many variables are in the Cars93 dataset? [2 Marks]\n\n\n93 observations, 27 variables\n\n\nSuppose we would like to predict the Price of the cars. Why would logistic regression not be suitable in this case? [2 Marks]\n\n\nLogistic regression is not suitable for a continuous response variable.\n\n\nAssume you want to fit a simple linear regression model to predict Price using Horsepower as the predictor. How would you fill the gaps, [A], [B], [C] and [D] in the code below to fit the linear regression model? [8 Marks]\n\n\nlm_mod1 &lt;-  lm(Price ~ Horsepower, data = Cars93)\n\n[A] = lm\n[B] = Price\n[C] = Horsepower\n[D] = Cars93\n\nAfter fitting the linear regression model and inspecting the estimated coefficients, we obtain the following results in R:\n\n\nlm_mod1 \n\n\nCall:\nlm(formula = Price ~ Horsepower, data = Cars93)\n\nCoefficients:\n(Intercept)   Horsepower  \n    -1.3988       0.1454  \n\n\nWhat would the predicted Price be if Horsepower was 100? [4 Marks]\n\n-1.3988 + 0.1454*100 = 13.1412\n\n\nBriefly explain, in your own words, why the plot being created with the code below is useful. [4 Marks]\n\n\nCars93_pred &lt;- Cars93 %&gt;%  mutate(price_pred = predict(lm_mod1))\n\nggplot(data = Cars93_pred,\n       mapping = aes(x = Price, y = price_pred)) +\n  theme_bw() +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1) +\n  xlab(\"Observed CL\") + \n  ylab(\"Predicted CL\")\n\n\n\n\n\n\n\n\n\nThis code is adding the model predictions of Price to the Cars93 data and creating a new dataset called Cars93_pred. Then the plot is comparing the predicted values to the observed values. The inclusion of the identity line allows for a good visual as to whether or not the model is doing a good job (if points fall along/close to the line the model is predicting well).\n\n\nNow fit a multiple linear regression using the predictor variables: MPG.city, MPG.highway, EngineSize, Horsepower, RPM, Rev.per.mile, Fuel.tank.capacity, and Width. Save this model as lm_mod2. Look at the estimated coefficients. Which ones seem to be negatively related to the response Price? [3 Marks]\n\n\nlm_mod2 &lt;-  lm(Price ~ MPG.city + MPG.highway + EngineSize + \n                 Horsepower + RPM + Rev.per.mile + \n                 Fuel.tank.capacity + Width  , data = Cars93)\n\nlm_mod2\n\n\nCall:\nlm(formula = Price ~ MPG.city + MPG.highway + EngineSize + Horsepower + \n    RPM + Rev.per.mile + Fuel.tank.capacity + Width, data = Cars93)\n\nCoefficients:\n       (Intercept)            MPG.city         MPG.highway          EngineSize  \n        60.2504279          -0.3741466           0.1068101           2.7994488  \n        Horsepower                 RPM        Rev.per.mile  Fuel.tank.capacity  \n         0.1303995          -0.0009222           0.0034005           0.5163990  \n             Width  \n        -1.0575538  \n\n\n\nMPG.city and Width are having a negative impact. MPG.highway, EngineSize, Horsepower and Fuel.tank.capacity are having a positive impact. RPM and Rev.per.mile don’t seem to be having much of an impact at all.\n\n\nCreate the plot shown in (e) but instead use lm_mod2 to get your predictions. Which model appears to perform better in terms of prediction, give a reason for your answer. [4 Marks]\n\n\nCars93_pred &lt;- Cars93 %&gt;%  mutate(price_pred2 = predict(lm_mod2))\n\nggplot(data = Cars93_pred,\n       mapping = aes(x = Price, y = price_pred2)) +\n  theme_bw() +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1) +\n  xlab(\"Observed CL\") + \n  ylab(\"Predicted CL\")\n\n\n\n\n\n\n\n\n\nModel 2 appears to be performing better as the points are generally closer to the identity line.\n\n\nBelow we present the sum of the squared residuals (discrepancy) for both model fits. Which one (model A or B) is more likely to correspond to the multiple linear regression (lm_mod2)? Justify your answer. [3 Marks]\n\n\n\n model A  model B \n2755.807 3250.881 \n\n\n\n“model A” is the multiple regression as the sum of the squared residuals is lower. The reason for this is that the model with more predictors is explaining more of the variation in price and is a better fit for the data."
  },
  {
    "objectID": "Assignment3.html",
    "href": "Assignment3.html",
    "title": "DS152 Introduction to Data Science (2)",
    "section": "",
    "text": "Answer all questions for continuous assessment. Due: 4pm on Friday, 14th March 2025."
  },
  {
    "objectID": "Assignment3.html#question-1",
    "href": "Assignment3.html#question-1",
    "title": "DS152 Introduction to Data Science (2)",
    "section": "Question 1",
    "text": "Question 1\n\nAn organization has 500 employees and the HR team decides to conduct a focus group to explore ideas for team building activities. From the list of employee emails they randomly sample 25 to take part in their focus group.\n\nThis is an example of\n\nSimple random sampling\nCluster sampling\nStratified sampling\nSystematic sampling\n\n\n\nSuppose you are studying rural communities in Ireland. To survey residents of rural areas you pick a random sample of 10 rural communities and focus your efforts on surveying people within those randomly chosen communities.\n\nThis is an example of\n\nSimple random sampling\nCluster sampling\nStratified sampling\nSystematic sampling"
  },
  {
    "objectID": "Assignment3.html#question-2",
    "href": "Assignment3.html#question-2",
    "title": "DS152 Introduction to Data Science (2)",
    "section": "Question 2",
    "text": "Question 2\nData was collected on 400 individuals to examine the relationship between a person’s income and credit card debt. The variable for credit card debt is called Balance. Other variables like credit limit brackets (limit_bracket) and marital status (Married) are included in the dataset as well. A glimpse of the dataset is shown below.\n\nglimpse(credit_dat)\n\nRows: 400\nColumns: 12\n$ ID            &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ Income        &lt;dbl&gt; 14.891, 106.025, 104.593, 148.924, 55.882, 80.180, 20.99…\n$ Rating        &lt;dbl&gt; 283, 483, 514, 681, 357, 569, 259, 512, 266, 491, 589, 1…\n$ Cards         &lt;dbl&gt; 2, 3, 4, 3, 2, 4, 2, 2, 5, 3, 4, 3, 1, 1, 2, 3, 3, 3, 1,…\n$ Age           &lt;dbl&gt; 34, 82, 71, 36, 68, 77, 37, 87, 66, 41, 30, 64, 57, 49, …\n$ Education     &lt;dbl&gt; 11, 15, 11, 11, 16, 10, 12, 9, 13, 19, 14, 16, 7, 9, 13,…\n$ Gender        &lt;chr&gt; \"Male\", \"Female\", \"Male\", \"Female\", \"Male\", \"Male\", \"Fem…\n$ Student       &lt;chr&gt; \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"…\n$ Married       &lt;chr&gt; \"Yes\", \"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\",…\n$ Ethnicity     &lt;chr&gt; \"Caucasian\", \"Asian\", \"Asian\", \"Asian\", \"Caucasian\", \"Ca…\n$ Balance       &lt;dbl&gt; 333, 903, 580, 964, 331, 1151, 203, 872, 279, 1350, 1407…\n$ limit_bracket &lt;fct&gt; medium-low, high, high, high, medium-high, high, medium-…\n\n\n\nThe plot below shows the relationship between credit card debt (Balance) and Income. Briefly describe the relationship in your own words.\n\n\n\n\n\n\n\n\n\n\n\nAssume you now want to visualise the same information in (a) but also include the credit-limit variable (limit_bracket). Replace [A], [B], [C], [D], and [E] in the code below to produce the following plot:\n\n\n  ggplot(credit_dat, aes(x = [A], y = [B], [C] = limit_bracket)) +\n  geom_[D]() +\n  geom_smooth(method = [E])\n\n\n\n\n\n\n\n\n\n\n[A] =\n[B] =\n[C] =\n[D] =\n[E] =\n\nFrom looking at the plot in (b), what impact does including information on credit limits have on how you interpret the relationship between credit-card debt and income? Does Simpson’s Paradox happen here?\n\n\nAssume you now want to calculate the average Balance and the average Income within each credit-limit bracket. Replace [A], [B], [C] and [D] in the code below to produce the following summary table:\n\n\n\n# A tibble: 4 × 3\n  limit_bracket mean_income mean_balance\n  &lt;fct&gt;               &lt;dbl&gt;        &lt;dbl&gt;\n1 low                  24.9         33.0\n2 medium-low           29.8        323. \n3 medium-high          38.3        679. \n4 high                 88.0       1045. \n\n\n\ncredit_dat %&gt;% \n  group_by([A]) %&gt;% \n  [B](mean_income = mean([C]),\n      [D] = mean(Balance))\n\nA =\nB =\nC =\nD =\n\nHow does the summary in (d) help to explain why the credit limit variable (limit_bracket) is a confounding variable when looking at the relationship between credit-card debt and income?"
  },
  {
    "objectID": "Assignment3.html#instructions",
    "href": "Assignment3.html#instructions",
    "title": "DS152 Introduction to Data Science (2)",
    "section": "",
    "text": "Answer all questions for continuous assessment. Due: 4pm on Friday, 14th March 2025."
  },
  {
    "objectID": "7-PredictiveAnalytics.html",
    "href": "7-PredictiveAnalytics.html",
    "title": "Predictive Analytics",
    "section": "",
    "text": "Analyzes historical and current data to make predictions about future events or behaviors\nCombines statistical techniques, machine learning algorithms, and data mining to identify patterns and trends\nUsed in many areas, e.g. insurance companies, banks, stock market, medical research, ecological monitoring, etc\n\n\n\n\nData collection gathers relevant information from various sources\nData preprocessing cleans and transforms raw data into a suitable format for analysis\nFeature engineering creates new variables or selects relevant features to improve model performance\nModel development builds and trains predictive algorithms using historical data\nModel evaluation assesses the accuracy and reliability of predictions using various metrics\n\n\n\n\n\nStructured data organized in predefined formats (spreadsheets)\nUnstructured data lacks a predefined structure (text documents, images, videos)\nTime series data represents observations collected at regular intervals over time (stock prices, weather data)\nCross-sectional data captures information from multiple subjects at a single point in time (survey responses)"
  },
  {
    "objectID": "7-PredictiveAnalytics.html#classification-trees",
    "href": "7-PredictiveAnalytics.html#classification-trees",
    "title": "Predictive Analytics",
    "section": "Classification trees",
    "text": "Classification trees\nClassification trees can be used to create predictions for a categorical variable.\nThe basic idea is to split the predictors so as to minimise the classification error. There are many algorithms that can be used to produce a classification tree, and different criteria to be minimised so as to improve predictive power.\nEach split is , i.e. two branches are generated. At the end of the tree we have the or . In the case of a classification tree, the predictions will be the classes for the majority of observations belonging to that terminal node.\nSee below for an example of a classification tree –"
  },
  {
    "objectID": "7-PredictiveAnalytics.html#k-nearest-neighbours",
    "href": "7-PredictiveAnalytics.html#k-nearest-neighbours",
    "title": "Predictive Analytics",
    "section": "K-nearest neighbours",
    "text": "K-nearest neighbours\nImagine we want to predict whether a film is classified as action or romance, based on two variables: number of kisses or number of kicks that appear in the film. Suppose that we have a database of films and the data looks like this:\n\n\nRows: 20\nColumns: 3\n$ kicks  &lt;dbl&gt; 3, 2, 5, 4, 5, 7, 3, 5, 6, 3, 16, 16, 13, 11, 10, 17, 12, 15, 8…\n$ kisses &lt;dbl&gt; 20, 17, 16, 14, 12, 9, 12, 19, 17, 27, 3, 2, 2, 4, 3, 3, 2, 5, …\n$ genre  &lt;chr&gt; \"romance\", \"romance\", \"romance\", \"romance\", \"romance\", \"romance…\n\n\n\n\n\n\n\n\n\nWhat genre is the film represented by a black dot? We could employ the \\(k\\)-nearest neighbours algorithm to classify it. If we choose, e.g. \\(k=5\\), then we would have 4 out of the 5 nearest neighbours classified as an action film. Therefore, the algorithm would classify the film represented by the black dot as an action film as well.\nThis is an example with two predictors, but this can be easily extended to higher dimensions."
  },
  {
    "objectID": "7-PredictiveAnalytics.html#example-diabetes-in-pima-indian-women-data",
    "href": "7-PredictiveAnalytics.html#example-diabetes-in-pima-indian-women-data",
    "title": "Predictive Analytics",
    "section": "Example: Diabetes in Pima Indian Women data",
    "text": "Example: Diabetes in Pima Indian Women data\nWe will now use logistic regression, a classification tree, and the k-nearest neighbours algorithm to predict whether a woman in the Pima.tr dataset has diabetes or not.\nThe Pima.tr dataset from package MASS has been used before during a lab. It has information on several biomarkers, such as glucose levels and blood pressure, as well as other variables such as age. The response type indicates whether that particular individual had diabetes or not. Our objective is to predict whether a woman has diabetes using information from the other variables in the dataset.\n\nPima.tr &lt;- MASS::Pima.tr\nglimpse(Pima.tr)\n\nRows: 200\nColumns: 8\n$ npreg &lt;int&gt; 5, 7, 5, 0, 0, 5, 3, 1, 3, 2, 0, 9, 1, 12, 1, 4, 1, 11, 1, 0, 2,…\n$ glu   &lt;int&gt; 86, 195, 77, 165, 107, 97, 83, 193, 142, 128, 137, 154, 189, 92,…\n$ bp    &lt;int&gt; 68, 70, 82, 76, 60, 76, 58, 50, 80, 78, 40, 78, 60, 62, 66, 76, …\n$ skin  &lt;int&gt; 28, 33, 41, 43, 25, 27, 31, 16, 15, 37, 35, 30, 23, 7, 52, 15, 8…\n$ bmi   &lt;dbl&gt; 30.2, 25.1, 35.8, 47.9, 26.4, 35.6, 34.3, 25.9, 32.4, 43.3, 43.1…\n$ ped   &lt;dbl&gt; 0.364, 0.163, 0.156, 0.259, 0.133, 0.378, 0.336, 0.655, 0.200, 1…\n$ age   &lt;int&gt; 24, 55, 35, 26, 23, 52, 25, 24, 63, 31, 33, 45, 59, 44, 29, 21, …\n$ type  &lt;fct&gt; No, Yes, No, No, No, Yes, No, No, No, Yes, Yes, No, Yes, Yes, No…\n\n\nLet’s split our data\n\nlibrary(rsample)\n# Fix random numbers by setting the seed \nset.seed(1116)\n# Put 80% of the data into the training set \npima_split &lt;- initial_split(Pima.tr, prop = 0.80)\n# Create data frames for the two sets:\ntrain_pima_data &lt;- training(pima_split)\ntest_pima_data  &lt;- testing(pima_split)\n\nWe will start with logistic regression\nLet’s fit a multiple logistic regression model:\n\nfit_logistic &lt;- glm(type ~ ., family = binomial, data = train_pima_data)\nfit_logistic\n\n\nCall:  glm(formula = type ~ ., family = binomial, data = train_pima_data)\n\nCoefficients:\n(Intercept)        npreg          glu           bp         skin          bmi  \n -12.565120     0.053341     0.028476     0.005766     0.001172     0.139419  \n        ped          age  \n   2.263408     0.060450  \n\nDegrees of Freedom: 159 Total (i.e. Null);  152 Residual\nNull Deviance:      204.6 \nResidual Deviance: 134.7    AIC: 150.7\n\n\nWe can use the predict function to obtain predictions for each individual in the dataset:\n\npima_res_test &lt;- test_pima_data %&gt;%\n                  mutate(pred_p = \n                         predict(fit_logistic, \n                                     type = \"response\", newdata = test_pima_data)) %&gt;% \n   mutate(pred_type = ifelse(pred_p &gt;=0.5,\"yes\",\"no\"))\n\npima_res_test\n\n   npreg glu  bp skin  bmi   ped age type      pred_p pred_type\n1      7 195  70   33 25.1 0.163  55  Yes 0.730366555       yes\n2      0 165  76   43 47.9 0.259  26   No 0.811244142       yes\n3      1 189  60   23 30.1 0.398  59  Yes 0.870681831       yes\n4      4  99  76   15 23.2 0.223  21   No 0.016821666        no\n5      1  87  68   34 37.6 0.401  24   No 0.119008947        no\n6      1  79  80   25 25.4 0.583  22   No 0.027096514        no\n7      0 119  66   27 38.8 0.259  22   No 0.191746781        no\n8      3 171  72   33 33.3 0.199  24  Yes 0.368649896        no\n9      4 127  88   11 34.5 0.598  28   No 0.411219278        no\n10     1 124  74   36 27.8 0.100  30   No 0.069383986        no\n11     6 109  60   27 25.0 0.206  27   No 0.039936807        no\n12     5 139  80   35 31.6 0.361  25  Yes 0.248995767        no\n13     6 134  70   23 35.4 0.542  29  Yes 0.479145323        no\n14     3 106  54   21 30.9 0.292  24   No 0.067175718        no\n15     0 135  94   46 40.6 0.284  26   No 0.437816778        no\n16     1 168  88   29 35.0 0.905  52  Yes 0.947101920       yes\n17     1 144  82   46 46.1 0.335  46  Yes 0.889106686       yes\n18    12 121  78   17 26.5 0.259  62   No 0.504745008       yes\n19     6 125  78   31 27.6 0.565  49  Yes 0.472366580        no\n20     1  79  75   30 32.0 0.396  22   No 0.042821739        no\n21     4 112  78   40 39.4 0.236  38   No 0.415459765        no\n22     2  94  76   18 31.6 0.649  23   No 0.113303157        no\n23     2  84  50   23 30.4 0.968  21   No 0.113806856        no\n24     4 117  62   12 29.7 0.380  30  Yes 0.137742566        no\n25     1  81  74   41 46.3 1.096  32   No 0.757626954       yes\n26     1 120  80   48 38.9 1.162  41   No 0.875970147       yes\n27     7 187  68   39 37.7 0.254  41  Yes 0.867670601       yes\n28     7 179  95   31 34.2 0.164  60   No 0.905158936       yes\n29     6  80  66   30 26.2 0.313  41   No 0.062292657        no\n30     1  97  70   15 18.2 0.147  21   No 0.005547706        no\n31     0 100  88   60 46.8 0.962  31   No 0.807891465       yes\n32     6 154  78   41 46.1 0.571  27   No 0.879721246       yes\n33     2  56  56   28 24.2 0.332  22   No 0.006350983        no\n34     0 188  82   14 32.0 0.682  22  Yes 0.648518039       yes\n35     2 197  70   99 34.7 0.575  62  Yes 0.972298384       yes\n36     2 142  82   18 24.7 0.761  21   No 0.184614941        no\n37     1 164  82   43 32.8 0.341  50   No 0.740536767       yes\n38     6 144  72   27 33.9 0.255  40   No 0.505934522       yes\n39    14 175  62   30 33.6 0.212  38  Yes 0.734781108       yes\n40     1 133 102   28 32.8 0.234  45  Yes 0.430286553        no\n\n\nWe set the threshold for prediction as threshold = 0.50, now we can have a look at the accuracy of the method:\n\nN &lt;- nrow(pima_res_test)\n\nconfusion_mat &lt;- table(pima_res_test %&gt;% select(type, pred_type))\nconfusion_mat\n\n     pred_type\ntype  no yes\n  No  17   9\n  Yes  6   8\n\naccuracy &lt;- (confusion_mat %&gt;% diag %&gt;% sum)/N\naccuracy\n\n[1] 0.625\n\n\n\nOverall accuracy \\(= (17+8)/(17+9+6+8) = 0.625\\)\nTrue positive rate (TPR) = TP/(TP + FN) \\(= 8/(8+6) = 0.57\\)\n\nTPR is the probability that an actual positive will be classified as positive. This is also known as sensitivity.\n\nTrue negative rate (TNR) = TN/(TN + FP) \\(= 17/(17+9) = 0.65\\)\n\nTNR is the probability that an actual negative will be classified as negative. This is also known as specificity.\n\n\nNow we will fit a classification tree\n\nfit_tree &lt;- rpart(type ~ ., data = train_pima_data)\nrpart.plot(fit_tree)\n\n\n\n\n\n\n\n\nLet’s check the predictions:\n\npima_res_test2 &lt;- test_pima_data %&gt;%\n                  mutate(pred_p = \n                         predict(fit_tree, \n                                 newdata = test_pima_data) %&gt;% as_tibble() %&gt;% pull(Yes)) %&gt;% \n                  mutate(pred_type = ifelse(pred_p &gt;=0.5,\"yes\",\"no\"))\n\npima_res_test2\n\n   npreg glu  bp skin  bmi   ped age type     pred_p pred_type\n1      7 195  70   33 25.1 0.163  55  Yes 0.33333333        no\n2      0 165  76   43 47.9 0.259  26   No 0.84375000       yes\n3      1 189  60   23 30.1 0.398  59  Yes 0.33333333        no\n4      4  99  76   15 23.2 0.223  21   No 0.07246377        no\n5      1  87  68   34 37.6 0.401  24   No 0.07246377        no\n6      1  79  80   25 25.4 0.583  22   No 0.07246377        no\n7      0 119  66   27 38.8 0.259  22   No 0.07246377        no\n8      3 171  72   33 33.3 0.199  24  Yes 0.00000000        no\n9      4 127  88   11 34.5 0.598  28   No 0.84375000       yes\n10     1 124  74   36 27.8 0.100  30   No 0.33333333        no\n11     6 109  60   27 25.0 0.206  27   No 0.07246377        no\n12     5 139  80   35 31.6 0.361  25  Yes 0.00000000        no\n13     6 134  70   23 35.4 0.542  29  Yes 0.84375000       yes\n14     3 106  54   21 30.9 0.292  24   No 0.07246377        no\n15     0 135  94   46 40.6 0.284  26   No 0.84375000       yes\n16     1 168  88   29 35.0 0.905  52  Yes 0.84375000       yes\n17     1 144  82   46 46.1 0.335  46  Yes 0.84375000       yes\n18    12 121  78   17 26.5 0.259  62   No 0.11111111        no\n19     6 125  78   31 27.6 0.565  49  Yes 0.80000000       yes\n20     1  79  75   30 32.0 0.396  22   No 0.07246377        no\n21     4 112  78   40 39.4 0.236  38   No 0.61538462       yes\n22     2  94  76   18 31.6 0.649  23   No 0.07246377        no\n23     2  84  50   23 30.4 0.968  21   No 0.07246377        no\n24     4 117  62   12 29.7 0.380  30  Yes 0.07246377        no\n25     1  81  74   41 46.3 1.096  32   No 0.61538462       yes\n26     1 120  80   48 38.9 1.162  41   No 0.61538462       yes\n27     7 187  68   39 37.7 0.254  41  Yes 0.84375000       yes\n28     7 179  95   31 34.2 0.164  60   No 0.84375000       yes\n29     6  80  66   30 26.2 0.313  41   No 0.11111111        no\n30     1  97  70   15 18.2 0.147  21   No 0.07246377        no\n31     0 100  88   60 46.8 0.962  31   No 0.61538462       yes\n32     6 154  78   41 46.1 0.571  27   No 0.84375000       yes\n33     2  56  56   28 24.2 0.332  22   No 0.07246377        no\n34     0 188  82   14 32.0 0.682  22  Yes 0.00000000        no\n35     2 197  70   99 34.7 0.575  62  Yes 0.84375000       yes\n36     2 142  82   18 24.7 0.761  21   No 0.00000000        no\n37     1 164  82   43 32.8 0.341  50   No 0.33333333        no\n38     6 144  72   27 33.9 0.255  40   No 0.84375000       yes\n39    14 175  62   30 33.6 0.212  38  Yes 0.33333333        no\n40     1 133 102   28 32.8 0.234  45  Yes 0.33333333        no\n\n\nWe set the threshold for prediction as threshold = 0.50, now we can have a look at the accuracy of the method:\n\nN &lt;- nrow(pima_res_test2)\n\nconfusion_mat2 &lt;- table(pima_res_test2 %&gt;% select(type, pred_type))\nconfusion_mat2\n\n     pred_type\ntype  no yes\n  No  16  10\n  Yes  8   6\n\naccuracy2 &lt;- (confusion_mat2 %&gt;% diag %&gt;% sum)/N\naccuracy2\n\n[1] 0.55\n\n\n\nOverall accuracy \\(= (16+6)/(16+10+8+6) = 0.55\\)\nTrue positive rate \\(= 6/(6+8) = 0.43\\)\nTrue negative rate \\(= 16/(16+10) = 0.62\\)\n\nNow we will use the k-nearest neighbours algorithm\nWe’ll use 10 nearest neighbours.\n\npred_type_knn &lt;- knn(train_pima_data %&gt;% select(-type), \n                     test_pima_data %&gt;% select(-type), \n                     cl =   train_pima_data$type, \n                     k = 10)\n\npima_res_test3 &lt;- test_pima_data %&gt;%\n                  mutate(pred_type = pred_type_knn)\n\npima_res_test3\n\n   npreg glu  bp skin  bmi   ped age type pred_type\n1      7 195  70   33 25.1 0.163  55  Yes       Yes\n2      0 165  76   43 47.9 0.259  26   No       Yes\n3      1 189  60   23 30.1 0.398  59  Yes       Yes\n4      4  99  76   15 23.2 0.223  21   No        No\n5      1  87  68   34 37.6 0.401  24   No        No\n6      1  79  80   25 25.4 0.583  22   No        No\n7      0 119  66   27 38.8 0.259  22   No        No\n8      3 171  72   33 33.3 0.199  24  Yes       Yes\n9      4 127  88   11 34.5 0.598  28   No        No\n10     1 124  74   36 27.8 0.100  30   No        No\n11     6 109  60   27 25.0 0.206  27   No        No\n12     5 139  80   35 31.6 0.361  25  Yes        No\n13     6 134  70   23 35.4 0.542  29  Yes        No\n14     3 106  54   21 30.9 0.292  24   No        No\n15     0 135  94   46 40.6 0.284  26   No        No\n16     1 168  88   29 35.0 0.905  52  Yes       Yes\n17     1 144  82   46 46.1 0.335  46  Yes       Yes\n18    12 121  78   17 26.5 0.259  62   No        No\n19     6 125  78   31 27.6 0.565  49  Yes        No\n20     1  79  75   30 32.0 0.396  22   No        No\n21     4 112  78   40 39.4 0.236  38   No        No\n22     2  94  76   18 31.6 0.649  23   No        No\n23     2  84  50   23 30.4 0.968  21   No        No\n24     4 117  62   12 29.7 0.380  30  Yes        No\n25     1  81  74   41 46.3 1.096  32   No        No\n26     1 120  80   48 38.9 1.162  41   No        No\n27     7 187  68   39 37.7 0.254  41  Yes       Yes\n28     7 179  95   31 34.2 0.164  60   No       Yes\n29     6  80  66   30 26.2 0.313  41   No        No\n30     1  97  70   15 18.2 0.147  21   No        No\n31     0 100  88   60 46.8 0.962  31   No        No\n32     6 154  78   41 46.1 0.571  27   No       Yes\n33     2  56  56   28 24.2 0.332  22   No        No\n34     0 188  82   14 32.0 0.682  22  Yes       Yes\n35     2 197  70   99 34.7 0.575  62  Yes       Yes\n36     2 142  82   18 24.7 0.761  21   No        No\n37     1 164  82   43 32.8 0.341  50   No       Yes\n38     6 144  72   27 33.9 0.255  40   No       Yes\n39    14 175  62   30 33.6 0.212  38  Yes       Yes\n40     1 133 102   28 32.8 0.234  45  Yes       Yes\n\n\nNow we can have a look at the accuracy of the method:\n\nN &lt;- nrow(pima_res_test3)\n\nconfusion_mat3 &lt;- table(pima_res_test3 %&gt;% select(type, pred_type))\nconfusion_mat3\n\n     pred_type\ntype  No Yes\n  No  21   5\n  Yes  4  10\n\naccuracy3 &lt;- (confusion_mat3 %&gt;% diag %&gt;% sum)/N\naccuracy3\n\n[1] 0.775\n\n\nOverall accuracy \\(= (21+10)/(21+5+4+10) = 0.78\\)\nTrue positive rate \\(= 10/(4+10) = 0.71\\)\nTrue negative rate \\(= 21/(21+5) = 0.81\\)\nWe can assess the overall accuracy, true positive and true negative rates for different values of \\(k\\):"
  },
  {
    "objectID": "7-PredictiveAnalytics.html#regression-trees",
    "href": "7-PredictiveAnalytics.html#regression-trees",
    "title": "Predictive Analytics",
    "section": "Regression Trees",
    "text": "Regression Trees\nRegression trees are similar to classification trees. The difference is that the response variable is continuous instead of categorical.\nThe same reasoning is employed when constructing a regression tree: the predictors are split in such a way that the prediction error is minimised. In the case of regression trees, we may opt to minimise the residual sum of squares, for example.\nFor the leaves or terminal nodes, the predictions will be the average estimate for the observations that belong to that terminal node."
  },
  {
    "objectID": "7-PredictiveAnalytics.html#example-pima-data",
    "href": "7-PredictiveAnalytics.html#example-pima-data",
    "title": "Predictive Analytics",
    "section": "Example: Pima data",
    "text": "Example: Pima data\nWe will now use linear regression and a regression tree to obtain predictions for the glu variable using the Pima.tr data.\nSplit the data\n\nlibrary(rsample)\n# Fix random numbers by setting the seed \nset.seed(1116)\n# Put 80% of the data into the training set \npima_split &lt;- initial_split(Pima.tr, prop = 0.80)\n# Create data frames for the two sets:\ntrain_pima_data &lt;- training(pima_split)\ntest_pima_data  &lt;- testing(pima_split)\n\nFitting a multiple linear regression model\n\nfit_lm &lt;- lm(glu ~ ., data = train_pima_data)\nfit_lm\n\n\nCall:\nlm(formula = glu ~ ., data = train_pima_data)\n\nCoefficients:\n(Intercept)        npreg           bp         skin          bmi          ped  \n    70.2137      -0.5522       0.4133      -0.0431       0.2508       4.0819  \n        age      typeYes  \n     0.2751      22.6378  \n\n\nEvaluate the performance on the test data:\n\nglu_res_test &lt;- test_pima_data %&gt;% \n                    mutate(pred_glu = predict(fit_lm, test_pima_data))\n\nggplot(glu_res_test, aes(x = glu, y = pred_glu)) +\n  geom_point() + \n  geom_line(aes(x = glu, y = glu))\n\n\n\n\n\n\n\n\nSummarise the model accuracy\nIn addition to mean error and mean absolute error which we have used before, we can also have a look at the correlation between observed and predicted values to help us summarise how well our model performs:\n\nglu_res_test %&gt;% \n  summarise(mean_error = mean(glu - pred_glu),\n            mean_abs_error = mean(abs(glu - pred_glu)),\n            cor = cor(glu, pred_glu))\n\n  mean_error mean_abs_error       cor\n1   5.105036       25.05825 0.6643261\n\n\nNow fit a regression tree\n\nfit_reg_tree &lt;- rpart(glu ~ ., data = train_pima_data)\nrpart.plot(fit_reg_tree)\n\n\n\n\n\n\n\n\nEvaluate the performance on the test data:\n\nglu_res_test2 &lt;- test_pima_data %&gt;% \n                    mutate(pred_glu = predict(fit_reg_tree, test_pima_data))\n\nggplot(glu_res_test2, aes(x = glu, y = pred_glu)) +\n  geom_point() + \n  geom_line(aes(x = glu, y = glu))\n\n\n\n\n\n\n\n\nSummarise the model accuracy\n\nglu_res_test2 %&gt;% \n  summarise(mean_error = mean(glu - pred_glu),\n            mean_abs_error = mean(abs(glu - pred_glu)),\n            cor = cor(glu, pred_glu))\n\n  mean_error mean_abs_error       cor\n1   10.35319       29.49208 0.3722016"
  },
  {
    "objectID": "7-PredictiveAnalytics.html#training-vs-test-accuracymean-errors",
    "href": "7-PredictiveAnalytics.html#training-vs-test-accuracymean-errors",
    "title": "Predictive Analytics",
    "section": "Training vs test accuracy/mean errors",
    "text": "Training vs test accuracy/mean errors\nWe expect the test error to be greater than the training error, after all the model ``has not seen’’ the test data before. This is essentialy what we want in real life, after all we will use our data to fit a machine learning model/algorithm, and we will use it to predict responses that are unknown."
  },
  {
    "objectID": "7-PredictiveAnalytics.html#key-components",
    "href": "7-PredictiveAnalytics.html#key-components",
    "title": "Predictive Analytics",
    "section": "",
    "text": "Data collection gathers relevant information from various sources\nData preprocessing cleans and transforms raw data into a suitable format for analysis\nFeature engineering creates new variables or selects relevant features to improve model performance\nModel development builds and trains predictive algorithms using historical data\nModel evaluation assesses the accuracy and reliability of predictions using various metrics"
  },
  {
    "objectID": "7-PredictiveAnalytics.html#types-of-data",
    "href": "7-PredictiveAnalytics.html#types-of-data",
    "title": "Predictive Analytics",
    "section": "",
    "text": "Structured data organized in predefined formats (spreadsheets)\nUnstructured data lacks a predefined structure (text documents, images, videos)\nTime series data represents observations collected at regular intervals over time (stock prices, weather data)\nCross-sectional data captures information from multiple subjects at a single point in time (survey responses)"
  },
  {
    "objectID": "7-PredictiveAnalytics.html#problem-definition",
    "href": "7-PredictiveAnalytics.html#problem-definition",
    "title": "Predictive Analytics",
    "section": "Problem definition",
    "text": "Problem definition\n\nIdentifies the specific problem or question to be addressed\nDetermines the outcome to be predicted (e.g., customer churn, sales volume)"
  },
  {
    "objectID": "7-PredictiveAnalytics.html#data-preparation",
    "href": "7-PredictiveAnalytics.html#data-preparation",
    "title": "Predictive Analytics",
    "section": "Data preparation",
    "text": "Data preparation\n\nData cleaning removes or corrects errors, inconsistencies, and missing values in the dataset\nData integration combines data from multiple sources into a unified format for analysis\nData transformation applies mathematical or logical operations to create new variables or modify existing ones"
  },
  {
    "objectID": "7-PredictiveAnalytics.html#model-training",
    "href": "7-PredictiveAnalytics.html#model-training",
    "title": "Predictive Analytics",
    "section": "Model training",
    "text": "Model training\n\nExplores both traditional statistical methods and advanced machine learning algorithms\nSplits the prepared data into training and testing sets to assess model performance\nApplies selected algorithms to the training data to learn patterns and relationships"
  },
  {
    "objectID": "7-PredictiveAnalytics.html#model-evaluation",
    "href": "7-PredictiveAnalytics.html#model-evaluation",
    "title": "Predictive Analytics",
    "section": "Model evaluation",
    "text": "Model evaluation\n\nCalculates relevant evaluation metrics to assesses model performance on the held-out test data to measure generalization\nEvaluates different types of predictive models based on the problem and data characteristics\nConsiders factors such as interpretability, scalability, and computational requirements\nAssesses the trade-offs between model complexity and performance"
  },
  {
    "objectID": "7-PredictiveAnalytics.html#model-selection",
    "href": "7-PredictiveAnalytics.html#model-selection",
    "title": "Predictive Analytics",
    "section": "Model selection",
    "text": "Model selection\n\nSelects an appropriate model for the specific predictive task"
  },
  {
    "objectID": "7-PredictiveAnalytics.html#for-regression-problems",
    "href": "7-PredictiveAnalytics.html#for-regression-problems",
    "title": "Predictive Analytics",
    "section": "For regression problems",
    "text": "For regression problems\nFor regression problems, usual predictive analytics techniques include\n\nlinear regression\nregression trees\nrandom forests\ngeneralised additive models\n\nWe will study regression trees in this lecture. We will not look at the mathematics in detail, the objectives are to understand how they work and be able to interpret the results."
  },
  {
    "objectID": "7-PredictiveAnalytics.html#for-classification-problems",
    "href": "7-PredictiveAnalytics.html#for-classification-problems",
    "title": "Predictive Analytics",
    "section": "For classification problems",
    "text": "For classification problems\nFor classification problems, usual predictive analytics techniques include\n\nlogistic regression\nclassification trees\nk-nearest neighbours\nsupport vector machines\ndiscriminant analysis\nneural networks\n\nWe will study classification trees and k-nearest neighbours in this lecture. We will not look at the mathematics in detail, the objectives are to understand how they work and be able to interpret the results."
  },
  {
    "objectID": "7-PredictiveAnalytics.html#performing-the-split",
    "href": "7-PredictiveAnalytics.html#performing-the-split",
    "title": "Predictive Analytics",
    "section": "Performing the split",
    "text": "Performing the split\nLet’s consider an example here. We have data on paintings from auction catalogs in paris. A glimpse of the data is shown below.\n\nglimpse(paris_paintings)\n\nRows: 220\nColumns: 12\n$ name         &lt;chr&gt; \"L1764-4\", \"L1764-7a\", \"L1764-7b\", \"L1764-10a\", \"L1764-10…\n$ sale         &lt;chr&gt; \"L1764\", \"L1764\", \"L1764\", \"L1764\", \"L1764\", \"L1764\", \"L1…\n$ lot          &lt;chr&gt; \"4\", \"7\", \"7\", \"10\", \"10\", \"10\", \"15\", \"16\", \"16\", \"40\", …\n$ year         &lt;dbl&gt; 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 176…\n$ logprice     &lt;dbl&gt; 2.4849067, 2.4849067, 2.4849067, 0.2876818, 0.2876818, 0.…\n$ price        &lt;dbl&gt; 12.0, 12.0, 12.0, 1.3, 1.3, 1.3, 6.0, 12.0, 12.0, 300.0, …\n$ subject      &lt;chr&gt; \"L'enfant Jesus & Saint Jean\", \"(2) Venus qui retient Ado…\n$ Height_in    &lt;dbl&gt; 13.00, 6.00, 6.00, 16.00, 16.00, 16.00, 36.00, 27.00, 27.…\n$ Width_in     &lt;dbl&gt; 16.00, 13.00, 13.00, 12.00, 12.00, 12.00, 48.00, 36.00, 3…\n$ Surface_Rect &lt;dbl&gt; 208.0000, 78.0000, 78.0000, 192.0000, 192.0000, 192.0000,…\n$ materialCat  &lt;chr&gt; \"wood\", \"canvas\", \"canvas\", \"canvas\", \"canvas\", \"canvas\",…\n$ landsALL     &lt;dbl&gt; 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, …\n\n\nWe will split the data into training and testing datasets\n\nlibrary(rsample)\n# Fix random numbers by setting the seed \nset.seed(1116)\n# Put 80% of the data into the training set \nprice_split &lt;- initial_split(paris_paintings, prop = 0.80)\n# Create data frames for the two sets:\ntrain_data &lt;- training(price_split)\ntest_data  &lt;- testing(price_split)\n\nFit a model and “learn” from the training data:\n\nlm_model_train &lt;- lm(logprice ~ Height_in + Width_in + year + Surface_Rect + \n                       materialCat + landsALL, data = train_data)\n\nEvaluate the performance on the test data:\n\nprice_res_test &lt;- test_data %&gt;% \n                    select(logprice) %&gt;% \n                    mutate(pred_price = predict(lm_model_train, test_data))\n\nggplot(price_res_test, aes(x = logprice, y = pred_price)) +\n  geom_point() + \n  geom_line(aes(x = logprice, y = logprice))\n\n\n\n\n\n\n\n\nSummarise the model accuracy\n\nprice_res_test %&gt;% \n  summarise(mean_error = mean(logprice - pred_price),\n            mean_abs_error = mean(abs(logprice - pred_price)))\n\n# A tibble: 1 × 2\n  mean_error mean_abs_error\n       &lt;dbl&gt;          &lt;dbl&gt;\n1    0.00278           1.71"
  },
  {
    "objectID": "Assignment3_soln.html#question-1",
    "href": "Assignment3_soln.html#question-1",
    "title": "DS152 Introduction to Data Science (2)",
    "section": "Question 1",
    "text": "Question 1\n\nAns: Simple random sampling [1 Marks]\nAns: Cluster sampling [1 Marks]"
  },
  {
    "objectID": "Assignment3_soln.html#question-2",
    "href": "Assignment3_soln.html#question-2",
    "title": "DS152 Introduction to Data Science (2)",
    "section": "Question 2",
    "text": "Question 2\nData was collected on 400 individuals to examine the relationship between a person’s income and credit card debt. The variable for credit card debt is called Balance. Other variables like credit limit brackets (limit_bracket) and marital status (Married) are included in the dataset as well. A glimpse of the dataset is shown below.\n\nglimpse(credit_dat)\n\nRows: 400\nColumns: 12\n$ ID            &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ Income        &lt;dbl&gt; 14.891, 106.025, 104.593, 148.924, 55.882, 80.180, 20.99…\n$ Rating        &lt;dbl&gt; 283, 483, 514, 681, 357, 569, 259, 512, 266, 491, 589, 1…\n$ Cards         &lt;dbl&gt; 2, 3, 4, 3, 2, 4, 2, 2, 5, 3, 4, 3, 1, 1, 2, 3, 3, 3, 1,…\n$ Age           &lt;dbl&gt; 34, 82, 71, 36, 68, 77, 37, 87, 66, 41, 30, 64, 57, 49, …\n$ Education     &lt;dbl&gt; 11, 15, 11, 11, 16, 10, 12, 9, 13, 19, 14, 16, 7, 9, 13,…\n$ Gender        &lt;chr&gt; \"Male\", \"Female\", \"Male\", \"Female\", \"Male\", \"Male\", \"Fem…\n$ Student       &lt;chr&gt; \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"…\n$ Married       &lt;chr&gt; \"Yes\", \"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\",…\n$ Ethnicity     &lt;chr&gt; \"Caucasian\", \"Asian\", \"Asian\", \"Asian\", \"Caucasian\", \"Ca…\n$ Balance       &lt;dbl&gt; 333, 903, 580, 964, 331, 1151, 203, 872, 279, 1350, 1407…\n$ limit_bracket &lt;fct&gt; medium-low, high, high, high, medium-high, high, medium-…\n\n\n\nThe plot below shows the relationship between credit card debt (Balance) and Income. Briefly describe the relationship in your own words. [2 Marks]\n\n\n\n\n\n\n\n\n\n\n\nIt appears that as income increases the credit car debt increases but there is a large amount of variation around the fitted regression line.\n\n\nAssume you now want to visualise the same information in (a) but also include the credit-limit variable (limit_bracket). Replace [A], [B], [C], [D], and [E] in the code below to produce the following plot: [Marks = 5]\n\n\nggplot(credit_dat, aes(x = Income, y = Balance, colour = limit_bracket)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\nA = Income\nB = Balance\nC = colour\nD = point\nE = “lm”\n\nFrom looking at the plot in (b), what impact does including information on credit limits have on how you interpret the relationship between credit-card debt and income? Does Simpson’s Paradox happen here? [3 Marks]\n\n\nWhen the credit limit bracket information is included we see that the relationship between income and debt is different within the credit limit brackets than it is overall. There’s a negative association within the medium-low and medium-high groups, a slight positive association in the high group and hardly any association within the low group. This appears to be an example of Simpson’s Paradox (direction of association changes within groups compared to aggregate).\n\n\nAssume you now want to calculate the average Balance and the average Income within each credit-limit bracket. Replace [A], [B], [C] and [D] in the code below to produce the following summary table: [4 Marks]\n\n\n\n# A tibble: 4 × 3\n  limit_bracket mean_income mean_balance\n  &lt;fct&gt;               &lt;dbl&gt;        &lt;dbl&gt;\n1 low                  24.9         33.0\n2 medium-low           29.8        323. \n3 medium-high          38.3        679. \n4 high                 88.0       1045. \n\n\nA = limit_brackets\nB = summarise\nC = Income\nD = mean_balance\n\nHow does the summary in (d) help to explain why the credit limit variable (limit_bracket) is a confounding variable when looking at the relationship between credit-card debt and income? [4 Marks]\n\n\nDebt appears to increase as you go from low to high credit limits, in addition people with higher incomes tend to be in higher credit limit brackets. Therefore, credit limit has a positive association with both Income and Debt and confounds the results if not accounted for (as in the plot from part b)"
  },
  {
    "objectID": "Tutorial4_soln.html",
    "href": "Tutorial4_soln.html",
    "title": "DS152 Tutorial Sheet 4",
    "section": "",
    "text": "The barley dataset contains data on an experiment set up in a completely randomised design with three replicates and two factors: nutrient (with three levels: nitrogen, phosphate and potassium) and dose (with three levels: 10ppm, 100ppm and 1000ppm), totaling nine treatments. The yield was measured in tonnes per hectare.\nYou can run the code below to glimpse the dataset:\n\nbarley &lt;- read_csv(\"https://www.dropbox.com/s/4p6ziofmxe2bqcf/barley.csv?raw=1\")\nglimpse(barley)\n\nRows: 27\nColumns: 3\n$ dose     &lt;chr&gt; \"10ppm\", \"10ppm\", \"10ppm\", \"10ppm\", \"10ppm\", \"10ppm\", \"10ppm\"…\n$ nutrient &lt;chr&gt; \"nitrogen\", \"nitrogen\", \"nitrogen\", \"phosphate\", \"phosphate\",…\n$ yield    &lt;dbl&gt; 3.727060, 4.268293, 4.209812, 4.708186, 5.423730, 5.133011, 6…\n\n\nThe table below displays means per each dose:nutrient combination:\n\nbarley_summarise &lt;- barley %&gt;%\n                      group_by(dose, nutrient) %&gt;%\n                      summarise(mean_yield = mean(yield) %&gt;% round(2),\n                                n = n()) \nbarley_summarise\n\n# A tibble: 9 × 4\n# Groups:   dose [3]\n  dose    nutrient  mean_yield     n\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;\n1 1000ppm nitrogen       10.2      3\n2 1000ppm phosphate       7.57     3\n3 1000ppm potassium       6.86     3\n4 100ppm  nitrogen        6.88     3\n5 100ppm  phosphate       7.69     3\n6 100ppm  potassium       9.12     3\n7 10ppm   nitrogen        4.07     3\n8 10ppm   phosphate       5.09     3\n9 10ppm   potassium       5.85     3\n\n\nNote for tutors: Please go through what this code is doing.\n(a) Use pivot_wider on this table to have separate columns for the nitrogen, phosphate and potassium means per dose group as shown below:\n\nbarley_summ_wide &lt;- barley_summarise %&gt;%\n                      pivot_wider(names_from = \"nutrient\",\n                                  values_from = \"mean_yield\")\n\nbarley_summ_wide\n\n# A tibble: 3 × 5\n# Groups:   dose [3]\n  dose        n nitrogen phosphate potassium\n  &lt;chr&gt;   &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 1000ppm     3    10.2       7.57      6.86\n2 100ppm      3     6.88      7.69      9.12\n3 10ppm       3     4.07      5.09      5.85\n\n\nNote for tutors: This is a recap of pivot_wider so please work through this slowly and maybe refer back to earlier notes.\n(b) Which treatment (dose:nutrient combination) seems to be associated with the largest yield?\n\nbarley_summarise %&gt;% \n  arrange(desc(mean_yield))\n\n# A tibble: 9 × 4\n# Groups:   dose [3]\n  dose    nutrient  mean_yield     n\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;\n1 1000ppm nitrogen       10.2      3\n2 100ppm  potassium       9.12     3\n3 100ppm  phosphate       7.69     3\n4 1000ppm phosphate       7.57     3\n5 100ppm  nitrogen        6.88     3\n6 1000ppm potassium       6.86     3\n7 10ppm   potassium       5.85     3\n8 10ppm   phosphate       5.09     3\n9 10ppm   nitrogen        4.07     3\n\n\n\nnitrogen with a dose of 1000ppm is associated with the highest yield.\n\nNote for tutors: Mention that this is a factorial design as we’re looking at 2 factors, nutrient and dose.\n(c) Which dose seems to be associated with the largest yield?\n\nbarley_summarise %&gt;% group_by(dose) %&gt;% summarise(mean(mean_yield))\n\n# A tibble: 3 × 2\n  dose    `mean(mean_yield)`\n  &lt;chr&gt;                &lt;dbl&gt;\n1 1000ppm               8.20\n2 100ppm                7.90\n3 10ppm                 5.00\n\n## which is the same as...\nbarley %&gt;% group_by(dose) %&gt;% summarise(mean(yield))\n\n# A tibble: 3 × 2\n  dose    `mean(yield)`\n  &lt;chr&gt;           &lt;dbl&gt;\n1 1000ppm          8.20\n2 100ppm           7.90\n3 10ppm            5.00\n\n\n\nAveraging over nutrient, 1000 pm seems to be associated with the largest yield.\n\n(d) Which nutrient seems to be associated with the largest yield?\n\nbarley_summarise %&gt;% group_by(nutrient) %&gt;% summarise(mean(mean_yield))\n\n# A tibble: 3 × 2\n  nutrient  `mean(mean_yield)`\n  &lt;chr&gt;                  &lt;dbl&gt;\n1 nitrogen                7.04\n2 phosphate               6.78\n3 potassium               7.28\n\n## which is the same as...\nbarley %&gt;% group_by(nutrient) %&gt;% summarise(mean(yield))\n\n# A tibble: 3 × 2\n  nutrient  `mean(yield)`\n  &lt;chr&gt;             &lt;dbl&gt;\n1 nitrogen           7.04\n2 phosphate          6.78\n3 potassium          7.28\n\n\n\nAveraging over dose, potassium seems to be associated with the largest yield.\n\n(e) The figure below displays an ‘interaction plot’, as seen in class. Does there appear to be an interaction between the factors dose and nutrient? Why?\n\nbarley %&gt;%\n  group_by(dose, nutrient) %&gt;%\n  summarise(mean = mean(yield)) %&gt;%\n  ggplot(aes(x = nutrient, y = mean, colour = dose, group = dose)) +\n  theme_bw() +\n  geom_point() +\n  geom_line()\n\n\n\n\n\n\n\n\nNote for tutors: Talk through the code and the use of the grouping to create this plot.\n\nYes there is an interaction because the lines are not parallel, i.e. the yield response to the nutrient changes depending on the levels of the dose."
  },
  {
    "objectID": "Tutorial4_soln.html#exercise",
    "href": "Tutorial4_soln.html#exercise",
    "title": "DS152 Tutorial Sheet 4",
    "section": "",
    "text": "The barley dataset contains data on an experiment set up in a completely randomised design with three replicates and two factors: nutrient (with three levels: nitrogen, phosphate and potassium) and dose (with three levels: 10ppm, 100ppm and 1000ppm), totaling nine treatments. The yield was measured in tonnes per hectare.\nYou can run the code below to glimpse the dataset:\n\nbarley &lt;- read_csv(\"https://www.dropbox.com/s/4p6ziofmxe2bqcf/barley.csv?raw=1\")\nglimpse(barley)\n\nRows: 27\nColumns: 3\n$ dose     &lt;chr&gt; \"10ppm\", \"10ppm\", \"10ppm\", \"10ppm\", \"10ppm\", \"10ppm\", \"10ppm\"…\n$ nutrient &lt;chr&gt; \"nitrogen\", \"nitrogen\", \"nitrogen\", \"phosphate\", \"phosphate\",…\n$ yield    &lt;dbl&gt; 3.727060, 4.268293, 4.209812, 4.708186, 5.423730, 5.133011, 6…\n\n\nThe table below displays means per each dose:nutrient combination:\n\nbarley_summarise &lt;- barley %&gt;%\n                      group_by(dose, nutrient) %&gt;%\n                      summarise(mean_yield = mean(yield) %&gt;% round(2),\n                                n = n()) \nbarley_summarise\n\n# A tibble: 9 × 4\n# Groups:   dose [3]\n  dose    nutrient  mean_yield     n\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;\n1 1000ppm nitrogen       10.2      3\n2 1000ppm phosphate       7.57     3\n3 1000ppm potassium       6.86     3\n4 100ppm  nitrogen        6.88     3\n5 100ppm  phosphate       7.69     3\n6 100ppm  potassium       9.12     3\n7 10ppm   nitrogen        4.07     3\n8 10ppm   phosphate       5.09     3\n9 10ppm   potassium       5.85     3\n\n\nNote for tutors: Please go through what this code is doing.\n(a) Use pivot_wider on this table to have separate columns for the nitrogen, phosphate and potassium means per dose group as shown below:\n\nbarley_summ_wide &lt;- barley_summarise %&gt;%\n                      pivot_wider(names_from = \"nutrient\",\n                                  values_from = \"mean_yield\")\n\nbarley_summ_wide\n\n# A tibble: 3 × 5\n# Groups:   dose [3]\n  dose        n nitrogen phosphate potassium\n  &lt;chr&gt;   &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 1000ppm     3    10.2       7.57      6.86\n2 100ppm      3     6.88      7.69      9.12\n3 10ppm       3     4.07      5.09      5.85\n\n\nNote for tutors: This is a recap of pivot_wider so please work through this slowly and maybe refer back to earlier notes.\n(b) Which treatment (dose:nutrient combination) seems to be associated with the largest yield?\n\nbarley_summarise %&gt;% \n  arrange(desc(mean_yield))\n\n# A tibble: 9 × 4\n# Groups:   dose [3]\n  dose    nutrient  mean_yield     n\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;\n1 1000ppm nitrogen       10.2      3\n2 100ppm  potassium       9.12     3\n3 100ppm  phosphate       7.69     3\n4 1000ppm phosphate       7.57     3\n5 100ppm  nitrogen        6.88     3\n6 1000ppm potassium       6.86     3\n7 10ppm   potassium       5.85     3\n8 10ppm   phosphate       5.09     3\n9 10ppm   nitrogen        4.07     3\n\n\n\nnitrogen with a dose of 1000ppm is associated with the highest yield.\n\nNote for tutors: Mention that this is a factorial design as we’re looking at 2 factors, nutrient and dose.\n(c) Which dose seems to be associated with the largest yield?\n\nbarley_summarise %&gt;% group_by(dose) %&gt;% summarise(mean(mean_yield))\n\n# A tibble: 3 × 2\n  dose    `mean(mean_yield)`\n  &lt;chr&gt;                &lt;dbl&gt;\n1 1000ppm               8.20\n2 100ppm                7.90\n3 10ppm                 5.00\n\n## which is the same as...\nbarley %&gt;% group_by(dose) %&gt;% summarise(mean(yield))\n\n# A tibble: 3 × 2\n  dose    `mean(yield)`\n  &lt;chr&gt;           &lt;dbl&gt;\n1 1000ppm          8.20\n2 100ppm           7.90\n3 10ppm            5.00\n\n\n\nAveraging over nutrient, 1000 pm seems to be associated with the largest yield.\n\n(d) Which nutrient seems to be associated with the largest yield?\n\nbarley_summarise %&gt;% group_by(nutrient) %&gt;% summarise(mean(mean_yield))\n\n# A tibble: 3 × 2\n  nutrient  `mean(mean_yield)`\n  &lt;chr&gt;                  &lt;dbl&gt;\n1 nitrogen                7.04\n2 phosphate               6.78\n3 potassium               7.28\n\n## which is the same as...\nbarley %&gt;% group_by(nutrient) %&gt;% summarise(mean(yield))\n\n# A tibble: 3 × 2\n  nutrient  `mean(yield)`\n  &lt;chr&gt;             &lt;dbl&gt;\n1 nitrogen           7.04\n2 phosphate          6.78\n3 potassium          7.28\n\n\n\nAveraging over dose, potassium seems to be associated with the largest yield.\n\n(e) The figure below displays an ‘interaction plot’, as seen in class. Does there appear to be an interaction between the factors dose and nutrient? Why?\n\nbarley %&gt;%\n  group_by(dose, nutrient) %&gt;%\n  summarise(mean = mean(yield)) %&gt;%\n  ggplot(aes(x = nutrient, y = mean, colour = dose, group = dose)) +\n  theme_bw() +\n  geom_point() +\n  geom_line()\n\n\n\n\n\n\n\n\nNote for tutors: Talk through the code and the use of the grouping to create this plot.\n\nYes there is an interaction because the lines are not parallel, i.e. the yield response to the nutrient changes depending on the levels of the dose."
  },
  {
    "objectID": "Tutorial4.html",
    "href": "Tutorial4.html",
    "title": "DS152 Tutorial Sheet 4",
    "section": "",
    "text": "The barley dataset contains data on an experiment set up in a completely randomised design with three replicates and two factors: nutrient (with three levels: nitrogen, phosphate and potassium) and dose (with three levels: 10ppm, 100ppm and 1000ppm), totaling nine treatments. The yield was measured in tonnes per hectare.\nYou can run the code below to glimpse the dataset:\n\nbarley &lt;- read_csv(\"https://www.dropbox.com/s/4p6ziofmxe2bqcf/barley.csv?raw=1\")\nglimpse(barley)\n\nRows: 27\nColumns: 3\n$ dose     &lt;chr&gt; \"10ppm\", \"10ppm\", \"10ppm\", \"10ppm\", \"10ppm\", \"10ppm\", \"10ppm\"…\n$ nutrient &lt;chr&gt; \"nitrogen\", \"nitrogen\", \"nitrogen\", \"phosphate\", \"phosphate\",…\n$ yield    &lt;dbl&gt; 3.727060, 4.268293, 4.209812, 4.708186, 5.423730, 5.133011, 6…\n\n\nThe table below displays means per each dose:nutrient combination:\n\nbarley_summarise &lt;- barley %&gt;%\n                      group_by(dose, nutrient) %&gt;%\n                      summarise(mean_yield = mean(yield) %&gt;% round(2),\n                                n = n()) \nbarley_summarise\n\n# A tibble: 9 × 4\n# Groups:   dose [3]\n  dose    nutrient  mean_yield     n\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;\n1 1000ppm nitrogen       10.2      3\n2 1000ppm phosphate       7.57     3\n3 1000ppm potassium       6.86     3\n4 100ppm  nitrogen        6.88     3\n5 100ppm  phosphate       7.69     3\n6 100ppm  potassium       9.12     3\n7 10ppm   nitrogen        4.07     3\n8 10ppm   phosphate       5.09     3\n9 10ppm   potassium       5.85     3\n\n\n(a) Use pivot_wider on this table to have separate columns for the nitrogen, phosphate and potassium means per dose group as shown below:\n\nbarley_summ_wide &lt;- barley_summarise %&gt;%\n                      pivot_wider(names_from = \"nutrient\",\n                                  values_from = \"mean_yield\")\n\nbarley_summ_wide\n\n# A tibble: 3 × 5\n# Groups:   dose [3]\n  dose        n nitrogen phosphate potassium\n  &lt;chr&gt;   &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 1000ppm     3    10.2       7.57      6.86\n2 100ppm      3     6.88      7.69      9.12\n3 10ppm       3     4.07      5.09      5.85\n\n\n(b) Which treatment (dose:nutrient combination) seems to be associated with the largest yield?\n\nbarley_summarise %&gt;% \n  arrange(desc(mean_yield))\n\n# A tibble: 9 × 4\n# Groups:   dose [3]\n  dose    nutrient  mean_yield     n\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;\n1 1000ppm nitrogen       10.2      3\n2 100ppm  potassium       9.12     3\n3 100ppm  phosphate       7.69     3\n4 1000ppm phosphate       7.57     3\n5 100ppm  nitrogen        6.88     3\n6 1000ppm potassium       6.86     3\n7 10ppm   potassium       5.85     3\n8 10ppm   phosphate       5.09     3\n9 10ppm   nitrogen        4.07     3\n\n\n(c) Which dose seems to be associated with the largest yield?\n\nbarley_summarise %&gt;% group_by(dose) %&gt;% summarise(mean(mean_yield))\n\n# A tibble: 3 × 2\n  dose    `mean(mean_yield)`\n  &lt;chr&gt;                &lt;dbl&gt;\n1 1000ppm               8.20\n2 100ppm                7.90\n3 10ppm                 5.00\n\n## which is the same as...\nbarley %&gt;% group_by(dose) %&gt;% summarise(mean(yield))\n\n# A tibble: 3 × 2\n  dose    `mean(yield)`\n  &lt;chr&gt;           &lt;dbl&gt;\n1 1000ppm          8.20\n2 100ppm           7.90\n3 10ppm            5.00\n\n\n(d) Which nutrient seems to be associated with the largest yield?\n\nbarley_summarise %&gt;% group_by(nutrient) %&gt;% summarise(mean(mean_yield))\n\n# A tibble: 3 × 2\n  nutrient  `mean(mean_yield)`\n  &lt;chr&gt;                  &lt;dbl&gt;\n1 nitrogen                7.04\n2 phosphate               6.78\n3 potassium               7.28\n\n## which is the same as...\nbarley %&gt;% group_by(nutrient) %&gt;% summarise(mean(yield))\n\n# A tibble: 3 × 2\n  nutrient  `mean(yield)`\n  &lt;chr&gt;             &lt;dbl&gt;\n1 nitrogen           7.04\n2 phosphate          6.78\n3 potassium          7.28\n\n\n(e) The figure below displays an ‘interaction plot’, as seen in class. Does there appear to be an interaction between the factors dose and nutrient? Why?\n\nbarley %&gt;%\n  group_by(dose, nutrient) %&gt;%\n  summarise(mean = mean(yield)) %&gt;%\n  ggplot(aes(x = nutrient, y = mean, colour = dose, group = dose)) +\n  theme_bw() +\n  geom_point() +\n  geom_line()"
  },
  {
    "objectID": "Tutorial4.html#exercise",
    "href": "Tutorial4.html#exercise",
    "title": "DS152 Tutorial Sheet 4",
    "section": "",
    "text": "The barley dataset contains data on an experiment set up in a completely randomised design with three replicates and two factors: nutrient (with three levels: nitrogen, phosphate and potassium) and dose (with three levels: 10ppm, 100ppm and 1000ppm), totaling nine treatments. The yield was measured in tonnes per hectare.\nYou can run the code below to glimpse the dataset:\n\nbarley &lt;- read_csv(\"https://www.dropbox.com/s/4p6ziofmxe2bqcf/barley.csv?raw=1\")\nglimpse(barley)\n\nRows: 27\nColumns: 3\n$ dose     &lt;chr&gt; \"10ppm\", \"10ppm\", \"10ppm\", \"10ppm\", \"10ppm\", \"10ppm\", \"10ppm\"…\n$ nutrient &lt;chr&gt; \"nitrogen\", \"nitrogen\", \"nitrogen\", \"phosphate\", \"phosphate\",…\n$ yield    &lt;dbl&gt; 3.727060, 4.268293, 4.209812, 4.708186, 5.423730, 5.133011, 6…\n\n\nThe table below displays means per each dose:nutrient combination:\n\nbarley_summarise &lt;- barley %&gt;%\n                      group_by(dose, nutrient) %&gt;%\n                      summarise(mean_yield = mean(yield) %&gt;% round(2),\n                                n = n()) \nbarley_summarise\n\n# A tibble: 9 × 4\n# Groups:   dose [3]\n  dose    nutrient  mean_yield     n\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;\n1 1000ppm nitrogen       10.2      3\n2 1000ppm phosphate       7.57     3\n3 1000ppm potassium       6.86     3\n4 100ppm  nitrogen        6.88     3\n5 100ppm  phosphate       7.69     3\n6 100ppm  potassium       9.12     3\n7 10ppm   nitrogen        4.07     3\n8 10ppm   phosphate       5.09     3\n9 10ppm   potassium       5.85     3\n\n\n(a) Use pivot_wider on this table to have separate columns for the nitrogen, phosphate and potassium means per dose group as shown below:\n\nbarley_summ_wide &lt;- barley_summarise %&gt;%\n                      pivot_wider(names_from = \"nutrient\",\n                                  values_from = \"mean_yield\")\n\nbarley_summ_wide\n\n# A tibble: 3 × 5\n# Groups:   dose [3]\n  dose        n nitrogen phosphate potassium\n  &lt;chr&gt;   &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 1000ppm     3    10.2       7.57      6.86\n2 100ppm      3     6.88      7.69      9.12\n3 10ppm       3     4.07      5.09      5.85\n\n\n(b) Which treatment (dose:nutrient combination) seems to be associated with the largest yield?\n\nbarley_summarise %&gt;% \n  arrange(desc(mean_yield))\n\n# A tibble: 9 × 4\n# Groups:   dose [3]\n  dose    nutrient  mean_yield     n\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;\n1 1000ppm nitrogen       10.2      3\n2 100ppm  potassium       9.12     3\n3 100ppm  phosphate       7.69     3\n4 1000ppm phosphate       7.57     3\n5 100ppm  nitrogen        6.88     3\n6 1000ppm potassium       6.86     3\n7 10ppm   potassium       5.85     3\n8 10ppm   phosphate       5.09     3\n9 10ppm   nitrogen        4.07     3\n\n\n(c) Which dose seems to be associated with the largest yield?\n\nbarley_summarise %&gt;% group_by(dose) %&gt;% summarise(mean(mean_yield))\n\n# A tibble: 3 × 2\n  dose    `mean(mean_yield)`\n  &lt;chr&gt;                &lt;dbl&gt;\n1 1000ppm               8.20\n2 100ppm                7.90\n3 10ppm                 5.00\n\n## which is the same as...\nbarley %&gt;% group_by(dose) %&gt;% summarise(mean(yield))\n\n# A tibble: 3 × 2\n  dose    `mean(yield)`\n  &lt;chr&gt;           &lt;dbl&gt;\n1 1000ppm          8.20\n2 100ppm           7.90\n3 10ppm            5.00\n\n\n(d) Which nutrient seems to be associated with the largest yield?\n\nbarley_summarise %&gt;% group_by(nutrient) %&gt;% summarise(mean(mean_yield))\n\n# A tibble: 3 × 2\n  nutrient  `mean(mean_yield)`\n  &lt;chr&gt;                  &lt;dbl&gt;\n1 nitrogen                7.04\n2 phosphate               6.78\n3 potassium               7.28\n\n## which is the same as...\nbarley %&gt;% group_by(nutrient) %&gt;% summarise(mean(yield))\n\n# A tibble: 3 × 2\n  nutrient  `mean(yield)`\n  &lt;chr&gt;             &lt;dbl&gt;\n1 nitrogen           7.04\n2 phosphate          6.78\n3 potassium          7.28\n\n\n(e) The figure below displays an ‘interaction plot’, as seen in class. Does there appear to be an interaction between the factors dose and nutrient? Why?\n\nbarley %&gt;%\n  group_by(dose, nutrient) %&gt;%\n  summarise(mean = mean(yield)) %&gt;%\n  ggplot(aes(x = nutrient, y = mean, colour = dose, group = dose)) +\n  theme_bw() +\n  geom_point() +\n  geom_line()"
  },
  {
    "objectID": "7-PredictiveAnalytics.html#definition-of-predictive-analytics",
    "href": "7-PredictiveAnalytics.html#definition-of-predictive-analytics",
    "title": "Predictive Analytics",
    "section": "",
    "text": "Analyzes historical and current data to make predictions about future events or behaviors\nCombines statistical techniques, machine learning algorithms, and data mining to identify patterns and trends\nUsed in many areas, e.g. insurance companies, banks, stock market, medical research, ecological monitoring, etc\n\n\n\n\nData collection gathers relevant information from various sources\nData preprocessing cleans and transforms raw data into a suitable format for analysis\nFeature engineering creates new variables or selects relevant features to improve model performance\nModel development builds and trains predictive algorithms using historical data\nModel evaluation assesses the accuracy and reliability of predictions using various metrics\n\n\n\n\n\nStructured data organized in predefined formats (spreadsheets)\nUnstructured data lacks a predefined structure (text documents, images, videos)\nTime series data represents observations collected at regular intervals over time (stock prices, weather data)\nCross-sectional data captures information from multiple subjects at a single point in time (survey responses)"
  },
  {
    "objectID": "7-PredictiveAnalytics.html#predictive-modeling-process",
    "href": "7-PredictiveAnalytics.html#predictive-modeling-process",
    "title": "Predictive Analytics",
    "section": "Predictive modeling process",
    "text": "Predictive modeling process\n\n1. Problem definition\n\nIdentifies the specific problem or question to be addressed\nDetermines the outcome to be predicted (e.g., customer churn, sales volume)\n\n\n\n2. Data preparation\n\nData cleaning removes or corrects errors, inconsistencies, and missing values in the dataset\nData integration combines data from multiple sources into a unified format for analysis\nData transformation applies mathematical or logical operations to create new variables or modify existing ones\n\n\n\n3. Model training\n\nExplores both traditional statistical methods and machine learning algorithms\nSplits the prepared data into training and testing sets to assess model performance\nApplies selected algorithms to the training data to learn patterns and relationships\n\n\n\n4. Model evaluation\n\nCalculates relevant evaluation metrics to assesses model performance on the held-out test data to measure generalization\nEvaluates different types of predictive models based on the problem and data characteristics\nConsiders factors such as interpretability, scalability, and computational requirements\nAssesses the trade-offs between model complexity and performance\n\n\n\n5. Model selection\n\nSelects an appropriate model for the specific predictive task"
  },
  {
    "objectID": "7-PredictiveAnalytics.html#common-predictive-techniques",
    "href": "7-PredictiveAnalytics.html#common-predictive-techniques",
    "title": "Predictive Analytics",
    "section": "Common predictive techniques",
    "text": "Common predictive techniques\nDepending on the type of the outcome variable (y) we may be facing two different types of prediction models.\n\nFor classification problems\nFor classification problems, usual predictive analytics techniques include\n\nlogistic regression\nclassification trees\nk-nearest neighbours\nsupport vector machines\ndiscriminant analysis\nneural networks\n\nWe will study classification trees and k-nearest neighbours in this lecture. We will not look at the mathematics in detail, the objectives are to understand how they work and be able to interpret the results.\n\n\nFor regression problems\nFor regression problems, usual predictive analytics techniques include\n\nlinear regression\nregression trees\nrandom forests\ngeneralised additive models\n\nWe will study regression trees in this lecture. We will not look at the mathematics in detail, the objectives are to understand how they work and be able to interpret the results."
  },
  {
    "objectID": "7-PredictiveAnalytics.html#evaluating-prediction-performance",
    "href": "7-PredictiveAnalytics.html#evaluating-prediction-performance",
    "title": "Predictive Analytics",
    "section": "Evaluating Prediction Performance",
    "text": "Evaluating Prediction Performance\nThe mechanics of prediction is easy:\n\nPlug in values of predictors to the model equation\nCalculate the predicted value of the response variable,\n\nGetting it right is hard!\n\nThere is no guarantee the model estimates you have are correct\nOr that your model will perform as well with new data as it did with your sample data\n\nSpending our data\n\nSeveral steps are required to create a useful model: parameter estimation,performance assessment,model selection etc.\nDoing all of this on the entire data we have available can lead to overfitting i.e., the model doesn’t generalise\nInstead we allocate specific subsets of data for different tasks, as opposed to allocating the largest possible amount to the model parameter estimation only (which is what we’ve done so far).\n\nSplitting Data\nTraining set:\n\nSandbox for model building\nSpend most of your time using the training set to develop the model\nMajority of the data (usually 80%)\n\nTesting set:\n\nHeld in reserve to determine efficacy of one or two chosen models\nCritical to look at it once, otherwise it becomes part of the modeling process\nRemainder of the data (usually 20%)\n\n\nPerforming the split\nLet’s consider an example here. We have data on paintings from auction catalogs in paris. A glimpse of the data is shown below.\n\nglimpse(paris_paintings)\n\nRows: 220\nColumns: 12\n$ name         &lt;chr&gt; \"L1764-4\", \"L1764-7a\", \"L1764-7b\", \"L1764-10a\", \"L1764-10…\n$ sale         &lt;chr&gt; \"L1764\", \"L1764\", \"L1764\", \"L1764\", \"L1764\", \"L1764\", \"L1…\n$ lot          &lt;chr&gt; \"4\", \"7\", \"7\", \"10\", \"10\", \"10\", \"15\", \"16\", \"16\", \"40\", …\n$ year         &lt;dbl&gt; 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 176…\n$ logprice     &lt;dbl&gt; 2.4849067, 2.4849067, 2.4849067, 0.2876818, 0.2876818, 0.…\n$ price        &lt;dbl&gt; 12.0, 12.0, 12.0, 1.3, 1.3, 1.3, 6.0, 12.0, 12.0, 300.0, …\n$ subject      &lt;chr&gt; \"L'enfant Jesus & Saint Jean\", \"(2) Venus qui retient Ado…\n$ Height_in    &lt;dbl&gt; 13.00, 6.00, 6.00, 16.00, 16.00, 16.00, 36.00, 27.00, 27.…\n$ Width_in     &lt;dbl&gt; 16.00, 13.00, 13.00, 12.00, 12.00, 12.00, 48.00, 36.00, 3…\n$ Surface_Rect &lt;dbl&gt; 208.0000, 78.0000, 78.0000, 192.0000, 192.0000, 192.0000,…\n$ materialCat  &lt;chr&gt; \"wood\", \"canvas\", \"canvas\", \"canvas\", \"canvas\", \"canvas\",…\n$ landsALL     &lt;dbl&gt; 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, …\n\n\nWe will split the data into training and testing datasets\n\nlibrary(rsample)\n# Fix random numbers by setting the seed \nset.seed(1116)\n# Put 80% of the data into the training set \nprice_split &lt;- initial_split(paris_paintings, prop = 0.80)\n# Create data frames for the two sets:\ntrain_data &lt;- training(price_split)\ntest_data  &lt;- testing(price_split)\n\nFit a model and “learn” from the training data:\n\nlm_model_train &lt;- lm(logprice ~ Height_in + Width_in + year + Surface_Rect + \n                       materialCat + landsALL, data = train_data)\n\nEvaluate the performance on the test data:\n\nprice_res_test &lt;- test_data %&gt;% \n                    select(logprice) %&gt;% \n                    mutate(pred_price = predict(lm_model_train, newdata = test_data))\n\nggplot(price_res_test, aes(x = logprice, y = pred_price)) +\n  geom_point() + \n  geom_line(aes(x = logprice, y = logprice))\n\n\n\n\n\n\n\n\nSummarise the model accuracy\n\nprice_res_test %&gt;% \n  summarise(mean_error = mean(logprice - pred_price),\n            mean_abs_error = mean(abs(logprice - pred_price)))\n\n# A tibble: 1 × 2\n  mean_error mean_abs_error\n       &lt;dbl&gt;          &lt;dbl&gt;\n1    0.00278           1.71"
  },
  {
    "objectID": "7-PredictiveAnalytics.html#classification-problems",
    "href": "7-PredictiveAnalytics.html#classification-problems",
    "title": "Predictive Analytics",
    "section": "Classification Problems",
    "text": "Classification Problems\n\nClassification trees\nClassification trees can be used to create predictions for a categorical variable.\nThe basic idea is to split the predictors so as to minimise the classification error. There are many algorithms that can be used to produce a classification tree, and different criteria to be minimised so as to improve predictive power.\nEach split is binary, i.e. two branches are generated. At the end of the tree we have the leaves or terminal nodes. In the case of a classification tree, the predictions will be the classes for the majority of observations belonging to that terminal node.\nSee below for an example of a classification tree:\n\n\n\nK-nearest neighbours\nImagine we want to predict whether a film is classified as action or romance, based on two variables: number of kisses or number of kicks that appear in the film. Suppose that we have a database of films and the data looks like this:\n\n\nRows: 20\nColumns: 3\n$ kicks  &lt;dbl&gt; 3, 2, 5, 4, 5, 7, 3, 5, 6, 3, 16, 16, 13, 11, 10, 17, 12, 15, 8…\n$ kisses &lt;dbl&gt; 20, 17, 16, 14, 12, 9, 12, 19, 17, 27, 3, 2, 2, 4, 3, 3, 2, 5, …\n$ genre  &lt;chr&gt; \"romance\", \"romance\", \"romance\", \"romance\", \"romance\", \"romance…\n\n\n\n\n\n\n\n\n\nWhat genre is the film represented by a black dot? We could employ the \\(k\\)-nearest neighbours algorithm to classify it. If we choose, e.g. \\(k=5\\), then we would have 4 out of the 5 nearest neighbours classified as an action film. Therefore, the algorithm would classify the film represented by the black dot as an action film as well.\nThis is an example with two predictors, but this can be easily extended to higher dimensions.\n\n\nExample: Diabetes in Pima Indian Women data\nWe will now use logistic regression, a classification tree, and the k-nearest neighbours algorithm to predict whether a woman in the Pima.tr dataset has diabetes or not.\nThe Pima.tr dataset from package MASS has been used before during a lab. It has information on several biomarkers, such as glucose levels and blood pressure, as well as other variables such as age. The response type indicates whether that particular individual had diabetes or not. Our objective is to predict whether a woman has diabetes using information from the other variables in the dataset.\n\nPima.tr &lt;- MASS::Pima.tr\nglimpse(Pima.tr)\n\nRows: 200\nColumns: 8\n$ npreg &lt;int&gt; 5, 7, 5, 0, 0, 5, 3, 1, 3, 2, 0, 9, 1, 12, 1, 4, 1, 11, 1, 0, 2,…\n$ glu   &lt;int&gt; 86, 195, 77, 165, 107, 97, 83, 193, 142, 128, 137, 154, 189, 92,…\n$ bp    &lt;int&gt; 68, 70, 82, 76, 60, 76, 58, 50, 80, 78, 40, 78, 60, 62, 66, 76, …\n$ skin  &lt;int&gt; 28, 33, 41, 43, 25, 27, 31, 16, 15, 37, 35, 30, 23, 7, 52, 15, 8…\n$ bmi   &lt;dbl&gt; 30.2, 25.1, 35.8, 47.9, 26.4, 35.6, 34.3, 25.9, 32.4, 43.3, 43.1…\n$ ped   &lt;dbl&gt; 0.364, 0.163, 0.156, 0.259, 0.133, 0.378, 0.336, 0.655, 0.200, 1…\n$ age   &lt;int&gt; 24, 55, 35, 26, 23, 52, 25, 24, 63, 31, 33, 45, 59, 44, 29, 21, …\n$ type  &lt;fct&gt; No, Yes, No, No, No, Yes, No, No, No, Yes, Yes, No, Yes, Yes, No…\n\nPima.tr &lt;- Pima.tr %&gt;% mutate(type = factor(type, labels = c(\"Neg\",\"Pos\")))\n\nLet’s split our data\n\nlibrary(rsample)\n# Fix random numbers by setting the seed \nset.seed(1116)\n# Put 80% of the data into the training set \npima_split &lt;- initial_split(Pima.tr, prop = 0.80)\n# Create data frames for the two sets:\ntrain_pima_data &lt;- training(pima_split)\ntest_pima_data  &lt;- testing(pima_split)\n\nWe will start with logistic regression\nLet’s fit a multiple logistic regression model:\n\nfit_logistic &lt;- glm(type ~ ., family = binomial, data = train_pima_data)\nfit_logistic\n\n\nCall:  glm(formula = type ~ ., family = binomial, data = train_pima_data)\n\nCoefficients:\n(Intercept)        npreg          glu           bp         skin          bmi  \n -12.565120     0.053341     0.028476     0.005766     0.001172     0.139419  \n        ped          age  \n   2.263408     0.060450  \n\nDegrees of Freedom: 159 Total (i.e. Null);  152 Residual\nNull Deviance:      204.6 \nResidual Deviance: 134.7    AIC: 150.7\n\n\nWe can use the predict function to obtain predictions for each individual in the dataset:\n\npima_res_test &lt;- test_pima_data %&gt;%\n                  mutate(pred_p = \n                         predict(fit_logistic, \n                                     type = \"response\", newdata = test_pima_data)) %&gt;% \n   mutate(pred_type = ifelse(pred_p &gt;=0.5,\"Pos\",\"Neg\"))\n\npima_res_test\n\n   npreg glu  bp skin  bmi   ped age type      pred_p pred_type\n1      7 195  70   33 25.1 0.163  55  Pos 0.730366555       Pos\n2      0 165  76   43 47.9 0.259  26  Neg 0.811244142       Pos\n3      1 189  60   23 30.1 0.398  59  Pos 0.870681831       Pos\n4      4  99  76   15 23.2 0.223  21  Neg 0.016821666       Neg\n5      1  87  68   34 37.6 0.401  24  Neg 0.119008947       Neg\n6      1  79  80   25 25.4 0.583  22  Neg 0.027096514       Neg\n7      0 119  66   27 38.8 0.259  22  Neg 0.191746781       Neg\n8      3 171  72   33 33.3 0.199  24  Pos 0.368649896       Neg\n9      4 127  88   11 34.5 0.598  28  Neg 0.411219278       Neg\n10     1 124  74   36 27.8 0.100  30  Neg 0.069383986       Neg\n11     6 109  60   27 25.0 0.206  27  Neg 0.039936807       Neg\n12     5 139  80   35 31.6 0.361  25  Pos 0.248995767       Neg\n13     6 134  70   23 35.4 0.542  29  Pos 0.479145323       Neg\n14     3 106  54   21 30.9 0.292  24  Neg 0.067175718       Neg\n15     0 135  94   46 40.6 0.284  26  Neg 0.437816778       Neg\n16     1 168  88   29 35.0 0.905  52  Pos 0.947101920       Pos\n17     1 144  82   46 46.1 0.335  46  Pos 0.889106686       Pos\n18    12 121  78   17 26.5 0.259  62  Neg 0.504745008       Pos\n19     6 125  78   31 27.6 0.565  49  Pos 0.472366580       Neg\n20     1  79  75   30 32.0 0.396  22  Neg 0.042821739       Neg\n21     4 112  78   40 39.4 0.236  38  Neg 0.415459765       Neg\n22     2  94  76   18 31.6 0.649  23  Neg 0.113303157       Neg\n23     2  84  50   23 30.4 0.968  21  Neg 0.113806856       Neg\n24     4 117  62   12 29.7 0.380  30  Pos 0.137742566       Neg\n25     1  81  74   41 46.3 1.096  32  Neg 0.757626954       Pos\n26     1 120  80   48 38.9 1.162  41  Neg 0.875970147       Pos\n27     7 187  68   39 37.7 0.254  41  Pos 0.867670601       Pos\n28     7 179  95   31 34.2 0.164  60  Neg 0.905158936       Pos\n29     6  80  66   30 26.2 0.313  41  Neg 0.062292657       Neg\n30     1  97  70   15 18.2 0.147  21  Neg 0.005547706       Neg\n31     0 100  88   60 46.8 0.962  31  Neg 0.807891465       Pos\n32     6 154  78   41 46.1 0.571  27  Neg 0.879721246       Pos\n33     2  56  56   28 24.2 0.332  22  Neg 0.006350983       Neg\n34     0 188  82   14 32.0 0.682  22  Pos 0.648518039       Pos\n35     2 197  70   99 34.7 0.575  62  Pos 0.972298384       Pos\n36     2 142  82   18 24.7 0.761  21  Neg 0.184614941       Neg\n37     1 164  82   43 32.8 0.341  50  Neg 0.740536767       Pos\n38     6 144  72   27 33.9 0.255  40  Neg 0.505934522       Pos\n39    14 175  62   30 33.6 0.212  38  Pos 0.734781108       Pos\n40     1 133 102   28 32.8 0.234  45  Pos 0.430286553       Neg\n\n\nWe set the threshold for prediction as threshold = 0.50.\nNow we can have a look at the confusion matrix. Generally, this has the form\n\\[\\begin{array}{c|cc}\n    & \\text{Predicted Negative} & \\text{Predicted Positive} \\\\\n    \\hline\n    \\text{Actual Negative} & TN & FP \\\\\n    \\text{Actual Positive} & FN & TP\n\\end{array}\\]\nFor our example we have\n\nN &lt;- nrow(pima_res_test)\n\nconfusion_mat &lt;- table(pima_res_test %&gt;% select(type, pred_type))\nconfusion_mat\n\n     pred_type\ntype  Neg Pos\n  Neg  17   9\n  Pos   6   8\n\naccuracy &lt;- (confusion_mat %&gt;% diag %&gt;% sum)/N\naccuracy\n\n[1] 0.625\n\n\n\nOverall accuracy = (TN + TP)/(TN + FP + FN + TP) \\(= (17+8)/(17+9+6+8) = 0.625\\)\nTrue positive rate (TPR) = TP/(TP + FN) \\(= 8/(8+6) = 0.57\\)\n\nTPR is the probability that an actual positive will be classified as positive. This is also known as sensitivity.\n\nTrue negative rate (TNR) = TN/(TN + FP) \\(= 17/(17+9) = 0.65\\)\n\nTNR is the probability that an actual negative will be classified as negative. This is also known as specificity.\n\n\nNow we will fit a classification tree\n\nfit_tree &lt;- rpart(type ~ ., data = train_pima_data)\nrpart.plot(fit_tree)\n\n\n\n\n\n\n\n\nLet’s check the predictions:\n\npima_res_test2 &lt;- test_pima_data %&gt;%\n                  mutate(pred_p = \n                         predict(fit_tree, \n                                 newdata = test_pima_data) %&gt;% as_tibble() %&gt;% pull(Pos)) %&gt;% \n                  mutate(pred_type = ifelse(pred_p &gt;=0.5,\"Pos\",\"Neg\"))\n\npima_res_test2\n\n   npreg glu  bp skin  bmi   ped age type     pred_p pred_type\n1      7 195  70   33 25.1 0.163  55  Pos 0.33333333       Neg\n2      0 165  76   43 47.9 0.259  26  Neg 0.84375000       Pos\n3      1 189  60   23 30.1 0.398  59  Pos 0.33333333       Neg\n4      4  99  76   15 23.2 0.223  21  Neg 0.07246377       Neg\n5      1  87  68   34 37.6 0.401  24  Neg 0.07246377       Neg\n6      1  79  80   25 25.4 0.583  22  Neg 0.07246377       Neg\n7      0 119  66   27 38.8 0.259  22  Neg 0.07246377       Neg\n8      3 171  72   33 33.3 0.199  24  Pos 0.00000000       Neg\n9      4 127  88   11 34.5 0.598  28  Neg 0.84375000       Pos\n10     1 124  74   36 27.8 0.100  30  Neg 0.33333333       Neg\n11     6 109  60   27 25.0 0.206  27  Neg 0.07246377       Neg\n12     5 139  80   35 31.6 0.361  25  Pos 0.00000000       Neg\n13     6 134  70   23 35.4 0.542  29  Pos 0.84375000       Pos\n14     3 106  54   21 30.9 0.292  24  Neg 0.07246377       Neg\n15     0 135  94   46 40.6 0.284  26  Neg 0.84375000       Pos\n16     1 168  88   29 35.0 0.905  52  Pos 0.84375000       Pos\n17     1 144  82   46 46.1 0.335  46  Pos 0.84375000       Pos\n18    12 121  78   17 26.5 0.259  62  Neg 0.11111111       Neg\n19     6 125  78   31 27.6 0.565  49  Pos 0.80000000       Pos\n20     1  79  75   30 32.0 0.396  22  Neg 0.07246377       Neg\n21     4 112  78   40 39.4 0.236  38  Neg 0.61538462       Pos\n22     2  94  76   18 31.6 0.649  23  Neg 0.07246377       Neg\n23     2  84  50   23 30.4 0.968  21  Neg 0.07246377       Neg\n24     4 117  62   12 29.7 0.380  30  Pos 0.07246377       Neg\n25     1  81  74   41 46.3 1.096  32  Neg 0.61538462       Pos\n26     1 120  80   48 38.9 1.162  41  Neg 0.61538462       Pos\n27     7 187  68   39 37.7 0.254  41  Pos 0.84375000       Pos\n28     7 179  95   31 34.2 0.164  60  Neg 0.84375000       Pos\n29     6  80  66   30 26.2 0.313  41  Neg 0.11111111       Neg\n30     1  97  70   15 18.2 0.147  21  Neg 0.07246377       Neg\n31     0 100  88   60 46.8 0.962  31  Neg 0.61538462       Pos\n32     6 154  78   41 46.1 0.571  27  Neg 0.84375000       Pos\n33     2  56  56   28 24.2 0.332  22  Neg 0.07246377       Neg\n34     0 188  82   14 32.0 0.682  22  Pos 0.00000000       Neg\n35     2 197  70   99 34.7 0.575  62  Pos 0.84375000       Pos\n36     2 142  82   18 24.7 0.761  21  Neg 0.00000000       Neg\n37     1 164  82   43 32.8 0.341  50  Neg 0.33333333       Neg\n38     6 144  72   27 33.9 0.255  40  Neg 0.84375000       Pos\n39    14 175  62   30 33.6 0.212  38  Pos 0.33333333       Neg\n40     1 133 102   28 32.8 0.234  45  Pos 0.33333333       Neg\n\n\nWe set the threshold for prediction as threshold = 0.50, now we can have a look at the accuracy of the method:\n\nN &lt;- nrow(pima_res_test2)\n\nconfusion_mat2 &lt;- table(pima_res_test2 %&gt;% select(type, pred_type))\nconfusion_mat2\n\n     pred_type\ntype  Neg Pos\n  Neg  16  10\n  Pos   8   6\n\naccuracy2 &lt;- (confusion_mat2 %&gt;% diag %&gt;% sum)/N\naccuracy2\n\n[1] 0.55\n\n\n\nOverall accuracy \\(= (16+6)/(16+10+8+6) = 0.55\\)\nTrue positive rate \\(= 6/(6+8) = 0.43\\)\nTrue negative rate \\(= 16/(16+10) = 0.62\\)\n\nNow we will use the k-nearest neighbours algorithm\nWe’ll use 10 nearest neighbours.\n\npred_type_knn &lt;- knn(train_pima_data %&gt;% select(-type), \n                     test_pima_data %&gt;% select(-type), \n                     cl =   train_pima_data %&gt;% pull(type), \n                     k = 10)\n\npima_res_test3 &lt;- test_pima_data %&gt;%\n                  mutate(pred_type = pred_type_knn)\n\npima_res_test3\n\n   npreg glu  bp skin  bmi   ped age type pred_type\n1      7 195  70   33 25.1 0.163  55  Pos       Pos\n2      0 165  76   43 47.9 0.259  26  Neg       Pos\n3      1 189  60   23 30.1 0.398  59  Pos       Pos\n4      4  99  76   15 23.2 0.223  21  Neg       Neg\n5      1  87  68   34 37.6 0.401  24  Neg       Neg\n6      1  79  80   25 25.4 0.583  22  Neg       Neg\n7      0 119  66   27 38.8 0.259  22  Neg       Neg\n8      3 171  72   33 33.3 0.199  24  Pos       Pos\n9      4 127  88   11 34.5 0.598  28  Neg       Neg\n10     1 124  74   36 27.8 0.100  30  Neg       Neg\n11     6 109  60   27 25.0 0.206  27  Neg       Neg\n12     5 139  80   35 31.6 0.361  25  Pos       Neg\n13     6 134  70   23 35.4 0.542  29  Pos       Neg\n14     3 106  54   21 30.9 0.292  24  Neg       Neg\n15     0 135  94   46 40.6 0.284  26  Neg       Neg\n16     1 168  88   29 35.0 0.905  52  Pos       Pos\n17     1 144  82   46 46.1 0.335  46  Pos       Pos\n18    12 121  78   17 26.5 0.259  62  Neg       Neg\n19     6 125  78   31 27.6 0.565  49  Pos       Neg\n20     1  79  75   30 32.0 0.396  22  Neg       Neg\n21     4 112  78   40 39.4 0.236  38  Neg       Neg\n22     2  94  76   18 31.6 0.649  23  Neg       Neg\n23     2  84  50   23 30.4 0.968  21  Neg       Neg\n24     4 117  62   12 29.7 0.380  30  Pos       Neg\n25     1  81  74   41 46.3 1.096  32  Neg       Neg\n26     1 120  80   48 38.9 1.162  41  Neg       Neg\n27     7 187  68   39 37.7 0.254  41  Pos       Pos\n28     7 179  95   31 34.2 0.164  60  Neg       Pos\n29     6  80  66   30 26.2 0.313  41  Neg       Neg\n30     1  97  70   15 18.2 0.147  21  Neg       Neg\n31     0 100  88   60 46.8 0.962  31  Neg       Neg\n32     6 154  78   41 46.1 0.571  27  Neg       Pos\n33     2  56  56   28 24.2 0.332  22  Neg       Neg\n34     0 188  82   14 32.0 0.682  22  Pos       Pos\n35     2 197  70   99 34.7 0.575  62  Pos       Pos\n36     2 142  82   18 24.7 0.761  21  Neg       Neg\n37     1 164  82   43 32.8 0.341  50  Neg       Pos\n38     6 144  72   27 33.9 0.255  40  Neg       Pos\n39    14 175  62   30 33.6 0.212  38  Pos       Pos\n40     1 133 102   28 32.8 0.234  45  Pos       Pos\n\n\nNow we can have a look at the accuracy of the method:\n\nN &lt;- nrow(pima_res_test3)\n\nconfusion_mat3 &lt;- table(pima_res_test3 %&gt;% select(type, pred_type))\nconfusion_mat3\n\n     pred_type\ntype  Neg Pos\n  Neg  21   5\n  Pos   4  10\n\naccuracy3 &lt;- (confusion_mat3 %&gt;% diag %&gt;% sum)/N\naccuracy3\n\n[1] 0.775\n\n\nOverall accuracy \\(= (21+10)/(21+5+4+10) = 0.78\\)\nTrue positive rate \\(= 10/(4+10) = 0.71\\)\nTrue negative rate \\(= 21/(21+5) = 0.81\\)\nWe can assess the overall accuracy, true positive and true negative rates for different values of \\(k\\):"
  },
  {
    "objectID": "7-PredictiveAnalytics.html#regression-problems",
    "href": "7-PredictiveAnalytics.html#regression-problems",
    "title": "Predictive Analytics",
    "section": "Regression Problems",
    "text": "Regression Problems\n\nRegression Trees\nRegression trees are similar to classification trees. The difference is that the response variable is continuous instead of categorical.\nThe same reasoning is employed when constructing a regression tree: the predictors are split in such a way that the prediction error is minimised. In the case of regression trees, we may opt to minimise the residual sum of squares, for example.\nFor the leaves or terminal nodes, the predictions will be the average estimate for the observations that belong to that terminal node.\n\n\nExample: Pima data\nWe will now use linear regression and a regression tree to obtain predictions for the glu variable using the Pima.tr data.\nSplit the data\n\nlibrary(rsample)\n# Fix random numbers by setting the seed \nset.seed(1116)\n# Put 80% of the data into the training set \npima_split &lt;- initial_split(Pima.tr, prop = 0.80)\n# Create data frames for the two sets:\ntrain_pima_data &lt;- training(pima_split)\ntest_pima_data  &lt;- testing(pima_split)\n\nFitting a multiple linear regression model\n\nfit_lm &lt;- lm(glu ~ ., data = train_pima_data)\nfit_lm\n\n\nCall:\nlm(formula = glu ~ ., data = train_pima_data)\n\nCoefficients:\n(Intercept)        npreg           bp         skin          bmi          ped  \n    70.2137      -0.5522       0.4133      -0.0431       0.2508       4.0819  \n        age      typePos  \n     0.2751      22.6378  \n\n\nEvaluate the performance on the test data:\n\nglu_res_test &lt;- test_pima_data %&gt;% \n                    mutate(pred_glu = predict(fit_lm, test_pima_data))\n\nggplot(glu_res_test, aes(x = glu, y = pred_glu)) +\n  geom_point() + \n  geom_line(aes(x = glu, y = glu))\n\n\n\n\n\n\n\n\nSummarise the model accuracy\nIn addition to mean error and mean absolute error which we have used before, we can also have a look at the correlation between observed and predicted values to help us summarise how well our model performs:\n\nglu_res_test %&gt;% \n  summarise(mean_error = mean(glu - pred_glu),\n            mean_abs_error = mean(abs(glu - pred_glu)),\n            cor = cor(glu, pred_glu))\n\n  mean_error mean_abs_error       cor\n1   5.105036       25.05825 0.6643261\n\n\nNow fit a regression tree\n\nfit_reg_tree &lt;- rpart(glu ~ ., data = train_pima_data)\nrpart.plot(fit_reg_tree)\n\n\n\n\n\n\n\n\nEvaluate the performance on the test data:\n\nglu_res_test2 &lt;- test_pima_data %&gt;% \n                    mutate(pred_glu = predict(fit_reg_tree, test_pima_data))\n\nggplot(glu_res_test2, aes(x = glu, y = pred_glu)) +\n  geom_point() + \n  geom_line(aes(x = glu, y = glu))\n\n\n\n\n\n\n\n\nSummarise the model accuracy\n\nglu_res_test2 %&gt;% \n  summarise(mean_error = mean(glu - pred_glu),\n            mean_abs_error = mean(abs(glu - pred_glu)),\n            cor = cor(glu, pred_glu))\n\n  mean_error mean_abs_error       cor\n1   10.35319       29.49208 0.3722016"
  },
  {
    "objectID": "7-PredictiveAnalytics.html#summary-of-training-and-testing",
    "href": "7-PredictiveAnalytics.html#summary-of-training-and-testing",
    "title": "Predictive Analytics",
    "section": "Summary of Training and testing",
    "text": "Summary of Training and testing\nSplitting Data\nTraining set:\n\nSandbox for model building\nSpend most of your time using the training set to develop the model\nMajority of the data (usually 80%)\n\nTesting set:\n\nHeld in reserve to determine efficacy of one or two chosen models\nRemainder of the data (usually 20%)\n\nIt is important to note that while we’ve only looked at training/test splits of the data, 3 splits are often used when there’s multiple modelling options to choose from. In this case the procedure is broken down into three steps\n\nTraining - to train the various models\nValidation - do assess performance of models and choose the best one\nTest - to assess the performance of the chosen model\n\nWe won’t go into these splits but it’s important to be aware of this practice.\n\n\nTraining vs test accuracy/mean errors\nWe expect the test error to be greater than the training error, after all the model ``has not seen’’ the test data before. This is essentially what we want in real life, after all we will use our data to fit a predictiion model, and we will use it to predict responses that are unknown."
  },
  {
    "objectID": "8-(un)supervisedLearning.html",
    "href": "8-(un)supervisedLearning.html",
    "title": "Supervised and Unsupervised Learning",
    "section": "",
    "text": "Machine learning is the act of discovering patterns buried in large data sets.\nThe majority of practical machine learning uses supervised learning.\nSupervised learning is where you have input (predictor) variables (x) and an output variable (y) and you use an algorithm to learn how the input relates to the output.\n\\[y = f(x)\\]\nThe goal is to approximate the mapping function so well that when you have new input data (x) that you can predict the output variables (y) for that data.\nIt is called supervised learning because the process of an algorithm learning from the training dataset can be thought of as a teacher supervising the learning process. We know the correct answers, the algorithm iteratively makes predictions on the “training” data and is corrected by the teacher. Learning stops when the algorithm achieves an acceptable level of performance.\nSupervised learning problems can be further grouped into regression and classification problems:\nRegression: A regression problem is when the output variable is a real value, such as “dollars” or “weight”.\nClassification: A classification problem is when the output variable is a category, such as “red” or “blue” or “disease” and “no disease”.\nWe saw these supervised learning methods in the predictive analytics section.\n\n\nUS Department of Health and Human Services, Centers for Disease Control and Prevention collect information on births recorded in the country. We have data which are a random sample of 1,000 births from 2014. Variables of interest include length of pregnancy in weeks (weeks), mother’s age in years (mage), the sex of the baby (sex), smoking status of the mother (habit), and the number of hospital (visits) visits during pregnancy.\n\nbirths14\n\n# A tibble: 794 × 13\n    fage  mage mature     weeks premie visits gained weight lowbirthweight sex  \n   &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt;\n 1    34    34 younger m…    37 full …     14     28   6.96 not low        male \n 2    36    31 younger m…    41 full …     12     41   8.86 not low        fema…\n 3    37    36 mature mom    37 full …     10     28   7.51 not low        fema…\n 4    32    31 younger m…    36 premie     12     48   6.75 not low        fema…\n 5    32    26 younger m…    39 full …     14     45   6.69 not low        fema…\n 6    37    36 mature mom    36 premie     10     20   6.13 not low        fema…\n 7    29    24 younger m…    40 full …     13     65   6.74 not low        male \n 8    30    32 younger m…    39 full …     15     25   8.94 not low        fema…\n 9    29    26 younger m…    39 full …     11     22   9.12 not low        male \n10    30    34 younger m…    42 full …     14     40   8.91 not low        male \n# ℹ 784 more rows\n# ℹ 3 more variables: habit &lt;chr&gt;, marital &lt;chr&gt;, whitemom &lt;chr&gt;\n\n\n\n\n\nlibrary(rsample)\n# Fix random numbers by setting the seed \nset.seed(1116)\n# Put 80% of the data into the training set \nbirths_split &lt;- initial_split(births14, prop = 0.80)\n# Create data frames for the two sets:\ntrain_data &lt;- training(births_split)\ntest_data  &lt;- testing(births_split)\n\n\n\n\nLet’s explore a multiple regression option\n\nlm_model_train &lt;- lm(weight ~ weeks + mage + sex + habit + visits, data = train_data)\n\n\n\n\n\nbirths_res_test &lt;- test_data %&gt;% \n                    select(weight) %&gt;% \n                    mutate(pred_weight = predict(lm_model_train, test_data))\n\nggplot(births_res_test, aes(x = weight, y = pred_weight)) +\n  geom_point() + \n  geom_line(aes(x = weight, y = weight))\n\n\n\n\n\n\n\n\n\n\n\n\nbirths_res_test %&gt;% \n  summarise(mean_error = mean(weight - pred_weight),\n            mean_abs_error = mean(abs(weight - pred_weight)))\n\n# A tibble: 1 × 2\n  mean_error mean_abs_error\n       &lt;dbl&gt;          &lt;dbl&gt;\n1     -0.145          0.794\n\n\nThe model is trying to “learn” about the relationship between the price of a painting and other painting attributes. If the model does a good job at “learning” then knowing various painting attributes/features can predict what their price will be. This is a supervised learning method because the accuracy of the model’s predictive performance can be evaluated.\n\n\n\n\nThe ‘Cryotherapy’ dataset gives the results of a cryotherapy procedure (1 = successful, 0 = unsuccesful). In this case, our outcome of interest is the success category — it is what we want to predict.\n\ncryo_dat\n\n# A tibble: 90 × 6\n     sex   age  Time  Type  Area Result\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1     1    35 12        1   100      0\n 2     1    29  7        1    96      1\n 3     1    50  8        3   132      1\n 4     1    32 11.8      3   750      0\n 5     1    67  9.25     1    42      0\n 6     1    41  8        2    20      1\n 7     1    36 11        1     8      0\n 8     1    59  3.5      3    20      0\n 9     1    20  4.5      1     6      1\n10     2    34 11.2      3   150      0\n# ℹ 80 more rows\n\n\n\ncryo_dat &lt;- cryo_dat %&gt;% mutate(Result_label = factor(Result, labels = c(\"not successful\", \"successful\")))\n\nLet’s look at the relationship the Time spent doing the procedure and the success:\n\nggplot(cryo_dat, aes(x = Time, y = Result_label)) +\ngeom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\nlibrary(rsample)\nset.seed(11)\ncryo_split &lt;- initial_split(cryo_dat, prop = 0.70)\n\ntrain_data &lt;- training(cryo_split)\ntest_data  &lt;- testing(cryo_split)\n\n\n\n\nLet’s fit a classification tree model using the Time spent doing the procedure and some additional predictors to predict the success:\n\nlibrary(rpart)\ntree_model &lt;- rpart(Result_label ~ Time + sex + age + Area,  data = train_data)\n\nLet’s visualise the results of fitting the classification tree:\n\nlibrary(rpart.plot)\nrpart.plot(tree_model)\n\n\n\n\n\n\n\n\n\n\n\nLet’s see if the model does a good job at predicting the success:\n\ncryo_res &lt;- test_data %&gt;% \n            select(Result_label) %&gt;% \n            mutate(pred_p = predict(tree_model, \n                                    newdata = test_data) %&gt;% as_tibble() %&gt;% pull(successful)) %&gt;% \n            mutate(pred_result = ifelse(pred_p &gt;= 0.5,\"successful\",\"not successful\")) \ncryo_res\n\n# A tibble: 28 × 3\n   Result_label   pred_p pred_result   \n   &lt;fct&gt;           &lt;dbl&gt; &lt;chr&gt;         \n 1 not successful 0.0357 not successful\n 2 successful     0.963  successful    \n 3 not successful 0.0357 not successful\n 4 successful     0.963  successful    \n 5 successful     0.963  successful    \n 6 successful     0.963  successful    \n 7 not successful 0.0357 not successful\n 8 not successful 0.0357 not successful\n 9 successful     0.963  successful    \n10 successful     0.0357 not successful\n# ℹ 18 more rows\n\n\nLet’s evaluate the accuracy.\nWe will create a table known as a confusion matrix:\n\nN &lt;- nrow(cryo_res)\n\nconfusion_mat &lt;- table(cryo_res %&gt;% select(Result_label, pred_result))\nconfusion_mat\n\n                pred_result\nResult_label     not successful successful\n  not successful              8          0\n  successful                  3         17\n\naccuracy &lt;- (confusion_mat %&gt;% diag %&gt;% sum)/N\naccuracy\n\n[1] 0.8928571\n\n\nThe model has “learned” about the relationship between time spend on the procedure and its success. As a result, the company can predict what their success will be for a given time. The company can provide recommendations for the length of time a patient should undergo the procedure, for example, if the produce takes 10 minutes it’s more likely to be unsuccessful. This is a supervised learning method and therefore the company can also evaluate the accuracy of the model’s predictive performance.\nExercise: Try fitting a logistic regression model and a knn model to these data and compare the results."
  },
  {
    "objectID": "8-(un)supervisedLearning.html#supervised-learning",
    "href": "8-(un)supervisedLearning.html#supervised-learning",
    "title": "Supervised and Unsupervised Learning",
    "section": "",
    "text": "Machine learning is the act of discovering patterns buried in large data sets.\nThe majority of practical machine learning uses supervised learning.\nSupervised learning is where you have input (predictor) variables (x) and an output variable (y) and you use an algorithm to learn how the input relates to the output.\n\\[y = f(x)\\]\nThe goal is to approximate the mapping function so well that when you have new input data (x) that you can predict the output variables (y) for that data.\nIt is called supervised learning because the process of an algorithm learning from the training dataset can be thought of as a teacher supervising the learning process. We know the correct answers, the algorithm iteratively makes predictions on the “training” data and is corrected by the teacher. Learning stops when the algorithm achieves an acceptable level of performance.\nSupervised learning problems can be further grouped into regression and classification problems:\nRegression: A regression problem is when the output variable is a real value, such as “dollars” or “weight”.\nClassification: A classification problem is when the output variable is a category, such as “red” or “blue” or “disease” and “no disease”.\nWe saw these supervised learning methods in the predictive analytics section.\n\n\nUS Department of Health and Human Services, Centers for Disease Control and Prevention collect information on births recorded in the country. We have data which are a random sample of 1,000 births from 2014. Variables of interest include length of pregnancy in weeks (weeks), mother’s age in years (mage), the sex of the baby (sex), smoking status of the mother (habit), and the number of hospital (visits) visits during pregnancy.\n\nbirths14\n\n# A tibble: 794 × 13\n    fage  mage mature     weeks premie visits gained weight lowbirthweight sex  \n   &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt;\n 1    34    34 younger m…    37 full …     14     28   6.96 not low        male \n 2    36    31 younger m…    41 full …     12     41   8.86 not low        fema…\n 3    37    36 mature mom    37 full …     10     28   7.51 not low        fema…\n 4    32    31 younger m…    36 premie     12     48   6.75 not low        fema…\n 5    32    26 younger m…    39 full …     14     45   6.69 not low        fema…\n 6    37    36 mature mom    36 premie     10     20   6.13 not low        fema…\n 7    29    24 younger m…    40 full …     13     65   6.74 not low        male \n 8    30    32 younger m…    39 full …     15     25   8.94 not low        fema…\n 9    29    26 younger m…    39 full …     11     22   9.12 not low        male \n10    30    34 younger m…    42 full …     14     40   8.91 not low        male \n# ℹ 784 more rows\n# ℹ 3 more variables: habit &lt;chr&gt;, marital &lt;chr&gt;, whitemom &lt;chr&gt;\n\n\n\n\n\nlibrary(rsample)\n# Fix random numbers by setting the seed \nset.seed(1116)\n# Put 80% of the data into the training set \nbirths_split &lt;- initial_split(births14, prop = 0.80)\n# Create data frames for the two sets:\ntrain_data &lt;- training(births_split)\ntest_data  &lt;- testing(births_split)\n\n\n\n\nLet’s explore a multiple regression option\n\nlm_model_train &lt;- lm(weight ~ weeks + mage + sex + habit + visits, data = train_data)\n\n\n\n\n\nbirths_res_test &lt;- test_data %&gt;% \n                    select(weight) %&gt;% \n                    mutate(pred_weight = predict(lm_model_train, test_data))\n\nggplot(births_res_test, aes(x = weight, y = pred_weight)) +\n  geom_point() + \n  geom_line(aes(x = weight, y = weight))\n\n\n\n\n\n\n\n\n\n\n\n\nbirths_res_test %&gt;% \n  summarise(mean_error = mean(weight - pred_weight),\n            mean_abs_error = mean(abs(weight - pred_weight)))\n\n# A tibble: 1 × 2\n  mean_error mean_abs_error\n       &lt;dbl&gt;          &lt;dbl&gt;\n1     -0.145          0.794\n\n\nThe model is trying to “learn” about the relationship between the price of a painting and other painting attributes. If the model does a good job at “learning” then knowing various painting attributes/features can predict what their price will be. This is a supervised learning method because the accuracy of the model’s predictive performance can be evaluated.\n\n\n\n\nThe ‘Cryotherapy’ dataset gives the results of a cryotherapy procedure (1 = successful, 0 = unsuccesful). In this case, our outcome of interest is the success category — it is what we want to predict.\n\ncryo_dat\n\n# A tibble: 90 × 6\n     sex   age  Time  Type  Area Result\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1     1    35 12        1   100      0\n 2     1    29  7        1    96      1\n 3     1    50  8        3   132      1\n 4     1    32 11.8      3   750      0\n 5     1    67  9.25     1    42      0\n 6     1    41  8        2    20      1\n 7     1    36 11        1     8      0\n 8     1    59  3.5      3    20      0\n 9     1    20  4.5      1     6      1\n10     2    34 11.2      3   150      0\n# ℹ 80 more rows\n\n\n\ncryo_dat &lt;- cryo_dat %&gt;% mutate(Result_label = factor(Result, labels = c(\"not successful\", \"successful\")))\n\nLet’s look at the relationship the Time spent doing the procedure and the success:\n\nggplot(cryo_dat, aes(x = Time, y = Result_label)) +\ngeom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\nlibrary(rsample)\nset.seed(11)\ncryo_split &lt;- initial_split(cryo_dat, prop = 0.70)\n\ntrain_data &lt;- training(cryo_split)\ntest_data  &lt;- testing(cryo_split)\n\n\n\n\nLet’s fit a classification tree model using the Time spent doing the procedure and some additional predictors to predict the success:\n\nlibrary(rpart)\ntree_model &lt;- rpart(Result_label ~ Time + sex + age + Area,  data = train_data)\n\nLet’s visualise the results of fitting the classification tree:\n\nlibrary(rpart.plot)\nrpart.plot(tree_model)\n\n\n\n\n\n\n\n\n\n\n\nLet’s see if the model does a good job at predicting the success:\n\ncryo_res &lt;- test_data %&gt;% \n            select(Result_label) %&gt;% \n            mutate(pred_p = predict(tree_model, \n                                    newdata = test_data) %&gt;% as_tibble() %&gt;% pull(successful)) %&gt;% \n            mutate(pred_result = ifelse(pred_p &gt;= 0.5,\"successful\",\"not successful\")) \ncryo_res\n\n# A tibble: 28 × 3\n   Result_label   pred_p pred_result   \n   &lt;fct&gt;           &lt;dbl&gt; &lt;chr&gt;         \n 1 not successful 0.0357 not successful\n 2 successful     0.963  successful    \n 3 not successful 0.0357 not successful\n 4 successful     0.963  successful    \n 5 successful     0.963  successful    \n 6 successful     0.963  successful    \n 7 not successful 0.0357 not successful\n 8 not successful 0.0357 not successful\n 9 successful     0.963  successful    \n10 successful     0.0357 not successful\n# ℹ 18 more rows\n\n\nLet’s evaluate the accuracy.\nWe will create a table known as a confusion matrix:\n\nN &lt;- nrow(cryo_res)\n\nconfusion_mat &lt;- table(cryo_res %&gt;% select(Result_label, pred_result))\nconfusion_mat\n\n                pred_result\nResult_label     not successful successful\n  not successful              8          0\n  successful                  3         17\n\naccuracy &lt;- (confusion_mat %&gt;% diag %&gt;% sum)/N\naccuracy\n\n[1] 0.8928571\n\n\nThe model has “learned” about the relationship between time spend on the procedure and its success. As a result, the company can predict what their success will be for a given time. The company can provide recommendations for the length of time a patient should undergo the procedure, for example, if the produce takes 10 minutes it’s more likely to be unsuccessful. This is a supervised learning method and therefore the company can also evaluate the accuracy of the model’s predictive performance.\nExercise: Try fitting a logistic regression model and a knn model to these data and compare the results."
  },
  {
    "objectID": "8-(un)supervisedLearning.html#supervised-learning---regression",
    "href": "8-(un)supervisedLearning.html#supervised-learning---regression",
    "title": "Supervised and Unsupervised Learning",
    "section": "Supervised Learning - Regression",
    "text": "Supervised Learning - Regression\nUS Department of Health and Human Services, Centers for Disease Control and Prevention collect information on births recorded in the country. We have data which are a random sample of 1,000 births from 2014. Variables of interest include length of pregnancy in weeks (weeks), mother’s age in years (mage), the sex of the baby (sex), smoking status of the mother (habit), and the number of hospital (visits) visits during pregnancy.\n\nbirths14\n\n# A tibble: 794 × 13\n    fage  mage mature     weeks premie visits gained weight lowbirthweight sex  \n   &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt;\n 1    34    34 younger m…    37 full …     14     28   6.96 not low        male \n 2    36    31 younger m…    41 full …     12     41   8.86 not low        fema…\n 3    37    36 mature mom    37 full …     10     28   7.51 not low        fema…\n 4    32    31 younger m…    36 premie     12     48   6.75 not low        fema…\n 5    32    26 younger m…    39 full …     14     45   6.69 not low        fema…\n 6    37    36 mature mom    36 premie     10     20   6.13 not low        fema…\n 7    29    24 younger m…    40 full …     13     65   6.74 not low        male \n 8    30    32 younger m…    39 full …     15     25   8.94 not low        fema…\n 9    29    26 younger m…    39 full …     11     22   9.12 not low        male \n10    30    34 younger m…    42 full …     14     40   8.91 not low        male \n# ℹ 784 more rows\n# ℹ 3 more variables: habit &lt;chr&gt;, marital &lt;chr&gt;, whitemom &lt;chr&gt;\n\n\n\nSplit the data\n\nlibrary(rsample)\n# Fix random numbers by setting the seed \nset.seed(1116)\n# Put 80% of the data into the training set \nbirths_split &lt;- initial_split(births14, prop = 0.80)\n# Create data frames for the two sets:\ntrain_data &lt;- training(births_split)\ntest_data  &lt;- testing(births_split)\n\n\n\nFit the model and “learn” from the training data\nLet’s explore a multiple regression option\n\nlm_model_train &lt;- lm(weight ~ weeks + mage + sex + habit + visits, data = train_data)\n\n\n\nEvaluate the performance on the test data\n\nbirths_res_test &lt;- test_data %&gt;% \n                    select(weight) %&gt;% \n                    mutate(pred_weight = predict(lm_model_train, test_data))\n\nggplot(births_res_test, aes(x = weight, y = pred_weight)) +\n  geom_point() + \n  geom_line(aes(x = weight, y = weight))\n\n\n\n\n\n\n\n\n\n\nSummarise the model accuracy\n\nbirths_res_test %&gt;% \n  summarise(mean_error = mean(weight - pred_weight),\n            mean_abs_error = mean(abs(weight - pred_weight)))\n\n# A tibble: 1 × 2\n  mean_error mean_abs_error\n       &lt;dbl&gt;          &lt;dbl&gt;\n1     -0.145          0.794\n\n\nThe model is trying to “learn” about the relationship between the price of a painting and other painting attributes. If the model does a good job at “learning” then knowing various painting attributes/features can predict what their price will be. This is a supervised learning method because the accuracy of the model’s predictive performance can be evaluated."
  },
  {
    "objectID": "8-(un)supervisedLearning.html#supervised-learning---classification",
    "href": "8-(un)supervisedLearning.html#supervised-learning---classification",
    "title": "Supervised and Unsupervised Learning",
    "section": "Supervised Learning - Classification",
    "text": "Supervised Learning - Classification\nWe saw examples of using logistic regression previously. Let’s consider another example here. The ‘Cryotherapy’ dataset gives the results of a cryotherapy procedure (1 = successful, 0 = unsuccesful). In this case, our outcome of interest is the success category — it is what we want to predict.\n\ncryo_dat\n\n# A tibble: 90 × 6\n     sex   age  Time  Type  Area Result\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1     1    35 12        1   100      0\n 2     1    29  7        1    96      1\n 3     1    50  8        3   132      1\n 4     1    32 11.8      3   750      0\n 5     1    67  9.25     1    42      0\n 6     1    41  8        2    20      1\n 7     1    36 11        1     8      0\n 8     1    59  3.5      3    20      0\n 9     1    20  4.5      1     6      1\n10     2    34 11.2      3   150      0\n# ℹ 80 more rows\n\n\nLet’s look at the relationship the Time spent doing the procedure and the success:\n\nggplot(cryo_dat, aes(x = Time, y = Result)) +\ngeom_point()\n\n\n\n\n\n\n\n\nLet’s split the data\n\nlibrary(rsample)\nset.seed(1116)\ncryo_split &lt;- initial_split(cryo_dat, prop = 0.80)\n\ntrain_data &lt;- training(cryo_split)\ntest_data  &lt;- testing(cryo_split)\n\nLet’s fit a logistic regression model using the Time spent doing the procedure to predict the success:\n\nlogistic_model &lt;- glm(Result ~ Time, family = \"binomial\",  data = train_data)\nlogistic_model\n\n\nCall:  glm(formula = Result ~ Time, family = \"binomial\", data = train_data)\n\nCoefficients:\n(Intercept)         Time  \n     7.5598      -0.8738  \n\nDegrees of Freedom: 71 Total (i.e. Null);  70 Residual\nNull Deviance:      98.42 \nResidual Deviance: 49.57    AIC: 53.57\n\n\nLet’s visualise the results of fitting the logistic regression:\n\nggplot(train_data, aes(x = Time, y = Result))+\n  geom_point() +\n  geom_smooth(method = \"glm\", \n              method.args = list(family = \"binomial\"),\n              se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nLet’s see if the model does a good job at predicting the success:\n\ncryo_res &lt;- test_data %&gt;% \n            select(Result) %&gt;% \n            mutate(pred_p = predict(logistic_model, \n                                    type = \"response\", newdata = test_data)) %&gt;% \n            mutate(pred_result = ifelse(pred_p &gt;=0.5,1,0)) \ncryo_res\n\n# A tibble: 18 × 3\n   Result pred_p pred_result\n    &lt;dbl&gt;  &lt;dbl&gt;       &lt;dbl&gt;\n 1      0 0.0509           0\n 2      1 0.639            1\n 3      0 0.0625           0\n 4      1 0.639            1\n 5      0 0.114            0\n 6      1 0.974            1\n 7      1 0.986            1\n 8      1 0.951            1\n 9      1 0.166            0\n10      0 0.0509           0\n11      0 0.0766           0\n12      1 0.983            1\n13      1 0.986            1\n14      0 0.323            0\n15      0 0.0936           0\n16      1 0.997            1\n17      1 0.114            0\n18      0 0.0509           0\n\n\nLet’s evaluate the accuracy.\nWe will create a table known as a confusion matrix:\n\nN &lt;- nrow(cryo_res)\n\nconfusion_mat &lt;- table(cryo_res %&gt;% select(Result, pred_result))\nconfusion_mat\n\n      pred_result\nResult 0 1\n     0 8 0\n     1 2 8\n\naccuracy &lt;- (confusion_mat %&gt;% diag %&gt;% sum)/N\naccuracy\n\n[1] 0.8888889\n\n\nThe model has “learned” about the relationship between time spend on the procedure and its success. As a result, the company can predict what their success will be for a given time. The company can provide recommendations for the length of time a patient should undergo the procedure, for example, if the produce takes 10 minutes it’s more likely to be unsuccessful. This is a supervised learning method and therefore the company can also evaluate the accuracy of the model’s predictive performance."
  },
  {
    "objectID": "8-(un)supervisedLearning.html#unsupervised-learning",
    "href": "8-(un)supervisedLearning.html#unsupervised-learning",
    "title": "Supervised and Unsupervised Learning",
    "section": "Unsupervised learning",
    "text": "Unsupervised learning\nUnlike supervised learning, unsupervised learning develops insights with unlabeled data. As a result, there is no evaluation of the accuracy of the model.\nAn unsupervised learning algorithm analyzes a set of data, groups data points based on perceived similarities and derives conclusions from these similarities.\n\nTypes of Unsupervised Learning:\nUnlike supervised learning which only had two main types, regression and classification, unsupervised learning has many methodologies and number of methods continues to grow with new discoveries. Below are some of the more common ones:\nClustering: Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters).\nAnomaly Detection: Anomaly detection is the identification of items, events or observations which do not conform to an expected pattern or other items in a dataset.\nNatural Language Processing: Natural Language Processing is a way for computers to analyze, understand, and derive meaning from human language in a smart and useful way. NLP uses machine learning to automatically learn patterns by analyzing a set of examples (collection of articles), and make an inference."
  },
  {
    "objectID": "8-(un)supervisedLearning.html#unsupervised-learning---clustering",
    "href": "8-(un)supervisedLearning.html#unsupervised-learning---clustering",
    "title": "Supervised and Unsupervised Learning",
    "section": "Unsupervised Learning - Clustering",
    "text": "Unsupervised Learning - Clustering\nWe will introduce the concepts behind a popular clustering method called k-means clustering.\nGoal: group the input samples together based on similarity. The distance between the samples in a cluster should be much smaller than the distance between the clusters\n\nExample: Simulated Data\n\nCan you see any possible clusters?\n\n\nK-means clustering\nThe algorithm works by:\n\nAssigning each sample to the closest “cluster centroid”\nMoving each cluster centroid to be the mean of points that are assigned to it\nRepeat.\n\n\nK-means clustering: iteration 0a\nBegin by randomly generating two centroids.\n\n\n\nK-means clustering: iteration 0b\nAssign each point to the nearest centroid\n\n\n\nK-means clustering: iteration 1a\nUpdate the centroids\n\n\n\nK-means clustering: iteration 1b\nAssign each point to the nearest centroid\n\n\n\nK-means clustering: convergence\nRepeat the process until points are no longer moved between groups\n\n\n\nK-means clustering: results\n\n\n\n\nExample: Old Faitful\nThe Old Faithful geyser is in Yellowstone National Park, Wyoming. - The geyser erupts frequently and it is a popular tourist destination.\n\nThe old faithful dataset contains waiting times between eruptions and the duration of the eruption. Can you see an possible clusters in the data?\n\nold_faithful\n\n# A tibble: 99 × 2\n   eruptions waiting\n       &lt;dbl&gt;   &lt;dbl&gt;\n 1      3.6       79\n 2      1.8       54\n 3      3.33      74\n 4      2.28      62\n 5      4.53      85\n 6      2.88      55\n 7      4.7       88\n 8      3.6       85\n 9      1.95      51\n10      4.35      85\n# ℹ 89 more rows\n\n\n\nggplot(old_faithful, aes(x = waiting, y = eruptions)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nLets apply the k-means algorithm:\n\nkmean_res &lt;- kmeans(old_faithful, centers = 2)\n\nold_faithful_res &lt;- old_faithful %&gt;%\n                      mutate(cluster = kmean_res$cluster)\nold_faithful_res\n\n# A tibble: 99 × 3\n   eruptions waiting cluster\n       &lt;dbl&gt;   &lt;dbl&gt;   &lt;int&gt;\n 1      3.6       79       2\n 2      1.8       54       1\n 3      3.33      74       2\n 4      2.28      62       1\n 5      4.53      85       2\n 6      2.88      55       1\n 7      4.7       88       2\n 8      3.6       85       2\n 9      1.95      51       1\n10      4.35      85       2\n# ℹ 89 more rows\n\n\n\n\nLet’s visualise the results:\n\nlibrary(factoextra)\n\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n\nfviz_cluster(kmean_res , data = old_faithful %&gt;% select(waiting, eruptions), \n             geom = \"point\",\n             ylab = \"waiting time (minutes)\",\n             xlab = \"eruption time (minutes)\")\n\n\n\n\n\n\n\n\nalternatively\n\nggplot(old_faithful_res, aes(x = waiting, y = eruptions, colour = as.factor(cluster))) +\n  geom_point() +\n  labs(colour = \"cluster\") +\n  ylab(\"waiting time (minutes)\") +\n  xlab(\"eruption time (minutes)\")\n\n\n\n\n\n\n\n\n\n\nEvaluation Methods\n\nContrary to supervised learning where we have the ground truth to evaluate the model’s performance, clustering analysis doesn’t have a solid evaluation metric that we can use to evaluate the outcome of different clustering algorithms.\nMoreover, since kmeans requires k as an input and doesn’t learn it from data, there is no right answer in terms of the number of clusters that we should have in any problem.\nSometimes domain knowledge and intuition may help but usually that is not the case.\nIn the cluster-predict methodology, we can evaluate how well the models are performing based on different metrics that may give us some intuition about k:\n\nElbow method\nSilhouette analysis\n\n\nElbow method\n\nThe basic idea behind cluster methods, such as k-means clustering, is to define clusters such that the within-cluster variation (known as total within-cluster sum of squares) is minimized.\nThus, we can find the optimal clusters by visualising no. of clusters vs total within-cluster sum of squares\nWe look for the “elbow” in the plot to choose the no. of clusters\n\n\nlibrary(factoextra)\nfviz_nbclust(old_faithful, kmeans, method = \"wss\")\n\n\n\n\n\n\n\n\nSilhouette method\n\nThe silhouette approach measures the “quality” of a clustering, i.e., it determines how well each object lies within its cluster.\nThe silhouette value is a measure of how similar an object is to its own cluster (cohesion) compared to other clusters (separation).\nThe silhouette ranges from -1 to +1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters\nThe average silhouette method computes the average silhouette of observations for different values of k.\nThe optimal number of clusters k is the one that maximizes the average silhouette over a range of possible values for k.\n\n\nlibrary(factoextra)\nfviz_nbclust(old_faithful, kmeans, method = \"silhouette\")\n\n\n\n\n\n\n\n\n\nWe can also look at a silhouette plot that shows values for each data point in the cluster\n\n\n# Load required libraries\nlibrary(cluster)\n\n# Compute silhouette information\nsil &lt;- silhouette(kmean_res$cluster, dist(old_faithful))\n# Plot silhouette\nfviz_silhouette(sil) \n\n  cluster size ave.sil.width\n1       1   37          0.69\n2       2   62          0.72\n\n\n\n\n\n\n\n\n\n\n\n\nCustomer Segmentation\nWe will use a synthetic dataset resembling customer spending behavior. This dataset includes features commonly used in marketing and customer analytics: age, income, spending score, and online activity.\n\ncustomer_data &lt;- readRDS(\"customer_data.rds\")\n\n\nWhy Use K-Means for Customer Segmentation?\nCustomer segmentation helps businesses identify distinct customer groups based on behavior, spending patterns, or demographics. This allows for targeted marketing and personalized services."
  },
  {
    "objectID": "Assigment4.html",
    "href": "Assigment4.html",
    "title": "DS152 Introduction to Data Science (2)",
    "section": "",
    "text": "Answer all questions for continuous assessment. Due: 4pm on Friday, 4th April 2025."
  },
  {
    "objectID": "Assigment4.html#instructions",
    "href": "Assigment4.html#instructions",
    "title": "DS152 Introduction to Data Science (2)",
    "section": "",
    "text": "Answer all questions for continuous assessment. Due: 4pm on Friday, 4th April 2025."
  },
  {
    "objectID": "Assigment4.html#questions",
    "href": "Assigment4.html#questions",
    "title": "DS152 Introduction to Data Science (2)",
    "section": "Questions",
    "text": "Questions\n1. We would like to design an experiment to investigate whether students learn the R language better in a traditional lecture based course or using an interactive online learning platform. Two courses that teach the exact same material are designed and the only difference between these courses is the method of delivery: traditional lecture or interactive online.\n\nWe sample a group of students for our study that we will randomly assign to these two courses.\nBut before we do so, we need to consider any potential confounding variables. It is suspected that previous programming experience might have an effect on how students learn in these two settings and we know that some of the students in our study have previous programming experience and some don’t. Therefore we decide to account for having previous programming experience. To do so, we divide our sample into two, those with programming experience and those without. Then, we randomly assign individuals from each group into the two courses, ensuring that those with and without programming experience are equally represented in the two courses.\n\na. What is the “treatment” variable and what are its levels?\nb. Is there a blocking variable, if so, what it is?\n\n2. A researcher designs a study to test the effect of light and noise levels on exam performance of students. The researcher also believes that light and noise levels might have different effects on males and females, so she wants to make sure both sexes are represented equally under different conditions.\n\na. What are the “treatment” variables in this study?\nb. What is the outcome variable?\nc. Is there a blocking variable, if so, what it is?\n\n3. Complete the sentence below using i, ii, iii or iv.\nIn random sampling, we use ___ to control for a variable. In random assignment for an experiment, we use ___ to achieve the same goal.\ni. stratifying, blocking\nii. blocking, stratifying\niii confounding, stratifying\niv. confounding, blocking\n\n4. A researcher is interested in studying the effects of a new iron supplement in female patients with anemia. Their plans are to select 40 female patients with a similar age and level of anemia from a GP clinic and give an approved iron supplement to a randomly selected subsample of 20, and the newly developed supplement to the other 20 patients. The researcher plans to use blood tests to calculate the difference in iron levels before they start taking the supplements and three months after.\n\na. What is the outcome variable?\nb. What is the treatment and how many levels are there?\nc. Is there a blocking variable, if so, what it is?\n\n5. The results from the experiment in 4 were inconclusive. Therefore, the researcher decided to set up a bigger experiment with the hope to add more precision to their estimates. They now select 40 female patients, each from 5 different GP clinics (totalling 200 patients). Within each GP clinic, the set up is the same as before, 20 patients take an approved iron supplement and 20 the newly developed one, and have their iron levels checked before and three months after taking the supplements. What study design do you think would be appropriate to use here? Give a reason for your answer."
  },
  {
    "objectID": "Assignment4_soln.html#questions",
    "href": "Assignment4_soln.html#questions",
    "title": "DS152 Introduction to Data Science (2)",
    "section": "Questions",
    "text": "Questions\n1. [4 Marks]\na. The taught corse is the treatment, with 2 levels, traditional lecture and online lecture.\nb. Yes, programming experience is being used as a blocking variable.\n\n2. [6 Marks]\na. The treatments are light and noise levels.\nb. The outcome is exam performance.\nc. Yes, gender, Male and Female.\n3. Complete the sentence below using i, ii, iii or iv. [2 Marks]\nIn random sampling, we use blocking to control for a variable. In random assignment for an experiment, we use stratifying to achieve the same goal.\nii. blocking, stratifying\n4. [5 Marks]\na. The outcome variable is the difference in iron levels\nb. The treatment is the iron supplement, there are 2 levels, approved and newly developed.\nc. No blocking.\n5. [3 Marks]\nA completely randomised block design would be appropriate. The GP clinic would be the blocking variable."
  },
  {
    "objectID": "Assignment5.html",
    "href": "Assignment5.html",
    "title": "DS152 Introduction to Data Science (2)",
    "section": "",
    "text": "Answer all questions for continuous assessment. Due: 4pm on Friday, 11th April 2025."
  },
  {
    "objectID": "Assignment5.html#instructions",
    "href": "Assignment5.html#instructions",
    "title": "DS152 Introduction to Data Science (2)",
    "section": "",
    "text": "Answer all questions for continuous assessment. Due: 4pm on Friday, 11th April 2025."
  },
  {
    "objectID": "Assignment5.html#background",
    "href": "Assignment5.html#background",
    "title": "DS152 Introduction to Data Science (2)",
    "section": "Background",
    "text": "Background\nThe Boston dataset contains housing values in the suburbs of Boston. It is a well known dataset used as an example for machine learning techniques. Usually the objective is to predict the median value of owner-occupied homes in thousands of dollars (medv in the dataset). There are 13 predictors, see below for a glimpse of the dataset.\n\nBoston &lt;- MASS::Boston\nglimpse(Boston)\n\nRows: 506\nColumns: 14\n$ crim    &lt;dbl&gt; 0.00632, 0.02731, 0.02729, 0.03237, 0.06905, 0.02985, 0.08829,…\n$ zn      &lt;dbl&gt; 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.5, 12.5, 12.5, 12.5, 12.5, 1…\n$ indus   &lt;dbl&gt; 2.31, 7.07, 7.07, 2.18, 2.18, 2.18, 7.87, 7.87, 7.87, 7.87, 7.…\n$ chas    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ nox     &lt;dbl&gt; 0.538, 0.469, 0.469, 0.458, 0.458, 0.458, 0.524, 0.524, 0.524,…\n$ rm      &lt;dbl&gt; 6.575, 6.421, 7.185, 6.998, 7.147, 6.430, 6.012, 6.172, 5.631,…\n$ age     &lt;dbl&gt; 65.2, 78.9, 61.1, 45.8, 54.2, 58.7, 66.6, 96.1, 100.0, 85.9, 9…\n$ dis     &lt;dbl&gt; 4.0900, 4.9671, 4.9671, 6.0622, 6.0622, 6.0622, 5.5605, 5.9505…\n$ rad     &lt;int&gt; 1, 2, 2, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,…\n$ tax     &lt;dbl&gt; 296, 242, 242, 222, 222, 222, 311, 311, 311, 311, 311, 311, 31…\n$ ptratio &lt;dbl&gt; 15.3, 17.8, 17.8, 18.7, 18.7, 18.7, 15.2, 15.2, 15.2, 15.2, 15…\n$ black   &lt;dbl&gt; 396.90, 396.90, 392.83, 394.63, 396.90, 394.12, 395.60, 396.90…\n$ lstat   &lt;dbl&gt; 4.98, 9.14, 4.03, 2.94, 5.33, 5.21, 12.43, 19.15, 29.93, 17.10…\n$ medv    &lt;dbl&gt; 24.0, 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15…\n\n\nWe will split the data into training (boston_train) and test (boston_test) sets, with 70% of the observations in the training set and we will fit the following 2 models:\n\nModel 1: multiple linear regression model with predictors: rm (average number of rooms per dwelling), ptratio (pupil-teacher ratio), lstat (lower status of the population %), rad (index of accessibility to radial highways), crim (per capita crime rate by town);\nModel 2: regression tree with the same predictors as Model 1."
  },
  {
    "objectID": "Assignment5.html#questions",
    "href": "Assignment5.html#questions",
    "title": "DS152 Introduction to Data Science (2)",
    "section": "Questions",
    "text": "Questions\n(a) Replace [A], [B] and [C] in the code below which uses functions from the rsample package to create the training and test datasets.\n\nlibrary(rsample)\nboston_split &lt;- initial_split(Boston, prop = [A])\n\nboston_train &lt;- [B](boston_split)\nboston_test  &lt;- [C](boston_split)\n\n[A] =\n[B] =\n[C] =\n(b) What are the dimensions (rows \\(\\times\\) columns) of the boston_train and boston_test datasets?\n(c) Replace [A] and [B] in the code below to fit the models.\n\nfit_model1 &lt;- [A](medv ~ rm + ptratio + lstat + rad + crim, data = boston_train)\nfit_model2 &lt;- [B]rpart(medv ~ rm + ptratio + lstat + rad + crim, data = boston_train)\n\n[A] =\n[B] =\n(d) Below is the output from Model 1 and Model 2. Based on each model, what is the predicted medv for a house with lstat = 10, rm = 7.5, ptratio = 18.5, crim = 4, rad = 5?\n\nModel 1\n\n\n\nCall:\nlm(formula = medv ~ rm + ptratio + lstat + rad + crim, data = boston_train)\n\nCoefficients:\n(Intercept)           rm      ptratio        lstat          rad         crim  \n   14.36556      4.88290     -0.86080     -0.54104      0.02868     -0.11700  \n\n\n\n\nModel 2\n\n\n\n\n\n\n\n\n\n(e) After fitting the models, we create plots of the observed vs predicted values for each model, based on the test data. The identity line is overlayed on the plots.\n\n\n\n\n\n\n\n\n\nBased on the observed vs predicted plots, do the models tend to over predict or under predict when medv = 50. Give a reason for your answer.\n(f) We obtained the mean error (ME) and the mean absolute error (MAE) for each model based on the test data. Below you can see a table containing these measurements, but the model is not identified. Assumming that that Model 2 is the best model, which row (X or Y) corresponds to Model 2? Give a reason for your answer.\n\n\n        ME      MAE\nX 1.202534 3.971460\nY 0.457539 3.585161"
  },
  {
    "objectID": "Assignment4.html",
    "href": "Assignment4.html",
    "title": "DS152 Introduction to Data Science (2)",
    "section": "",
    "text": "Answer all questions for continuous assessment. Due: 4pm on Friday, 4th April 2025."
  },
  {
    "objectID": "Assignment4.html#instructions",
    "href": "Assignment4.html#instructions",
    "title": "DS152 Introduction to Data Science (2)",
    "section": "",
    "text": "Answer all questions for continuous assessment. Due: 4pm on Friday, 4th April 2025."
  },
  {
    "objectID": "Assignment4.html#questions",
    "href": "Assignment4.html#questions",
    "title": "DS152 Introduction to Data Science (2)",
    "section": "Questions",
    "text": "Questions\n1. We would like to design an experiment to investigate whether students learn the R language better in a traditional lecture based course or using an interactive online learning platform. Two courses that teach the exact same material are designed and the only difference between these courses is the method of delivery: traditional lecture or interactive online.\n\nWe sample a group of students for our study that we will randomly assign to these two courses.\nBut before we do so, we need to consider any potential confounding variables. It is suspected that previous programming experience might have an effect on how students learn in these two settings and we know that some of the students in our study have previous programming experience and some don’t. Therefore we decide to account for having previous programming experience. To do so, we divide our sample into two, those with programming experience and those without. Then, we randomly assign individuals from each group into the two courses, ensuring that those with and without programming experience are equally represented in the two courses.\n\na. What is the “treatment” variable and what are its levels?\nb. Is there a blocking variable, if so, what it is?\n\n2. A researcher designs a study to test the effect of light and noise levels on exam performance of students. The researcher also believes that light and noise levels might have different effects on males and females, so she wants to make sure both sexes are represented equally under different conditions.\n\na. What are the “treatment” variables in this study?\nb. What is the outcome variable?\nc. Is there a blocking variable, if so, what it is?\n\n3. Complete the sentence below using i, ii, iii or iv.\nIn random sampling, we use ___ to control for a variable. In random assignment for an experiment, we use ___ to achieve the same goal.\ni. stratifying, blocking\nii. blocking, stratifying\niii confounding, stratifying\niv. confounding, blocking\n\n4. A researcher is interested in studying the effects of a new iron supplement in female patients with anemia. Their plans are to select 40 female patients with a similar age and level of anemia from a GP clinic and give an approved iron supplement to a randomly selected subsample of 20, and the newly developed supplement to the other 20 patients. The researcher plans to use blood tests to calculate the difference in iron levels before they start taking the supplements and three months after.\n\na. What is the outcome variable?\nb. What is the treatment and how many levels are there?\nc. Is there a blocking variable, if so, what it is?\n\n5. The results from the experiment in 4 were inconclusive. Therefore, the researcher decided to set up a bigger experiment with the hope to add more precision to their estimates. They now select 40 female patients, each from 5 different GP clinics (totalling 200 patients). Within each GP clinic, the set up is the same as before, 20 patients take an approved iron supplement and 20 the newly developed one, and have their iron levels checked before and three months after taking the supplements. What study design do you think would be appropriate to use here? Give a reason for your answer."
  },
  {
    "objectID": "Tutorial6_soln.html",
    "href": "Tutorial6_soln.html",
    "title": "DS152 Tutorial Sheet 5",
    "section": "",
    "text": "We will work with the biopsy data (you’ve worked with this dataset before). It is a breast cancer database obtained from the University of Wisconsin-Madison Hospital. 699 biopsies of breast tumours were assessed and nine attributes (V1 - V9) were scored on a scale of 1 to 10. The objective is to predict whether a tumour is benign (0) or malignant (1), based on 5 of the attributes.\nBelow we have a glimpse of the dataset.\n\nbiopsy &lt;- MASS::biopsy\nglimpse(biopsy)\n\nRows: 699\nColumns: 11\n$ ID    &lt;chr&gt; \"1000025\", \"1002945\", \"1015425\", \"1016277\", \"1017023\", \"1017122\"…\n$ V1    &lt;int&gt; 5, 5, 3, 6, 4, 8, 1, 2, 2, 4, 1, 2, 5, 1, 8, 7, 4, 4, 10, 6, 7, …\n$ V2    &lt;int&gt; 1, 4, 1, 8, 1, 10, 1, 1, 1, 2, 1, 1, 3, 1, 7, 4, 1, 1, 7, 1, 3, …\n$ V3    &lt;int&gt; 1, 4, 1, 8, 1, 10, 1, 2, 1, 1, 1, 1, 3, 1, 5, 6, 1, 1, 7, 1, 2, …\n$ V4    &lt;int&gt; 1, 5, 1, 1, 3, 8, 1, 1, 1, 1, 1, 1, 3, 1, 10, 4, 1, 1, 6, 1, 10,…\n$ V5    &lt;int&gt; 2, 7, 2, 3, 2, 7, 2, 2, 2, 2, 1, 2, 2, 2, 7, 6, 2, 2, 4, 2, 5, 6…\n$ V6    &lt;int&gt; 1, 10, 2, 4, 1, 10, 10, 1, 1, 1, 1, 1, 3, 3, 9, 1, 1, 1, 10, 1, …\n$ V7    &lt;int&gt; 3, 3, 3, 3, 3, 9, 3, 3, 1, 2, 3, 2, 4, 3, 5, 4, 2, 3, 4, 3, 5, 7…\n$ V8    &lt;int&gt; 1, 2, 1, 7, 1, 7, 1, 1, 1, 1, 1, 1, 4, 1, 5, 3, 1, 1, 1, 1, 4, 1…\n$ V9    &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 4, 1, 1, 1, 2, 1, 4, 1…\n$ class &lt;fct&gt; benign, benign, benign, benign, benign, malignant, benign, benig…\n\n\nWe’re going to update the dataset to add a binary (0,1) version of the class variable.\n\nbiopsy &lt;- biopsy %&gt;% mutate(class_binary = as.numeric(class == \"malignant\"))\n\n(a) Before we begin modelling the data, let’s split the dataset in two: the training and the test set. We will fit the models using the training set, and then validate them using the test set. We will use 60% of the data as the training set, and the remaining 40% as the test set. Set the seed to 103 and replace [A], [B], [C] and [D] in the code below to create these training and test datasets.\n\nlibrary(rsample)\nlibrary(rpart)\nset.seed(103)\nbiopsy_split &lt;- initial_split(biopsy, prop = 0.6)\ntrain_biopsy_data &lt;- training(biopsy_split)\ntest_biopsy_data  &lt;- testing(biopsy_split)\n\n(b) We will use 2 different machine learning algorithms, namely:\n\nMethod 1: multiple logistic regression\nMethod 2: classification tree\n\nWe will fit them to the training set and then we will compare how well they perform on the test set.\nReplace [A] and [B] in the code below to fit a logistic regression model to the training data using all variables (V1 to V5) as predictors and class_binary as the outcome/response. Call the fitted model object logistic_model.\n\nlogistic_model  &lt;- glm(class_binary ~ V1 + V2 + V3 + V4 + V5, family = binomial, data = train_biopsy_data)\n\n(c) Now replace [A], [B] and [C] in the code below to fit a classification tree and call it tree_model and plot the classification tree.\n\nlibrary(rpart)\nlibrary(rpart.plot)\n\ntree_model &lt;- rpart(class_binary ~ V1 + V2 + V3 + V4 + V5,data = train_biopsy_data)\nrpart.plot(tree_model)\n\n\n\n\n\n\n\n\n(d) Now we will use the test set to evaluate the two different methods. Below are the confusion tables for each method, using the test set.\n\n\n\n\n           pred_class1\nclass       benign malignant\n  benign       188         6\n  malignant      6        80\n\n\n\n\n\n\n\n           pred_class2\nclass       benign malignant\n  benign       180        14\n  malignant      4        82\n\n\nCalculate the overall accuracy, true positive rate and true negative rate for each method you trained. We take positive to be malignant, and negative to be benign.\n\n\n\n\n## accuracy \nsum(diag(confusion_logistic))/(sum(confusion_logistic))\n\n[1] 0.9571429\n\n## TPR TP/(TP + FN)\nconfusion_logistic[2,2]/(sum(confusion_logistic[2,]))\n\n[1] 0.9302326\n\n## TNR TN/(TN + FP)\nconfusion_logistic[1,1]/(sum(confusion_logistic[1,]))\n\n[1] 0.9690722\n\n\n\n\n\n\n## accuracy \nsum(diag(confusion_tree))/(sum(confusion_tree))\n\n[1] 0.9357143\n\n## TPR TP/(TP + FN)\nconfusion_tree[2,2]/(sum(confusion_tree[2,]))\n\n[1] 0.9534884\n\n## TNR TN/(TN + FP)\nconfusion_tree[1,1]/(sum(confusion_tree[1,]))\n\n[1] 0.9278351\n\n\nNote for tutors: You don’t need to co through all the code for creating the predictions etc here just focus on how to do the calculations from the confusion tables.\n\nNow we will use the k-nearest neighbours algorithm on the biopsy data. We will use k = 3 and k = 6 and compare results. The code below fits the models and gives predictions.\n\n\nlibrary(class)\npred_class_knn3 &lt;- knn(train_biopsy_data %&gt;% select(V1:V5), \n                     test_biopsy_data %&gt;% select(V1:V5), \n                     cl =   train_biopsy_data %&gt;% pull(class), \n                     k = 3)\n\npred_class_knn6 &lt;- knn(train_biopsy_data %&gt;% select(V1:V5), \n                     test_biopsy_data %&gt;% select(V1:V5), \n                     cl =   train_biopsy_data %&gt;% pull(class), \n                     k = 6)\n\n\nbiopsy_res_knn &lt;- test_biopsy_data %&gt;%\n                  mutate(pred_class3 = pred_class_knn3) %&gt;% \n                  mutate(pred_class6 = pred_class_knn6)\n\nNow we can have a look at the confusion tables:\n\nN &lt;- nrow(biopsy_res_knn)\n\nconfusion_mat3 &lt;- table(biopsy_res_knn  %&gt;% select(class, pred_class3))\nconfusion_mat3\n\n           pred_class3\nclass       benign malignant\n  benign       187         7\n  malignant      4        82\n\nconfusion_mat6 &lt;- table(biopsy_res_knn  %&gt;% select(class, pred_class6))\nconfusion_mat6\n\n           pred_class6\nclass       benign malignant\n  benign       186         8\n  malignant      5        81\n\n\nNote for tutors: Talk through the code here for part (e) as knn is a little different to the other methods in how the code is formatted.\nThen calculate the overall accuracy, true positive rate and true negative rate for each method you trained. We take positive to be malignant, and negative to be benign.\n\n\n\n\n## accuracy \nsum(diag(confusion_mat3))/(sum(confusion_mat3))\n\n[1] 0.9607143\n\n## TPR TP/(TP + FN)\nconfusion_mat3[2,2]/(sum(confusion_mat3[2,]))\n\n[1] 0.9534884\n\n## TNR TN/(TN + FP)\nconfusion_mat3[1,1]/(sum(confusion_mat3[1,]))\n\n[1] 0.9639175\n\n\n\n\n\n\n## accuracy \nsum(diag(confusion_mat6))/(sum(confusion_mat6))\n\n[1] 0.9535714\n\n## TPR TP/(TP + FN)\nconfusion_mat6[2,2]/(sum(confusion_mat6[2,]))\n\n[1] 0.9418605\n\n## TNR TN/(TN + FP)\nconfusion_mat6[1,1]/(sum(confusion_mat6[1,]))\n\n[1] 0.9587629"
  },
  {
    "objectID": "Tutorial6_soln.html#exercise",
    "href": "Tutorial6_soln.html#exercise",
    "title": "DS152 Tutorial Sheet 5",
    "section": "",
    "text": "We will work with the biopsy data (you’ve worked with this dataset before). It is a breast cancer database obtained from the University of Wisconsin-Madison Hospital. 699 biopsies of breast tumours were assessed and nine attributes (V1 - V9) were scored on a scale of 1 to 10. The objective is to predict whether a tumour is benign (0) or malignant (1), based on 5 of the attributes.\nBelow we have a glimpse of the dataset.\n\nbiopsy &lt;- MASS::biopsy\nglimpse(biopsy)\n\nRows: 699\nColumns: 11\n$ ID    &lt;chr&gt; \"1000025\", \"1002945\", \"1015425\", \"1016277\", \"1017023\", \"1017122\"…\n$ V1    &lt;int&gt; 5, 5, 3, 6, 4, 8, 1, 2, 2, 4, 1, 2, 5, 1, 8, 7, 4, 4, 10, 6, 7, …\n$ V2    &lt;int&gt; 1, 4, 1, 8, 1, 10, 1, 1, 1, 2, 1, 1, 3, 1, 7, 4, 1, 1, 7, 1, 3, …\n$ V3    &lt;int&gt; 1, 4, 1, 8, 1, 10, 1, 2, 1, 1, 1, 1, 3, 1, 5, 6, 1, 1, 7, 1, 2, …\n$ V4    &lt;int&gt; 1, 5, 1, 1, 3, 8, 1, 1, 1, 1, 1, 1, 3, 1, 10, 4, 1, 1, 6, 1, 10,…\n$ V5    &lt;int&gt; 2, 7, 2, 3, 2, 7, 2, 2, 2, 2, 1, 2, 2, 2, 7, 6, 2, 2, 4, 2, 5, 6…\n$ V6    &lt;int&gt; 1, 10, 2, 4, 1, 10, 10, 1, 1, 1, 1, 1, 3, 3, 9, 1, 1, 1, 10, 1, …\n$ V7    &lt;int&gt; 3, 3, 3, 3, 3, 9, 3, 3, 1, 2, 3, 2, 4, 3, 5, 4, 2, 3, 4, 3, 5, 7…\n$ V8    &lt;int&gt; 1, 2, 1, 7, 1, 7, 1, 1, 1, 1, 1, 1, 4, 1, 5, 3, 1, 1, 1, 1, 4, 1…\n$ V9    &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 4, 1, 1, 1, 2, 1, 4, 1…\n$ class &lt;fct&gt; benign, benign, benign, benign, benign, malignant, benign, benig…\n\n\nWe’re going to update the dataset to add a binary (0,1) version of the class variable.\n\nbiopsy &lt;- biopsy %&gt;% mutate(class_binary = as.numeric(class == \"malignant\"))\n\n(a) Before we begin modelling the data, let’s split the dataset in two: the training and the test set. We will fit the models using the training set, and then validate them using the test set. We will use 60% of the data as the training set, and the remaining 40% as the test set. Set the seed to 103 and replace [A], [B], [C] and [D] in the code below to create these training and test datasets.\n\nlibrary(rsample)\nlibrary(rpart)\nset.seed(103)\nbiopsy_split &lt;- initial_split(biopsy, prop = 0.6)\ntrain_biopsy_data &lt;- training(biopsy_split)\ntest_biopsy_data  &lt;- testing(biopsy_split)\n\n(b) We will use 2 different machine learning algorithms, namely:\n\nMethod 1: multiple logistic regression\nMethod 2: classification tree\n\nWe will fit them to the training set and then we will compare how well they perform on the test set.\nReplace [A] and [B] in the code below to fit a logistic regression model to the training data using all variables (V1 to V5) as predictors and class_binary as the outcome/response. Call the fitted model object logistic_model.\n\nlogistic_model  &lt;- glm(class_binary ~ V1 + V2 + V3 + V4 + V5, family = binomial, data = train_biopsy_data)\n\n(c) Now replace [A], [B] and [C] in the code below to fit a classification tree and call it tree_model and plot the classification tree.\n\nlibrary(rpart)\nlibrary(rpart.plot)\n\ntree_model &lt;- rpart(class_binary ~ V1 + V2 + V3 + V4 + V5,data = train_biopsy_data)\nrpart.plot(tree_model)\n\n\n\n\n\n\n\n\n(d) Now we will use the test set to evaluate the two different methods. Below are the confusion tables for each method, using the test set.\n\n\n\n\n           pred_class1\nclass       benign malignant\n  benign       188         6\n  malignant      6        80\n\n\n\n\n\n\n\n           pred_class2\nclass       benign malignant\n  benign       180        14\n  malignant      4        82\n\n\nCalculate the overall accuracy, true positive rate and true negative rate for each method you trained. We take positive to be malignant, and negative to be benign.\n\n\n\n\n## accuracy \nsum(diag(confusion_logistic))/(sum(confusion_logistic))\n\n[1] 0.9571429\n\n## TPR TP/(TP + FN)\nconfusion_logistic[2,2]/(sum(confusion_logistic[2,]))\n\n[1] 0.9302326\n\n## TNR TN/(TN + FP)\nconfusion_logistic[1,1]/(sum(confusion_logistic[1,]))\n\n[1] 0.9690722\n\n\n\n\n\n\n## accuracy \nsum(diag(confusion_tree))/(sum(confusion_tree))\n\n[1] 0.9357143\n\n## TPR TP/(TP + FN)\nconfusion_tree[2,2]/(sum(confusion_tree[2,]))\n\n[1] 0.9534884\n\n## TNR TN/(TN + FP)\nconfusion_tree[1,1]/(sum(confusion_tree[1,]))\n\n[1] 0.9278351\n\n\nNote for tutors: You don’t need to co through all the code for creating the predictions etc here just focus on how to do the calculations from the confusion tables.\n\nNow we will use the k-nearest neighbours algorithm on the biopsy data. We will use k = 3 and k = 6 and compare results. The code below fits the models and gives predictions.\n\n\nlibrary(class)\npred_class_knn3 &lt;- knn(train_biopsy_data %&gt;% select(V1:V5), \n                     test_biopsy_data %&gt;% select(V1:V5), \n                     cl =   train_biopsy_data %&gt;% pull(class), \n                     k = 3)\n\npred_class_knn6 &lt;- knn(train_biopsy_data %&gt;% select(V1:V5), \n                     test_biopsy_data %&gt;% select(V1:V5), \n                     cl =   train_biopsy_data %&gt;% pull(class), \n                     k = 6)\n\n\nbiopsy_res_knn &lt;- test_biopsy_data %&gt;%\n                  mutate(pred_class3 = pred_class_knn3) %&gt;% \n                  mutate(pred_class6 = pred_class_knn6)\n\nNow we can have a look at the confusion tables:\n\nN &lt;- nrow(biopsy_res_knn)\n\nconfusion_mat3 &lt;- table(biopsy_res_knn  %&gt;% select(class, pred_class3))\nconfusion_mat3\n\n           pred_class3\nclass       benign malignant\n  benign       187         7\n  malignant      4        82\n\nconfusion_mat6 &lt;- table(biopsy_res_knn  %&gt;% select(class, pred_class6))\nconfusion_mat6\n\n           pred_class6\nclass       benign malignant\n  benign       186         8\n  malignant      5        81\n\n\nNote for tutors: Talk through the code here for part (e) as knn is a little different to the other methods in how the code is formatted.\nThen calculate the overall accuracy, true positive rate and true negative rate for each method you trained. We take positive to be malignant, and negative to be benign.\n\n\n\n\n## accuracy \nsum(diag(confusion_mat3))/(sum(confusion_mat3))\n\n[1] 0.9607143\n\n## TPR TP/(TP + FN)\nconfusion_mat3[2,2]/(sum(confusion_mat3[2,]))\n\n[1] 0.9534884\n\n## TNR TN/(TN + FP)\nconfusion_mat3[1,1]/(sum(confusion_mat3[1,]))\n\n[1] 0.9639175\n\n\n\n\n\n\n## accuracy \nsum(diag(confusion_mat6))/(sum(confusion_mat6))\n\n[1] 0.9535714\n\n## TPR TP/(TP + FN)\nconfusion_mat6[2,2]/(sum(confusion_mat6[2,]))\n\n[1] 0.9418605\n\n## TNR TN/(TN + FP)\nconfusion_mat6[1,1]/(sum(confusion_mat6[1,]))\n\n[1] 0.9587629"
  },
  {
    "objectID": "Tutorial6_soln.html#exercise-1",
    "href": "Tutorial6_soln.html#exercise-1",
    "title": "DS152 Tutorial Sheet 6",
    "section": "",
    "text": "We will work with the biopsy data (you’ve worked with this dataset before). It is a breast cancer database obtained from the University of Wisconsin-Madison Hospital. 699 biopsies of breast tumours were assessed and nine attributes (V1 - V9) were scored on a scale of 1 to 10. The objective is to predict whether a tumour is benign (0) or malignant (1), based on 5 of the attributes.\nBelow we have a glimpse of the dataset.\n\nbiopsy &lt;- MASS::biopsy\nglimpse(biopsy)\n\nRows: 699\nColumns: 11\n$ ID    &lt;chr&gt; \"1000025\", \"1002945\", \"1015425\", \"1016277\", \"1017023\", \"1017122\"…\n$ V1    &lt;int&gt; 5, 5, 3, 6, 4, 8, 1, 2, 2, 4, 1, 2, 5, 1, 8, 7, 4, 4, 10, 6, 7, …\n$ V2    &lt;int&gt; 1, 4, 1, 8, 1, 10, 1, 1, 1, 2, 1, 1, 3, 1, 7, 4, 1, 1, 7, 1, 3, …\n$ V3    &lt;int&gt; 1, 4, 1, 8, 1, 10, 1, 2, 1, 1, 1, 1, 3, 1, 5, 6, 1, 1, 7, 1, 2, …\n$ V4    &lt;int&gt; 1, 5, 1, 1, 3, 8, 1, 1, 1, 1, 1, 1, 3, 1, 10, 4, 1, 1, 6, 1, 10,…\n$ V5    &lt;int&gt; 2, 7, 2, 3, 2, 7, 2, 2, 2, 2, 1, 2, 2, 2, 7, 6, 2, 2, 4, 2, 5, 6…\n$ V6    &lt;int&gt; 1, 10, 2, 4, 1, 10, 10, 1, 1, 1, 1, 1, 3, 3, 9, 1, 1, 1, 10, 1, …\n$ V7    &lt;int&gt; 3, 3, 3, 3, 3, 9, 3, 3, 1, 2, 3, 2, 4, 3, 5, 4, 2, 3, 4, 3, 5, 7…\n$ V8    &lt;int&gt; 1, 2, 1, 7, 1, 7, 1, 1, 1, 1, 1, 1, 4, 1, 5, 3, 1, 1, 1, 1, 4, 1…\n$ V9    &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 4, 1, 1, 1, 2, 1, 4, 1…\n$ class &lt;fct&gt; benign, benign, benign, benign, benign, malignant, benign, benig…\n\n\nWe’re going to update the dataset to add a binary (0,1) version of the class variable.\n\nbiopsy &lt;- biopsy %&gt;% mutate(class_binary = as.numeric(class == \"malignant\"))\n\n\nBefore we begin modelling the data, let’s split the dataset in two: the training and the test set. We will fit the models using the training set, and then validate them using the test set. We will use 60% of the data as the training set, and the remaining 40% as the test set. Set the seed to 103 and replace [A], [B], [C] and [D] in the code below to create these training and test datasets.\n\n\nlibrary(rsample)\nlibrary(rpart)\nset.seed(103)\nbiopsy_split &lt;- initial_split(biopsy, prop = 0.6)\ntrain_biopsy_data &lt;- training(biopsy_split)\ntest_biopsy_data  &lt;- testing(biopsy_split)\n\n\nWe will use 2 different machine learning algorithms, namely:\n\n\nMethod 1: multiple logistic regression\nMethod 2: classification tree\n\nWe will fit them to the training set and then we will compare how well they perform on the test set.\nReplace [A] and [B] in the code below to fit a logistic regression model to the training data using all variables (V1 to V5) as predictors and class_binary as the outcome/response. Call the fitted model object logistic_model.\n\nlogistic_model  &lt;- glm(class_binary ~ V1 + V2 + V3 + V4 + V5, family = binomial, data = train_biopsy_data)\n\n\nNow replace [A], [B] and [C] in the code below to fit a classification tree and call it tree_model and plot the classification tree.\n\n\nlibrary(rpart)\nlibrary(rpart.plot)\n\ntree_model &lt;- rpart(class_binary ~ V1 + V2 + V3 + V4 + V5,data = train_biopsy_data)\nrpart.plot(tree_model)\n\n\n\n\n\n\n\n\n\nNow we will use the test set to evaluate the two different methods. Below are the confusion tables for each method, using the test set.\n\n\n\n\n\n           pred_class1\nclass       benign malignant\n  benign       188         6\n  malignant      6        80\n\n\n\n\n\n\n\n           pred_class2\nclass       benign malignant\n  benign       180        14\n  malignant      4        82\n\n\nCalculate the overall accuracy, true positive rate and true negative rate for each method you trained. We take positive to be malignant, and negative to be benign.\n\n\n\n\n## accuracy \nsum(diag(confusion_logistic))/(sum(confusion_logistic))\n\n[1] 0.9571429\n\n## TPR TP/(TP + FN)\nconfusion_logistic[2,2]/(sum(confusion_logistic[2,]))\n\n[1] 0.9302326\n\n## TNR TN/(TN + FP)\nconfusion_logistic[1,1]/(sum(confusion_logistic[1,]))\n\n[1] 0.9690722\n\n\n\n\n\n\n## accuracy \nsum(diag(confusion_tree))/(sum(confusion_tree))\n\n[1] 0.9357143\n\n## TPR TP/(TP + FN)\nconfusion_tree[2,2]/(sum(confusion_tree[2,]))\n\n[1] 0.9534884\n\n## TNR TN/(TN + FP)\nconfusion_tree[1,1]/(sum(confusion_tree[1,]))\n\n[1] 0.9278351\n\n\n\nNow we will use the k-nearest neighbours algorithm on the biopsy data. We will use k = 3 and k = 6 and compare results. The code below fits the models and gives predictions.\n\n\nlibrary(class)\npred_class_knn3 &lt;- knn(train_biopsy_data %&gt;% select(V1:V5), \n                     test_biopsy_data %&gt;% select(V1:V5), \n                     cl =   train_biopsy_data %&gt;% pull(class), \n                     k = 3)\n\npred_class_knn6 &lt;- knn(train_biopsy_data %&gt;% select(V1:V5), \n                     test_biopsy_data %&gt;% select(V1:V5), \n                     cl =   train_biopsy_data %&gt;% pull(class), \n                     k = 6)\n\n\nbiopsy_res_knn &lt;- test_biopsy_data %&gt;%\n                  mutate(pred_class3 = pred_class_knn3) %&gt;% \n                  mutate(pred_class6 = pred_class_knn6)\n\nNow we can have a look at the confusion tables:\n\nN &lt;- nrow(biopsy_res_knn)\n\nconfusion_mat3 &lt;- table(biopsy_res_knn  %&gt;% select(class, pred_class3))\nconfusion_mat3\n\n           pred_class3\nclass       benign malignant\n  benign       187         7\n  malignant      4        82\n\nconfusion_mat6 &lt;- table(biopsy_res_knn  %&gt;% select(class, pred_class6))\nconfusion_mat6\n\n           pred_class6\nclass       benign malignant\n  benign       186         8\n  malignant      5        81\n\n\nThen calculate the overall accuracy, true positive rate and true negative rate for each method you trained. We take positive to be malignant, and negative to be benign.\n\n\n\n\n## accuracy \nsum(diag(confusion_mat3))/(sum(confusion_mat3))\n\n[1] 0.9607143\n\n## TPR TP/(TP + FN)\nconfusion_mat3[2,2]/(sum(confusion_mat3[2,]))\n\n[1] 0.9534884\n\n## TNR TN/(TN + FP)\nconfusion_mat3[1,1]/(sum(confusion_mat3[1,]))\n\n[1] 0.9639175\n\n\n\n\n\n\n## accuracy \nsum(diag(confusion_mat6))/(sum(confusion_mat6))\n\n[1] 0.9535714\n\n## TPR TP/(TP + FN)\nconfusion_mat6[2,2]/(sum(confusion_mat6[2,]))\n\n[1] 0.9418605\n\n## TNR TN/(TN + FP)\nconfusion_mat6[1,1]/(sum(confusion_mat6[1,]))\n\n[1] 0.9587629"
  },
  {
    "objectID": "Tutorial6.html",
    "href": "Tutorial6.html",
    "title": "DS152 Tutorial Sheet 5",
    "section": "",
    "text": "We will work with the biopsy data (you’ve worked with this dataset before). It is a breast cancer database obtained from the University of Wisconsin-Madison Hospital. 699 biopsies of breast tumours were assessed and nine attributes (V1 - V9) were scored on a scale of 1 to 10. The objective is to predict whether a tumour is benign (0) or malignant (1), based on 5 of the attributes.\nBelow we have a glimpse of the dataset.\n\nbiopsy &lt;- MASS::biopsy\nglimpse(biopsy)\n\nRows: 699\nColumns: 11\n$ ID    &lt;chr&gt; \"1000025\", \"1002945\", \"1015425\", \"1016277\", \"1017023\", \"1017122\"…\n$ V1    &lt;int&gt; 5, 5, 3, 6, 4, 8, 1, 2, 2, 4, 1, 2, 5, 1, 8, 7, 4, 4, 10, 6, 7, …\n$ V2    &lt;int&gt; 1, 4, 1, 8, 1, 10, 1, 1, 1, 2, 1, 1, 3, 1, 7, 4, 1, 1, 7, 1, 3, …\n$ V3    &lt;int&gt; 1, 4, 1, 8, 1, 10, 1, 2, 1, 1, 1, 1, 3, 1, 5, 6, 1, 1, 7, 1, 2, …\n$ V4    &lt;int&gt; 1, 5, 1, 1, 3, 8, 1, 1, 1, 1, 1, 1, 3, 1, 10, 4, 1, 1, 6, 1, 10,…\n$ V5    &lt;int&gt; 2, 7, 2, 3, 2, 7, 2, 2, 2, 2, 1, 2, 2, 2, 7, 6, 2, 2, 4, 2, 5, 6…\n$ V6    &lt;int&gt; 1, 10, 2, 4, 1, 10, 10, 1, 1, 1, 1, 1, 3, 3, 9, 1, 1, 1, 10, 1, …\n$ V7    &lt;int&gt; 3, 3, 3, 3, 3, 9, 3, 3, 1, 2, 3, 2, 4, 3, 5, 4, 2, 3, 4, 3, 5, 7…\n$ V8    &lt;int&gt; 1, 2, 1, 7, 1, 7, 1, 1, 1, 1, 1, 1, 4, 1, 5, 3, 1, 1, 1, 1, 4, 1…\n$ V9    &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 4, 1, 1, 1, 2, 1, 4, 1…\n$ class &lt;fct&gt; benign, benign, benign, benign, benign, malignant, benign, benig…\n\n\nWe’re going to update the dataset to add a binary (0,1) version of the class variable.\n\nbiopsy &lt;- biopsy %&gt;% mutate(class_binary = as.numeric(class == \"malignant\"))\n\n(a) Before we begin modelling the data, let’s split the dataset in two: the training and the test set. We will fit the models using the training set, and then validate them using the test set. We will use 60% of the data as the training set, and the remaining 40% as the test set. Set the seed to 103 and replace [A], [B], [C] and [D] in the code below to create these training and test datasets.\n\nlibrary(rsample)\n\nset.seed(?)\n\nbiopsy_split &lt;- [A](biopsy, prop = [B])\n\ntrain_biopsy_data &lt;- [C]\ntest_biopsy_data  &lt;- [D]\n\n(b) We will use 2 different machine learning algorithms, namely:\n\nMethod 1: multiple logistic regression\nMethod 2: classification tree\n\nWe will fit them to the training set and then we will compare how well they perform on the test set.\nReplace [A] and [B] in the code below to fit a logistic regression model to the training data using all variables (V1 to V5) as predictors and class_binary as the outcome/response. Call the fitted model object logistic_model.\n\nlogistic_model  &lt;- glm([A], family = binomial, data = [B])\n\n(c) Now replace [A], [B] and [C] in the code below to fit a classification tree and call it tree_model and plot the classification tree.\n\nlibrary(rpart)\nlibrary(rpart.plot)\n\ntree_model &lt;- rpart([A],data = [B])\n\nrpart.plot([C])\n\n(d) Now we will use the test set to evaluate the two different methods. Below are the confusion tables for each method, using the test set. Calculate the overall accuracy, true positive rate and true negative rate for each method you trained. We take positive to be malignant, and negative to be benign.\n\n\n\n\n           pred_class1\nclass       benign malignant\n  benign       183        12\n  malignant      2        83\n\n\n\n\n\n\n\n           pred_class2\nclass       benign malignant\n  benign       177        18\n  malignant      6        79\n\n\n(e) Now we will use the k-nearest neighbours algorithm on the biopsy data. We will use k = 3 and k = 6 and compare results. The code below fits the models and gives predictions.\n\nlibrary(class)\npred_class_knn3 &lt;- knn(train_biopsy_data %&gt;% select(V1:V5), \n                     test_biopsy_data %&gt;% select(V1:V5), \n                     cl =   train_biopsy_data %&gt;% pull(class), \n                     k = 3)\n\npred_class_knn6 &lt;- knn(train_biopsy_data %&gt;% select(V1:V5), \n                     test_biopsy_data %&gt;% select(V1:V5), \n                     cl =   train_biopsy_data %&gt;% pull(class), \n                     k = 6)\n\n\nbiopsy_res_knn &lt;- test_biopsy_data %&gt;%\n                  mutate(pred_class3 = pred_class_knn3) %&gt;% \n                  mutate(pred_class6 = pred_class_knn6)\n\nFrom biopsy_res_knn we create the confusion tables for each knn method, shown below. Use these to calculate the overall accuracy, true positive rate and true negative rate for each knn method you trained. We take positive to be malignant, and negative to be benign.\n\nN &lt;- nrow(biopsy_res_knn)\n\nconfusion_mat3 &lt;- table(biopsy_res_knn  %&gt;% select(class, pred_class3))\nconfusion_mat3\n\n           pred_class3\nclass       benign malignant\n  benign       182        13\n  malignant      4        81\n\nconfusion_mat6 &lt;- table(biopsy_res_knn  %&gt;% select(class, pred_class6))\nconfusion_mat6\n\n           pred_class6\nclass       benign malignant\n  benign       183        12\n  malignant      0        85"
  },
  {
    "objectID": "Tutorial6.html#exercise-1",
    "href": "Tutorial6.html#exercise-1",
    "title": "DS152 Tutorial Sheet 5",
    "section": "",
    "text": "We will work with the biopsy data (you’ve worked with this dataset before). It is a breast cancer database obtained from the University of Wisconsin-Madison Hospital. 699 biopsies of breast tumours were assessed and nine attributes (V1 - V9) were scored on a scale of 1 to 10. The objective is to predict whether a tumour is benign (0) or malignant (1), based on 5 of the attributes.\nBelow we have a glimpse of the dataset.\n\nbiopsy &lt;- MASS::biopsy\nglimpse(biopsy)\n\nRows: 699\nColumns: 11\n$ ID    &lt;chr&gt; \"1000025\", \"1002945\", \"1015425\", \"1016277\", \"1017023\", \"1017122\"…\n$ V1    &lt;int&gt; 5, 5, 3, 6, 4, 8, 1, 2, 2, 4, 1, 2, 5, 1, 8, 7, 4, 4, 10, 6, 7, …\n$ V2    &lt;int&gt; 1, 4, 1, 8, 1, 10, 1, 1, 1, 2, 1, 1, 3, 1, 7, 4, 1, 1, 7, 1, 3, …\n$ V3    &lt;int&gt; 1, 4, 1, 8, 1, 10, 1, 2, 1, 1, 1, 1, 3, 1, 5, 6, 1, 1, 7, 1, 2, …\n$ V4    &lt;int&gt; 1, 5, 1, 1, 3, 8, 1, 1, 1, 1, 1, 1, 3, 1, 10, 4, 1, 1, 6, 1, 10,…\n$ V5    &lt;int&gt; 2, 7, 2, 3, 2, 7, 2, 2, 2, 2, 1, 2, 2, 2, 7, 6, 2, 2, 4, 2, 5, 6…\n$ V6    &lt;int&gt; 1, 10, 2, 4, 1, 10, 10, 1, 1, 1, 1, 1, 3, 3, 9, 1, 1, 1, 10, 1, …\n$ V7    &lt;int&gt; 3, 3, 3, 3, 3, 9, 3, 3, 1, 2, 3, 2, 4, 3, 5, 4, 2, 3, 4, 3, 5, 7…\n$ V8    &lt;int&gt; 1, 2, 1, 7, 1, 7, 1, 1, 1, 1, 1, 1, 4, 1, 5, 3, 1, 1, 1, 1, 4, 1…\n$ V9    &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 4, 1, 1, 1, 2, 1, 4, 1…\n$ class &lt;fct&gt; benign, benign, benign, benign, benign, malignant, benign, benig…\n\n\nWe’re going to update the dataset to add a binary (0,1) version of the class variable.\n\nbiopsy &lt;- biopsy %&gt;% mutate(class_binary = as.numeric(class == \"malignant\"))\n\n\nBefore we begin modelling the data, let’s split the dataset in two: the training and the test set. We will fit the models using the training set, and then validate them using the test set. We will use 60% of the data as the training set, and the remaining 40% as the test set. Set the seed to 103 and replace [A], [B], [C] and [D] in the code below to create these training and test datasets.\n\n\nlibrary(rsample)\n\nset.seed(?)\n\nbiopsy_split &lt;- [A](biopsy, prop = [B])\n\ntrain_biopsy_data &lt;- [C]\ntest_biopsy_data  &lt;- [D]\n\n\nWe will use 2 different machine learning algorithms, namely:\n\n\nMethod 1: multiple logistic regression\nMethod 2: classification tree\n\nWe will fit them to the training set and then we will compare how well they perform on the test set.\nReplace [A] and [B] in the code below to fit a logistic regression model to the training data using all variables (V1 to V5) as predictors and class_binary as the outcome/response. Call the fitted model object logistic_model.\n\nlogistic_model  &lt;- glm([A], family = binomial, data = [B])\n\n\nNow replace [A], [B] and [C] in the code below to fit a classification tree and call it tree_model and plot the classification tree.\n\n\nlibrary(rpart)\nlibrary(rpart.plot)\n\ntree_model &lt;- rpart([A],data = [B])\n\nrpart.plot([C])\n\n\nNow we will use the test set to evaluate the two different methods. Below are the confusion tables for each method, using the test set.\n\n\n\n\n\n           pred_class1\nclass       benign malignant\n  benign       183        12\n  malignant      2        83\n\n\n\n\n\n\n\n           pred_class2\nclass       benign malignant\n  benign       177        18\n  malignant      6        79\n\n\nCalculate the overall accuracy, true positive rate and true negative rate for each method you trained. We take positive to be malignant, and negative to be benign.\n\nNow we will use the k-nearest neighbours algorithm on the biopsy data. We will use k = 3 and k = 6 and compare results. The code below fits the models and gives predictions.\n\n\nlibrary(class)\npred_class_knn3 &lt;- knn(train_biopsy_data %&gt;% select(V1:V5), \n                     test_biopsy_data %&gt;% select(V1:V5), \n                     cl =   train_biopsy_data %&gt;% pull(class), \n                     k = 3)\n\npred_class_knn6 &lt;- knn(train_biopsy_data %&gt;% select(V1:V5), \n                     test_biopsy_data %&gt;% select(V1:V5), \n                     cl =   train_biopsy_data %&gt;% pull(class), \n                     k = 6)\n\n\nbiopsy_res_knn &lt;- test_biopsy_data %&gt;%\n                  mutate(pred_class3 = pred_class_knn3) %&gt;% \n                  mutate(pred_class6 = pred_class_knn6)\n\nFrom biopsy_res_knn we create the confusion tables for each knn method, shown below. Use these to calculate the overall accuracy, true positive rate and true negative rate for each knn method you trained. We take positive to be malignant, and negative to be benign.\n\nN &lt;- nrow(biopsy_res_knn)\n\nconfusion_mat3 &lt;- table(biopsy_res_knn  %&gt;% select(class, pred_class3))\nconfusion_mat3\n\n           pred_class3\nclass       benign malignant\n  benign       182        13\n  malignant      4        81\n\nconfusion_mat6 &lt;- table(biopsy_res_knn  %&gt;% select(class, pred_class6))\nconfusion_mat6\n\n           pred_class6\nclass       benign malignant\n  benign       183        12\n  malignant      0        85"
  },
  {
    "objectID": "Tutorial6.html#exercise",
    "href": "Tutorial6.html#exercise",
    "title": "DS152 Tutorial Sheet 5",
    "section": "",
    "text": "We will work with the biopsy data (you’ve worked with this dataset before). It is a breast cancer database obtained from the University of Wisconsin-Madison Hospital. 699 biopsies of breast tumours were assessed and nine attributes (V1 - V9) were scored on a scale of 1 to 10. The objective is to predict whether a tumour is benign (0) or malignant (1), based on 5 of the attributes.\nBelow we have a glimpse of the dataset.\n\nbiopsy &lt;- MASS::biopsy\nglimpse(biopsy)\n\nRows: 699\nColumns: 11\n$ ID    &lt;chr&gt; \"1000025\", \"1002945\", \"1015425\", \"1016277\", \"1017023\", \"1017122\"…\n$ V1    &lt;int&gt; 5, 5, 3, 6, 4, 8, 1, 2, 2, 4, 1, 2, 5, 1, 8, 7, 4, 4, 10, 6, 7, …\n$ V2    &lt;int&gt; 1, 4, 1, 8, 1, 10, 1, 1, 1, 2, 1, 1, 3, 1, 7, 4, 1, 1, 7, 1, 3, …\n$ V3    &lt;int&gt; 1, 4, 1, 8, 1, 10, 1, 2, 1, 1, 1, 1, 3, 1, 5, 6, 1, 1, 7, 1, 2, …\n$ V4    &lt;int&gt; 1, 5, 1, 1, 3, 8, 1, 1, 1, 1, 1, 1, 3, 1, 10, 4, 1, 1, 6, 1, 10,…\n$ V5    &lt;int&gt; 2, 7, 2, 3, 2, 7, 2, 2, 2, 2, 1, 2, 2, 2, 7, 6, 2, 2, 4, 2, 5, 6…\n$ V6    &lt;int&gt; 1, 10, 2, 4, 1, 10, 10, 1, 1, 1, 1, 1, 3, 3, 9, 1, 1, 1, 10, 1, …\n$ V7    &lt;int&gt; 3, 3, 3, 3, 3, 9, 3, 3, 1, 2, 3, 2, 4, 3, 5, 4, 2, 3, 4, 3, 5, 7…\n$ V8    &lt;int&gt; 1, 2, 1, 7, 1, 7, 1, 1, 1, 1, 1, 1, 4, 1, 5, 3, 1, 1, 1, 1, 4, 1…\n$ V9    &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 4, 1, 1, 1, 2, 1, 4, 1…\n$ class &lt;fct&gt; benign, benign, benign, benign, benign, malignant, benign, benig…\n\n\nWe’re going to update the dataset to add a binary (0,1) version of the class variable.\n\nbiopsy &lt;- biopsy %&gt;% mutate(class_binary = as.numeric(class == \"malignant\"))\n\n(a) Before we begin modelling the data, let’s split the dataset in two: the training and the test set. We will fit the models using the training set, and then validate them using the test set. We will use 60% of the data as the training set, and the remaining 40% as the test set. Set the seed to 103 and replace [A], [B], [C] and [D] in the code below to create these training and test datasets.\n\nlibrary(rsample)\n\nset.seed(?)\n\nbiopsy_split &lt;- [A](biopsy, prop = [B])\n\ntrain_biopsy_data &lt;- [C]\ntest_biopsy_data  &lt;- [D]\n\n(b) We will use 2 different machine learning algorithms, namely:\n\nMethod 1: multiple logistic regression\nMethod 2: classification tree\n\nWe will fit them to the training set and then we will compare how well they perform on the test set.\nReplace [A] and [B] in the code below to fit a logistic regression model to the training data using all variables (V1 to V5) as predictors and class_binary as the outcome/response. Call the fitted model object logistic_model.\n\nlogistic_model  &lt;- glm([A], family = binomial, data = [B])\n\n(c) Now replace [A], [B] and [C] in the code below to fit a classification tree and call it tree_model and plot the classification tree.\n\nlibrary(rpart)\nlibrary(rpart.plot)\n\ntree_model &lt;- rpart([A],data = [B])\n\nrpart.plot([C])\n\n(d) Now we will use the test set to evaluate the two different methods. Below are the confusion tables for each method, using the test set. Calculate the overall accuracy, true positive rate and true negative rate for each method you trained. We take positive to be malignant, and negative to be benign.\n\n\n\n\n           pred_class1\nclass       benign malignant\n  benign       183        12\n  malignant      2        83\n\n\n\n\n\n\n\n           pred_class2\nclass       benign malignant\n  benign       177        18\n  malignant      6        79\n\n\n(e) Now we will use the k-nearest neighbours algorithm on the biopsy data. We will use k = 3 and k = 6 and compare results. The code below fits the models and gives predictions.\n\nlibrary(class)\npred_class_knn3 &lt;- knn(train_biopsy_data %&gt;% select(V1:V5), \n                     test_biopsy_data %&gt;% select(V1:V5), \n                     cl =   train_biopsy_data %&gt;% pull(class), \n                     k = 3)\n\npred_class_knn6 &lt;- knn(train_biopsy_data %&gt;% select(V1:V5), \n                     test_biopsy_data %&gt;% select(V1:V5), \n                     cl =   train_biopsy_data %&gt;% pull(class), \n                     k = 6)\n\n\nbiopsy_res_knn &lt;- test_biopsy_data %&gt;%\n                  mutate(pred_class3 = pred_class_knn3) %&gt;% \n                  mutate(pred_class6 = pred_class_knn6)\n\nFrom biopsy_res_knn we create the confusion tables for each knn method, shown below. Use these to calculate the overall accuracy, true positive rate and true negative rate for each knn method you trained. We take positive to be malignant, and negative to be benign.\n\nN &lt;- nrow(biopsy_res_knn)\n\nconfusion_mat3 &lt;- table(biopsy_res_knn  %&gt;% select(class, pred_class3))\nconfusion_mat3\n\n           pred_class3\nclass       benign malignant\n  benign       182        13\n  malignant      4        81\n\nconfusion_mat6 &lt;- table(biopsy_res_knn  %&gt;% select(class, pred_class6))\nconfusion_mat6\n\n           pred_class6\nclass       benign malignant\n  benign       183        12\n  malignant      0        85"
  },
  {
    "objectID": "9b-text.html",
    "href": "9b-text.html",
    "title": "Introduction to Text Analysis",
    "section": "",
    "text": "Text Analysis or Text Analytics is the representation, processing and modelling of text data.\nText Mining is the procedure used to transform text into data that can be used by a machine learning technique.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGovernment: spotting emerging trends and public concerns\nFinancial institutions: detecting fraudulent activity (e.g. insurance)\nRetail: identifying potential customers; predict and avoid churning; improve the brand\nMarket: identifying trends in different segments (e.g. using social network data)"
  },
  {
    "objectID": "9b-text.html#text-analysis",
    "href": "9b-text.html#text-analysis",
    "title": "Introduction to Text Analysis",
    "section": "",
    "text": "Text Analysis or Text Analytics is the representation, processing and modelling of text data.\nText Mining is the procedure used to transform text into data that can be used by a machine learning technique.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGovernment: spotting emerging trends and public concerns\nFinancial institutions: detecting fraudulent activity (e.g. insurance)\nRetail: identifying potential customers; predict and avoid churning; improve the brand\nMarket: identifying trends in different segments (e.g. using social network data)"
  },
  {
    "objectID": "9b-text.html#tidy-text",
    "href": "9b-text.html#tidy-text",
    "title": "Introduction to Text Analysis",
    "section": "Tidy Text",
    "text": "Tidy Text\nUsing tidy data principles can make many text mining tasks easier, more effective, and consistent with tools already in wide use.\nLearn more at https://www.tidytextmining.com/.\n\nPackages\n\nlibrary(tidyverse)\nlibrary(tidytext)\n\n\n\nWhat is tidy text?\nWe can define the tidy text format as being a table with one-token-per-row. A token is a meaningful unit of text, such as a word, that we are interested in using for analysis, and tokenization is the process of splitting text into tokens.\nTidy data sets allow manipulation with a standard set of “tidy” tools, including popular packages such as dplyr (Wickham and Francois 2016), tidyr (Wickham 2016) and ggplot2 (Wickham 2009). By keeping the input and output in tidy tables, users can transition fluidly between these packages. These tidy tools extend naturally to many text analyses and explorations.\n\n\nSimple example\n\ntext &lt;- c(\"Take me out tonight\",\n          \"Where there's music and there's people\",\n          \"And they're young and alive\",\n          \"Driving in your car\",\n          \"I never never want to go home\",\n          \"Because I haven't got one\",\n          \"Anymore\")\ntext\n\n[1] \"Take me out tonight\"                   \n[2] \"Where there's music and there's people\"\n[3] \"And they're young and alive\"           \n[4] \"Driving in your car\"                   \n[5] \"I never never want to go home\"         \n[6] \"Because I haven't got one\"             \n[7] \"Anymore\"                               \n\n\n\ntext_df &lt;- tibble(line = 1:7, text = text)\ntext_df\n\n# A tibble: 7 × 2\n   line text                                  \n  &lt;int&gt; &lt;chr&gt;                                 \n1     1 Take me out tonight                   \n2     2 Where there's music and there's people\n3     3 And they're young and alive           \n4     4 Driving in your car                   \n5     5 I never never want to go home         \n6     6 Because I haven't got one             \n7     7 Anymore                               \n\n\n\ntext_df %&gt;%\n  unnest_tokens(word, text)\n\n# A tibble: 32 × 2\n    line word   \n   &lt;int&gt; &lt;chr&gt;  \n 1     1 take   \n 2     1 me     \n 3     1 out    \n 4     1 tonight\n 5     2 where  \n 6     2 there's\n 7     2 music  \n 8     2 and    \n 9     2 there's\n10     2 people \n# ℹ 22 more rows"
  },
  {
    "objectID": "9b-text.html#sentiment-analysis-with-song-lyrics",
    "href": "9b-text.html#sentiment-analysis-with-song-lyrics",
    "title": "Introduction to Text Analysis",
    "section": "Sentiment Analysis with song lyrics",
    "text": "Sentiment Analysis with song lyrics\nOur modeling goal is to “discover” topics in the lyrics of Spice Girls songs. Instead of a supervised or predictive model where our observations have labels, this is an unsupervised approach.\nWe can read in and glimpse the data as follows:\n\nlibrary(tidyverse)\nlyrics &lt;- \nread_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-12-14/lyrics.csv\")\n\n\nglimpse(lyrics)\n\nRows: 1,885\nColumns: 9\n$ artist_name    &lt;chr&gt; \"Spice Girls\", \"Spice Girls\", \"Spice Girls\", \"Spice Gir…\n$ album_name     &lt;chr&gt; \"Spice\", \"Spice\", \"Spice\", \"Spice\", \"Spice\", \"Spice\", \"…\n$ track_number   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ song_id        &lt;dbl&gt; 89740, 89740, 89740, 89740, 89740, 89740, 89740, 89740,…\n$ song_name      &lt;chr&gt; \"Wannabe\", \"Wannabe\", \"Wannabe\", \"Wannabe\", \"Wannabe\", …\n$ line_number    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, …\n$ section_name   &lt;chr&gt; \"Intro\", \"Intro\", \"Intro\", \"Intro\", \"Intro\", \"Intro\", \"…\n$ line           &lt;chr&gt; \"Hahaha\", \"Yo, I'll tell you what I want, what I really…\n$ section_artist &lt;chr&gt; \"Scary, Ginger\", \"Scary, Ginger\", \"Scary, Ginger\", \"Sca…\n\n\nLet’s just consider the album called “Spice” and look at the song names in that album. Note the use of the distinct function as each song name appears multiple times in the dataset.\n\nspice_lyrics &lt;- lyrics %&gt;%\n                  filter(album_name == \"Spice\") \n\nspice_lyrics %&gt;% distinct(song_name)\n\n# A tibble: 10 × 1\n   song_name                 \n   &lt;chr&gt;                     \n 1 \"Wannabe\"                 \n 2 \"Say You\\x92ll Be There\"  \n 3 \"2 Become 1\"              \n 4 \"Love Thing\"              \n 5 \"Last Time Lover\"         \n 6 \"Mama\"                    \n 7 \"Who Do You Think You Are\"\n 8 \"Something Kinda Funny\"   \n 9 \"Naked\"                   \n10 \"If U Can\\x92t Dance\"     \n\n\nLet’s get an idea of how long the songs are by looking at the number of lines in each song.\n\nspice_lyrics %&gt;%\n    count(song_name) %&gt;%\n    arrange(n)\n\n# A tibble: 10 × 2\n   song_name                      n\n   &lt;chr&gt;                      &lt;int&gt;\n 1 \"Something Kinda Funny\"       34\n 2 \"2 Become 1\"                  42\n 3 \"Mama\"                        55\n 4 \"Say You\\x92ll Be There\"      55\n 5 \"Who Do You Think You Are\"    58\n 6 \"Wannabe\"                     60\n 7 \"Naked\"                       70\n 8 \"Last Time Lover\"             72\n 9 \"If U Can\\x92t Dance\"         73\n10 \"Love Thing\"                  80\n\n\nTidy up your lyrics\n\ntidy_spice_lyrics &lt;- spice_lyrics %&gt;% \n                      unnest_tokens(word,line) %&gt;% \n                      select(word, track_number, song_name)\ntidy_spice_lyrics \n\n# A tibble: 4,609 × 3\n   word   track_number song_name\n   &lt;chr&gt;         &lt;dbl&gt; &lt;chr&gt;    \n 1 hahaha            1 Wannabe  \n 2 yo                1 Wannabe  \n 3 i'll              1 Wannabe  \n 4 tell              1 Wannabe  \n 5 you               1 Wannabe  \n 6 what              1 Wannabe  \n 7 i                 1 Wannabe  \n 8 want              1 Wannabe  \n 9 what              1 Wannabe  \n10 i                 1 Wannabe  \n# ℹ 4,599 more rows\n\n\nWhat are the most common words?\n\ntidy_spice_lyrics %&gt;%\n  count(word) %&gt;%\n  arrange(desc(n))\n\n# A tibble: 574 × 2\n   word      n\n   &lt;chr&gt; &lt;int&gt;\n 1 you     322\n 2 it      226\n 3 i       134\n 4 me      108\n 5 to       84\n 6 can't    81\n 7 if       69\n 8 and      67\n 9 a        63\n10 love     63\n# ℹ 564 more rows\n\n\n\nStop words\nIn computing, stop words are words which are filtered out before or after processing of natural language data (text). They usually refer to the most common words in a language, but there is not a single list of stop words used by all natural language processing tools.\n\nlibrary(stopwords)\nget_stopwords(language = \"en\", source = \"snowball\")\n\n# A tibble: 175 × 2\n   word      lexicon \n   &lt;chr&gt;     &lt;chr&gt;   \n 1 i         snowball\n 2 me        snowball\n 3 my        snowball\n 4 myself    snowball\n 5 we        snowball\n 6 our       snowball\n 7 ours      snowball\n 8 ourselves snowball\n 9 you       snowball\n10 your      snowball\n# ℹ 165 more rows\n\n\nNote, the stopword lexicon is specified. The default is “snowball”. Use stopwords_getsources() to see available sources.\n\nstopwords_getsources()\n\n[1] \"snowball\"      \"stopwords-iso\" \"misc\"          \"smart\"        \n[5] \"marimo\"        \"ancient\"       \"nltk\"          \"perseus\"      \n\n\nWhat are the most common words when we exclude stop words?\n\ncommon_spice_lyrics &lt;- tidy_spice_lyrics %&gt;%\n                        anti_join(get_stopwords(source = \"smart\")) %&gt;%\n                        count(word) %&gt;%\n                        arrange(desc(n))\n\nJoining with `by = join_by(word)`\n\ncommon_spice_lyrics\n\n# A tibble: 384 × 2\n   word       n\n   &lt;chr&gt;  &lt;int&gt;\n 1 love      63\n 2 wanna     61\n 3 dance     60\n 4 time      36\n 5 hey       35\n 6 baby      34\n 7 lover     33\n 8 make      33\n 9 naked     29\n10 groove    22\n# ℹ 374 more rows\n\n\nLet’s visualise the most common words\n\nggplot(common_spice_lyrics %&gt;% top_n(20), aes(x = fct_reorder(word,n), y = n)) +\n    geom_col() +\n    coord_flip() + \n    theme_minimal() +\n    labs(title = \"Frequency of Spice Girl's lyrics\",\n         subtitle = \"`Love` tops the chart\",\n         y = \"\",\n         x = \"\")\n\n\n\n\n\n\n\n\n\n\nSentiment Analysis\nOne way to analyze the sentiment of a text is to consider the text as a combination of its individual words and the sentiment content of the whole text as the sum of the sentiment content of the individual words.\nSentiment lexicons - bing\n\nget_sentiments(\"bing\")\n\n# A tibble: 6,786 × 2\n   word        sentiment\n   &lt;chr&gt;       &lt;chr&gt;    \n 1 2-faces     negative \n 2 abnormal    negative \n 3 abolish     negative \n 4 abominable  negative \n 5 abominably  negative \n 6 abominate   negative \n 7 abomination negative \n 8 abort       negative \n 9 aborted     negative \n10 aborts      negative \n# ℹ 6,776 more rows\n\n\nSentiments in Spice Girls lyrics\nWe’ll use the “bing” lexicon.\n\nsentiment_spice_lyrics &lt;- tidy_spice_lyrics %&gt;%\n                            anti_join(get_stopwords(source = \"smart\")) %&gt;%\n                            inner_join(get_sentiments(\"bing\")) %&gt;%\n                            count(sentiment, word) %&gt;%\n                            arrange(desc(n))\nsentiment_spice_lyrics\n\n# A tibble: 69 × 3\n   sentiment word       n\n   &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;\n 1 positive  love      63\n 2 positive  lover     33\n 3 positive  loving    22\n 4 negative  shake     18\n 5 positive  good      18\n 6 positive  trust     18\n 7 negative  funny     17\n 8 positive  yay       17\n 9 positive  whoa      16\n10 positive  easy      12\n# ℹ 59 more rows\n\n\nSentiments in Spice Girls lyrics\n\nsentiment_spice_lyrics %&gt;% \n  group_by(sentiment) %&gt;% \n  summarise(n_sentiment = sum(n))\n\n# A tibble: 2 × 2\n  sentiment n_sentiment\n  &lt;chr&gt;           &lt;int&gt;\n1 negative           98\n2 positive          279\n\n\nVisualise the Sentiments in Spice Girls lyrics\n\nggplot(sentiment_spice_lyrics %&gt;% top_n(20), aes(x = fct_reorder(word,n), y = n)) +\n    geom_col() +\n    coord_flip() + \n    theme_minimal() +\n    labs(title = \"Sentiment of Spice Girl's lyrics\",\n         subtitle = \"`Love` tops the chart\",\n         y = \"\",\n         x = \"\") +\n    facet_wrap(~sentiment, scales  = \"free\")\n\nSelecting by n\n\n\n\n\n\n\n\n\n\nSentiment lexicons - bing\nYou can get other lexicons with the tidytext package. The “afinn” lexicon returns a numeric value instead of a sentiment. The value is an integer between minus five (negative) and plus five (positive).\n\nget_sentiments(\"afinn\")\n\n# A tibble: 2,477 × 2\n   word       value\n   &lt;chr&gt;      &lt;dbl&gt;\n 1 abandon       -2\n 2 abandoned     -2\n 3 abandons      -2\n 4 abducted      -2\n 5 abduction     -2\n 6 abductions    -2\n 7 abhor         -3\n 8 abhorred      -3\n 9 abhorrent     -3\n10 abhors        -3\n# ℹ 2,467 more rows\n\n\nSentiments in Spice Girls lyrics\nWe’ll use the “afinn” lexicon.\n\nsentiment_spice_lyrics &lt;- tidy_spice_lyrics %&gt;%\n                            anti_join(get_stopwords(source = \"smart\")) %&gt;%\n                            inner_join(get_sentiments(\"afinn\")) \nsentiment_spice_lyrics\n\n# A tibble: 380 × 4\n   word      track_number song_name value\n   &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1 hahaha               1 Wannabe       3\n 2 forget               1 Wannabe      -1\n 3 wasting              1 Wannabe      -2\n 4 fine                 1 Wannabe       2\n 5 easy                 1 Wannabe       1\n 6 love                 1 Wannabe       3\n 7 easy                 1 Wannabe       1\n 8 carefully            1 Wannabe       2\n 9 likes                1 Wannabe       2\n10 likes                1 Wannabe       2\n# ℹ 370 more rows\n\n\nsummarise the afinn scores\n\nsentiment_spice_lyrics %&gt;% group_by(song_name) %&gt;% summarise(mean_afinn = mean(value))\n\n# A tibble: 10 × 2\n   song_name                  mean_afinn\n   &lt;chr&gt;                           &lt;dbl&gt;\n 1 \"2 Become 1\"                    1.86 \n 2 \"If U Can\\x92t Dance\"          -1    \n 3 \"Last Time Lover\"               1.1  \n 4 \"Love Thing\"                    1.08 \n 5 \"Mama\"                          1.96 \n 6 \"Naked\"                        -0.267\n 7 \"Say You\\x92ll Be There\"        0.45 \n 8 \"Something Kinda Funny\"         2.27 \n 9 \"Wannabe\"                      -0.120\n10 \"Who Do You Think You Are\"      1.55 \n\n\nvisualise the afinn scores\n\nggplot(sentiment_spice_lyrics, aes(y = value)) +\n  geom_boxplot() \n\n\n\n\n\n\n\n\n\nggplot(sentiment_spice_lyrics, aes(x = song_name, y = value)) +\n  geom_boxplot() +\n  geom_point() +\n  coord_flip()"
  },
  {
    "objectID": "kmeans_workedexample.html",
    "href": "kmeans_workedexample.html",
    "title": "R Notebook",
    "section": "",
    "text": "K-Means is an unsupervised machine learning algorithm used for partitioning a dataset into K clusters based on similarity. It minimizes the within-cluster sum of squares (WCSS) by iteratively refining cluster centroids.\n\n\n\nCustomer segmentation helps businesses identify distinct customer groups based on behavior, spending patterns, or demographics. This allows for targeted marketing and personalized services.\n\n\n\n\nWe will use a synthetic dataset resembling customer spending behavior. The dataset contains: - CustomerID: Unique customer identifier - Annual_Income: Yearly income (in $1000s) - Spending_Score: A score from 0 to 100 representing spending habits (higher means more spending)\n\n\n\n\n\n\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(cluster)\nlibrary(factoextra)\n\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n\n\n\n\n\n\n# Sample data: Simulated Customer Segmentation dataset\ndata &lt;- data.frame(\n  CustomerID = 1:200,\n  Annual_Income = round(runif(200, 15, 120), 1),  # Income in $1000s\n  Spending_Score = round(runif(200, 1, 100), 1)  # Spending Score (1-100)\n)\n\n# View first few rows\nhead(data)\n\n  CustomerID Annual_Income Spending_Score\n1          1          35.6            3.6\n2          2          30.6           97.1\n3          3          75.6           38.9\n4          4         101.7           60.3\n5          5          58.8           75.1\n6          6         116.7           56.3\n\n\n\n\n\n\n# Select relevant features (dropping CustomerID)\ndata_scaled &lt;- scale(data[, c(\"Annual_Income\", \"Spending_Score\")])\n\n\n\n\n\nset.seed(123) # For reproducibility\nwcss &lt;- vector()\nfor (k in 1:10) {\n  kmeans_result &lt;- kmeans(data_scaled, centers = k, nstart = 25)\n  wcss[k] &lt;- kmeans_result$tot.withinss\n}\n\n# Plot Elbow Method\nplot(1:10, wcss, type = \"b\", pch = 19, frame = FALSE,\n     xlab = \"Number of Clusters (K)\", ylab = \"WCSS\",\n     main = \"Elbow Method for Optimal K\")\n\n\n\n\n\n\n\n\n\n\n\n\n# Apply K-Means with optimal K (let's assume K=5 from the Elbow Method)\nkmeans_model &lt;- kmeans(data_scaled, centers = 5, nstart = 25)\ndata$Cluster &lt;- as.factor(kmeans_model$cluster)\n\n\n\n\n\n# Scatter plot of clusters\nfviz_cluster(kmeans_model, data = data_scaled, geom = \"point\",\n             ellipse.type = \"norm\", palette = \"jco\", ggtheme = theme_minimal())\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdentified Segments: The customers are grouped into five distinct segments based on spending habits and income levels.\nCluster Characteristics:\n\nHigh-income, high-spending customers (e.g., luxury spenders)\nHigh-income, low-spending customers (e.g., frugal earners)\nLow-income, high-spending customers (e.g., budget-conscious spenders)\nLow-income, low-spending customers (e.g., cost-sensitive buyers)\nModerate-income, moderate-spending customers\n\nBusiness Applications: The segmentation results can inform targeted marketing strategies, loyalty programs, and pricing models.\n\n\n\n\n\nK-Means clustering is a powerful tool for customer segmentation.\nThe Elbow Method helps select an appropriate number of clusters.\nVisualization provides valuable insights into customer behavior.\n\n\nThis example demonstrates how to implement K-Means clustering in R, interpret the results, and apply them to business scenarios."
  },
  {
    "objectID": "kmeans_workedexample.html#overview-of-k-means-clustering",
    "href": "kmeans_workedexample.html#overview-of-k-means-clustering",
    "title": "R Notebook",
    "section": "",
    "text": "K-Means is an unsupervised machine learning algorithm used for partitioning a dataset into K clusters based on similarity. It minimizes the within-cluster sum of squares (WCSS) by iteratively refining cluster centroids.\n\n\n\nCustomer segmentation helps businesses identify distinct customer groups based on behavior, spending patterns, or demographics. This allows for targeted marketing and personalized services."
  },
  {
    "objectID": "kmeans_workedexample.html#dataset-description",
    "href": "kmeans_workedexample.html#dataset-description",
    "title": "R Notebook",
    "section": "",
    "text": "We will use a synthetic dataset resembling customer spending behavior. The dataset contains: - CustomerID: Unique customer identifier - Annual_Income: Yearly income (in $1000s) - Spending_Score: A score from 0 to 100 representing spending habits (higher means more spending)"
  },
  {
    "objectID": "kmeans_workedexample.html#implementing-k-means-in-r",
    "href": "kmeans_workedexample.html#implementing-k-means-in-r",
    "title": "R Notebook",
    "section": "",
    "text": "# Load necessary libraries\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(cluster)\nlibrary(factoextra)\n\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n\n\n\n\n\n\n# Sample data: Simulated Customer Segmentation dataset\ndata &lt;- data.frame(\n  CustomerID = 1:200,\n  Annual_Income = round(runif(200, 15, 120), 1),  # Income in $1000s\n  Spending_Score = round(runif(200, 1, 100), 1)  # Spending Score (1-100)\n)\n\n# View first few rows\nhead(data)\n\n  CustomerID Annual_Income Spending_Score\n1          1          35.6            3.6\n2          2          30.6           97.1\n3          3          75.6           38.9\n4          4         101.7           60.3\n5          5          58.8           75.1\n6          6         116.7           56.3\n\n\n\n\n\n\n# Select relevant features (dropping CustomerID)\ndata_scaled &lt;- scale(data[, c(\"Annual_Income\", \"Spending_Score\")])\n\n\n\n\n\nset.seed(123) # For reproducibility\nwcss &lt;- vector()\nfor (k in 1:10) {\n  kmeans_result &lt;- kmeans(data_scaled, centers = k, nstart = 25)\n  wcss[k] &lt;- kmeans_result$tot.withinss\n}\n\n# Plot Elbow Method\nplot(1:10, wcss, type = \"b\", pch = 19, frame = FALSE,\n     xlab = \"Number of Clusters (K)\", ylab = \"WCSS\",\n     main = \"Elbow Method for Optimal K\")\n\n\n\n\n\n\n\n\n\n\n\n\n# Apply K-Means with optimal K (let's assume K=5 from the Elbow Method)\nkmeans_model &lt;- kmeans(data_scaled, centers = 5, nstart = 25)\ndata$Cluster &lt;- as.factor(kmeans_model$cluster)\n\n\n\n\n\n# Scatter plot of clusters\nfviz_cluster(kmeans_model, data = data_scaled, geom = \"point\",\n             ellipse.type = \"norm\", palette = \"jco\", ggtheme = theme_minimal())"
  },
  {
    "objectID": "kmeans_workedexample.html#interpretation-of-results",
    "href": "kmeans_workedexample.html#interpretation-of-results",
    "title": "R Notebook",
    "section": "",
    "text": "Identified Segments: The customers are grouped into five distinct segments based on spending habits and income levels.\nCluster Characteristics:\n\nHigh-income, high-spending customers (e.g., luxury spenders)\nHigh-income, low-spending customers (e.g., frugal earners)\nLow-income, high-spending customers (e.g., budget-conscious spenders)\nLow-income, low-spending customers (e.g., cost-sensitive buyers)\nModerate-income, moderate-spending customers\n\nBusiness Applications: The segmentation results can inform targeted marketing strategies, loyalty programs, and pricing models."
  },
  {
    "objectID": "kmeans_workedexample.html#conclusion",
    "href": "kmeans_workedexample.html#conclusion",
    "title": "R Notebook",
    "section": "",
    "text": "K-Means clustering is a powerful tool for customer segmentation.\nThe Elbow Method helps select an appropriate number of clusters.\nVisualization provides valuable insights into customer behavior.\n\n\nThis example demonstrates how to implement K-Means clustering in R, interpret the results, and apply them to business scenarios."
  },
  {
    "objectID": "9-image.html",
    "href": "9-image.html",
    "title": "Introduction to Image Analysis",
    "section": "",
    "text": "What is an image? What does a computer “see”?\nIn essence, it is an array of numbers representing colour intensities called pixels.\nThe pixel (a word invented from “picture element”) is the basic unit of programmable color on a computer display or in a computer image.\n\n\n\n\n\n\n\n\n\n\n\n\nThe application of image analysis can be expanded to different domains of science, such as:\nImage detection on videos\n\nAutonomous cars\n\nAnimals identification\n\nDisease diagnosis\n\nMeasure Student Engagement\n\n\n\n\nhttp://yann.lecun.com/exdb/mnist/\n\n70,000 grayscale images of handwritten numbers at low resolution (28 by 28 pixels)\nUsed 60,000 to train the algorithm and 10,000 to test\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwe can use virtually ANY supervised classification algorithm (each pixel is a “feature” or “predictor”)\ne.g. k-nearest neighbours, trees/random forests, logistic/multinomial regression, support vector machines, neural networks\nyou have already studied a few of these techniques\nWe will use KNN to classify the images\n\n\n\n\nIf we assume each pixel is a feature/predictor then we should format that data such that the columns are pixels and each row corresponds to an image.\nWe’ll work with a subset of the MNIST data and consider 1000 images int he training data and 100 images in the test data.\n\nmnist_train\n\n# A tibble: 1,000 × 765\n   label pixel1 pixel2 pixel3 pixel4 pixel5 pixel6 pixel7 pixel8 pixel9 pixel10\n   &lt;fct&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n 1 2          0      0      0      0      0      0      0      0      0       0\n 2 7          0      0      0      0      0      0      0      0      0       0\n 3 3          0      0      0      0      0      0      0      0      0       0\n 4 4          0      0      0      0      0      0      0      0      0       0\n 5 6          0      0      0      0      0      0      0      0      0       0\n 6 1          0      0      0      0      0      0      0      0      0       0\n 7 8          0      0      0      0      0      0      0      0      0       0\n 8 1          0      0      0      0      0      0      0      0      0       0\n 9 0          0      0      0      0      0      0      0      0      0       0\n10 9          0      0      0      0      0      0      0      0      0       0\n# ℹ 990 more rows\n# ℹ 754 more variables: pixel11 &lt;dbl&gt;, pixel12 &lt;dbl&gt;, pixel13 &lt;dbl&gt;,\n#   pixel14 &lt;dbl&gt;, pixel15 &lt;dbl&gt;, pixel16 &lt;dbl&gt;, pixel17 &lt;dbl&gt;, pixel18 &lt;dbl&gt;,\n#   pixel19 &lt;dbl&gt;, pixel20 &lt;dbl&gt;, pixel21 &lt;dbl&gt;, pixel22 &lt;dbl&gt;, pixel23 &lt;dbl&gt;,\n#   pixel24 &lt;dbl&gt;, pixel25 &lt;dbl&gt;, pixel26 &lt;dbl&gt;, pixel27 &lt;dbl&gt;, pixel28 &lt;dbl&gt;,\n#   pixel29 &lt;dbl&gt;, pixel30 &lt;dbl&gt;, pixel31 &lt;dbl&gt;, pixel32 &lt;dbl&gt;, pixel33 &lt;dbl&gt;,\n#   pixel34 &lt;dbl&gt;, pixel35 &lt;dbl&gt;, pixel36 &lt;dbl&gt;, pixel37 &lt;dbl&gt;, …\n\n\n\nmnist_test\n\n# A tibble: 100 × 765\n   label pixel1 pixel2 pixel3 pixel4 pixel5 pixel6 pixel7 pixel8 pixel9 pixel10\n   &lt;fct&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n 1 8          0      0      0      0      0      0      0      0      0       0\n 2 1          0      0      0      0      0      0      0      0      0       0\n 3 4          0      0      0      0      0      0      0      0      0       0\n 4 4          0      0      0      0      0      0      0      0      0       0\n 5 6          0      0      0      0      0      0      0      0      0       0\n 6 0          0      0      0      0      0      0      0      0      0       0\n 7 2          0      0      0      0      0      0      0      0      0       0\n 8 9          0      0      0      0      0      0      0      0      0       0\n 9 1          0      0      0      0      0      0      0      0      0       0\n10 4          0      0      0      0      0      0      0      0      0       0\n# ℹ 90 more rows\n# ℹ 754 more variables: pixel11 &lt;dbl&gt;, pixel12 &lt;dbl&gt;, pixel13 &lt;dbl&gt;,\n#   pixel14 &lt;dbl&gt;, pixel15 &lt;dbl&gt;, pixel16 &lt;dbl&gt;, pixel17 &lt;dbl&gt;, pixel18 &lt;dbl&gt;,\n#   pixel19 &lt;dbl&gt;, pixel20 &lt;dbl&gt;, pixel21 &lt;dbl&gt;, pixel22 &lt;dbl&gt;, pixel23 &lt;dbl&gt;,\n#   pixel24 &lt;dbl&gt;, pixel25 &lt;dbl&gt;, pixel26 &lt;dbl&gt;, pixel27 &lt;dbl&gt;, pixel28 &lt;dbl&gt;,\n#   pixel29 &lt;dbl&gt;, pixel30 &lt;dbl&gt;, pixel31 &lt;dbl&gt;, pixel32 &lt;dbl&gt;, pixel33 &lt;dbl&gt;,\n#   pixel34 &lt;dbl&gt;, pixel35 &lt;dbl&gt;, pixel36 &lt;dbl&gt;, pixel37 &lt;dbl&gt;, …\n\n\n\n\n\n\nlibrary(class)\npred_label_knn &lt;- knn(mnist_train %&gt;% select(-label), \n                      mnist_test %&gt;% select(-label), \n                      cl = mnist_train$label , \n                      k = 5)\npred_label_knn\n\n  [1] 8 1 9 7 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 1 1 2 2 3 7 3 0 3 9 1 1 9 0 3 5 5\n [38] 5 6 5 0 6 7 6 6 3 2 7 8 1 1 7 7 6 9 9 6 1 3 3 9 1 8 7 1 1 0 9 1 4 4 5 4 0\n [75] 6 2 2 3 1 5 1 2 0 8 8 1 2 6 7 1 6 1 3 4 0 1 2 2 0 7\nLevels: 0 1 2 3 4 5 6 7 8 9\n\n\n\n\n\n\nmnist_res &lt;- mnist_test %&gt;%\n                select(label) %&gt;% \n                mutate(pred_label = pred_label_knn)\n\nmnist_res\n\n# A tibble: 100 × 2\n   label pred_label\n   &lt;fct&gt; &lt;fct&gt;     \n 1 8     8         \n 2 1     1         \n 3 4     9         \n 4 4     7         \n 5 6     6         \n 6 0     0         \n 7 2     2         \n 8 9     9         \n 9 1     1         \n10 4     4         \n# ℹ 90 more rows\n\n\n\n\n\n\nN &lt;- nrow(mnist_res)\n\nconfusion_mat &lt;- table(mnist_res %&gt;% select(label, pred_label))\nconfusion_mat\n\n     pred_label\nlabel  0  1  2  3  4  5  6  7  8  9\n    0  6  0  0  0  0  0  0  0  0  0\n    1  0 16  0  0  0  0  0  0  0  0\n    2  2  2 10  0  0  0  0  1  0  0\n    3  0  0  0 10  0  1  0  0  1  0\n    4  0  0  0  0  6  0  0  1  0  4\n    5  0  0  0  0  0  4  1  1  0  0\n    6  1  0  0  0  0  0  9  0  0  0\n    7  0  2  0  0  0  0  0  7  0  0\n    8  0  0  0  0  0  1  0  1  6  0\n    9  0  0  0  0  1  0  0  1  0  5\n\naccuracy &lt;- (confusion_mat %&gt;% diag %&gt;% sum)/N\naccuracy\n\n[1] 0.79"
  },
  {
    "objectID": "9-image.html#image-analysis",
    "href": "9-image.html#image-analysis",
    "title": "Introduction to Image Analysis",
    "section": "",
    "text": "What is an image? What does a computer “see”?\nIn essence, it is an array of numbers representing colour intensities called pixels.\nThe pixel (a word invented from “picture element”) is the basic unit of programmable color on a computer display or in a computer image.\n\n\n\n\n\n\n\n\n\n\n\n\nThe application of image analysis can be expanded to different domains of science, such as:\nImage detection on videos\n\nAutonomous cars\n\nAnimals identification\n\nDisease diagnosis\n\nMeasure Student Engagement\n\n\n\n\nhttp://yann.lecun.com/exdb/mnist/\n\n70,000 grayscale images of handwritten numbers at low resolution (28 by 28 pixels)\nUsed 60,000 to train the algorithm and 10,000 to test\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwe can use virtually ANY supervised classification algorithm (each pixel is a “feature” or “predictor”)\ne.g. k-nearest neighbours, trees/random forests, logistic/multinomial regression, support vector machines, neural networks\nyou have already studied a few of these techniques\nWe will use KNN to classify the images\n\n\n\n\nIf we assume each pixel is a feature/predictor then we should format that data such that the columns are pixels and each row corresponds to an image.\nWe’ll work with a subset of the MNIST data and consider 1000 images int he training data and 100 images in the test data.\n\nmnist_train\n\n# A tibble: 1,000 × 765\n   label pixel1 pixel2 pixel3 pixel4 pixel5 pixel6 pixel7 pixel8 pixel9 pixel10\n   &lt;fct&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n 1 2          0      0      0      0      0      0      0      0      0       0\n 2 7          0      0      0      0      0      0      0      0      0       0\n 3 3          0      0      0      0      0      0      0      0      0       0\n 4 4          0      0      0      0      0      0      0      0      0       0\n 5 6          0      0      0      0      0      0      0      0      0       0\n 6 1          0      0      0      0      0      0      0      0      0       0\n 7 8          0      0      0      0      0      0      0      0      0       0\n 8 1          0      0      0      0      0      0      0      0      0       0\n 9 0          0      0      0      0      0      0      0      0      0       0\n10 9          0      0      0      0      0      0      0      0      0       0\n# ℹ 990 more rows\n# ℹ 754 more variables: pixel11 &lt;dbl&gt;, pixel12 &lt;dbl&gt;, pixel13 &lt;dbl&gt;,\n#   pixel14 &lt;dbl&gt;, pixel15 &lt;dbl&gt;, pixel16 &lt;dbl&gt;, pixel17 &lt;dbl&gt;, pixel18 &lt;dbl&gt;,\n#   pixel19 &lt;dbl&gt;, pixel20 &lt;dbl&gt;, pixel21 &lt;dbl&gt;, pixel22 &lt;dbl&gt;, pixel23 &lt;dbl&gt;,\n#   pixel24 &lt;dbl&gt;, pixel25 &lt;dbl&gt;, pixel26 &lt;dbl&gt;, pixel27 &lt;dbl&gt;, pixel28 &lt;dbl&gt;,\n#   pixel29 &lt;dbl&gt;, pixel30 &lt;dbl&gt;, pixel31 &lt;dbl&gt;, pixel32 &lt;dbl&gt;, pixel33 &lt;dbl&gt;,\n#   pixel34 &lt;dbl&gt;, pixel35 &lt;dbl&gt;, pixel36 &lt;dbl&gt;, pixel37 &lt;dbl&gt;, …\n\n\n\nmnist_test\n\n# A tibble: 100 × 765\n   label pixel1 pixel2 pixel3 pixel4 pixel5 pixel6 pixel7 pixel8 pixel9 pixel10\n   &lt;fct&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n 1 8          0      0      0      0      0      0      0      0      0       0\n 2 1          0      0      0      0      0      0      0      0      0       0\n 3 4          0      0      0      0      0      0      0      0      0       0\n 4 4          0      0      0      0      0      0      0      0      0       0\n 5 6          0      0      0      0      0      0      0      0      0       0\n 6 0          0      0      0      0      0      0      0      0      0       0\n 7 2          0      0      0      0      0      0      0      0      0       0\n 8 9          0      0      0      0      0      0      0      0      0       0\n 9 1          0      0      0      0      0      0      0      0      0       0\n10 4          0      0      0      0      0      0      0      0      0       0\n# ℹ 90 more rows\n# ℹ 754 more variables: pixel11 &lt;dbl&gt;, pixel12 &lt;dbl&gt;, pixel13 &lt;dbl&gt;,\n#   pixel14 &lt;dbl&gt;, pixel15 &lt;dbl&gt;, pixel16 &lt;dbl&gt;, pixel17 &lt;dbl&gt;, pixel18 &lt;dbl&gt;,\n#   pixel19 &lt;dbl&gt;, pixel20 &lt;dbl&gt;, pixel21 &lt;dbl&gt;, pixel22 &lt;dbl&gt;, pixel23 &lt;dbl&gt;,\n#   pixel24 &lt;dbl&gt;, pixel25 &lt;dbl&gt;, pixel26 &lt;dbl&gt;, pixel27 &lt;dbl&gt;, pixel28 &lt;dbl&gt;,\n#   pixel29 &lt;dbl&gt;, pixel30 &lt;dbl&gt;, pixel31 &lt;dbl&gt;, pixel32 &lt;dbl&gt;, pixel33 &lt;dbl&gt;,\n#   pixel34 &lt;dbl&gt;, pixel35 &lt;dbl&gt;, pixel36 &lt;dbl&gt;, pixel37 &lt;dbl&gt;, …\n\n\n\n\n\n\nlibrary(class)\npred_label_knn &lt;- knn(mnist_train %&gt;% select(-label), \n                      mnist_test %&gt;% select(-label), \n                      cl = mnist_train$label , \n                      k = 5)\npred_label_knn\n\n  [1] 8 1 9 7 6 0 2 9 1 4 7 4 7 3 9 8 8 4 7 1 1 1 2 2 3 7 3 0 3 9 1 1 9 0 3 5 5\n [38] 5 6 5 0 6 7 6 6 3 2 7 8 1 1 7 7 6 9 9 6 1 3 3 9 1 8 7 1 1 0 9 1 4 4 5 4 0\n [75] 6 2 2 3 1 5 1 2 0 8 8 1 2 6 7 1 6 1 3 4 0 1 2 2 0 7\nLevels: 0 1 2 3 4 5 6 7 8 9\n\n\n\n\n\n\nmnist_res &lt;- mnist_test %&gt;%\n                select(label) %&gt;% \n                mutate(pred_label = pred_label_knn)\n\nmnist_res\n\n# A tibble: 100 × 2\n   label pred_label\n   &lt;fct&gt; &lt;fct&gt;     \n 1 8     8         \n 2 1     1         \n 3 4     9         \n 4 4     7         \n 5 6     6         \n 6 0     0         \n 7 2     2         \n 8 9     9         \n 9 1     1         \n10 4     4         \n# ℹ 90 more rows\n\n\n\n\n\n\nN &lt;- nrow(mnist_res)\n\nconfusion_mat &lt;- table(mnist_res %&gt;% select(label, pred_label))\nconfusion_mat\n\n     pred_label\nlabel  0  1  2  3  4  5  6  7  8  9\n    0  6  0  0  0  0  0  0  0  0  0\n    1  0 16  0  0  0  0  0  0  0  0\n    2  2  2 10  0  0  0  0  1  0  0\n    3  0  0  0 10  0  1  0  0  1  0\n    4  0  0  0  0  6  0  0  1  0  4\n    5  0  0  0  0  0  4  1  1  0  0\n    6  1  0  0  0  0  0  9  0  0  0\n    7  0  2  0  0  0  0  0  7  0  0\n    8  0  0  0  0  0  1  0  1  6  0\n    9  0  0  0  0  1  0  0  1  0  5\n\naccuracy &lt;- (confusion_mat %&gt;% diag %&gt;% sum)/N\naccuracy\n\n[1] 0.79"
  },
  {
    "objectID": "Tutorial7.html",
    "href": "Tutorial7.html",
    "title": "DS152 Tutorial Sheet 6",
    "section": "",
    "text": "We will work with the Swiss banknotes dataset and perform logistic regression to determine whether the status of a bank note is genuine or counterfeit, based on six predictors related to measurements made on the bills.\n\nlibrary(tidyverse)\nlibrary(mclust)\nglimpse(banknote)\n\nRows: 200\nColumns: 7\n$ Status   &lt;fct&gt; genuine, genuine, genuine, genuine, genuine, genuine, genuine…\n$ Length   &lt;dbl&gt; 214.8, 214.6, 214.8, 214.8, 215.0, 215.7, 215.5, 214.5, 214.9…\n$ Left     &lt;dbl&gt; 131.0, 129.7, 129.7, 129.7, 129.6, 130.8, 129.5, 129.6, 129.4…\n$ Right    &lt;dbl&gt; 131.1, 129.7, 129.7, 129.6, 129.7, 130.5, 129.7, 129.2, 129.7…\n$ Bottom   &lt;dbl&gt; 9.0, 8.1, 8.7, 7.5, 10.4, 9.0, 7.9, 7.2, 8.2, 9.2, 7.9, 7.7, …\n$ Top      &lt;dbl&gt; 9.7, 9.5, 9.6, 10.4, 7.7, 10.1, 9.6, 10.7, 11.0, 10.0, 11.7, …\n$ Diagonal &lt;dbl&gt; 141.0, 141.7, 142.2, 142.0, 141.8, 141.4, 141.6, 141.7, 141.9…\n\n\n(a) Run the code below to add a binary (0,1) variable to the dataset called status_binary where the value is 0 when the Status is counterfeit and 1 when the Status is genuine.\n\nbanknote &lt;- banknote %&gt;% \n              mutate(status_binary = as.numeric(Status == \"genuine\")) \nglimpse(banknote) \n\nRows: 200\nColumns: 8\n$ Status        &lt;fct&gt; genuine, genuine, genuine, genuine, genuine, genuine, ge…\n$ Length        &lt;dbl&gt; 214.8, 214.6, 214.8, 214.8, 215.0, 215.7, 215.5, 214.5, …\n$ Left          &lt;dbl&gt; 131.0, 129.7, 129.7, 129.7, 129.6, 130.8, 129.5, 129.6, …\n$ Right         &lt;dbl&gt; 131.1, 129.7, 129.7, 129.6, 129.7, 130.5, 129.7, 129.2, …\n$ Bottom        &lt;dbl&gt; 9.0, 8.1, 8.7, 7.5, 10.4, 9.0, 7.9, 7.2, 8.2, 9.2, 7.9, …\n$ Top           &lt;dbl&gt; 9.7, 9.5, 9.6, 10.4, 7.7, 10.1, 9.6, 10.7, 11.0, 10.0, 1…\n$ Diagonal      &lt;dbl&gt; 141.0, 141.7, 142.2, 142.0, 141.8, 141.4, 141.6, 141.7, …\n$ status_binary &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n\n\n(b) Replace [A], [B] and [C] in the code below to create a scatter point plot showing status_binary as the response variable and Top as a predictor. Do you think Top predictors for separating the counterfeit from the genuine notes?\n\nggplot(banknote, aes(x = [A], y = [B])) +\n  geom_[C]\n\n(c) Split the data into 85% training and 15% test data by replacing [A], [B], [C], [D] and [E] in the following code. Set the seed to 10465.\n\nlibrary(rsample)\nset.seed([A])\nbank_split &lt;- initial_split([B], prop = [C])\n\ntrain_bank_data &lt;- [D](bank_split)\ntest_bank_data  &lt;- [E](bank_split)\n\n(d) Replace [A], [B], [C] and [D] in the code below to fit a simple logistic regression model to the training data, using status_binary as the response variable and Top as a predictor.\n\nlogistic_model &lt;- [A]([B] ~ [C],\n                    family = binomial,\n                    data = [D])\nlogistic_model\n\n(e) Set up a threshold of 0.50 for classifying banknotes as genuine based on the test data set by replacing [A] and [B] in the following code.\n\nbank_res &lt;- test_bank_data %&gt;% \n            select(Status, status_binary) %&gt;% \n            mutate(pred_p = predict(logistic_model, \n                                    type = \"response\", newdata = [A])) %&gt;% \n            mutate(pred_status = ifelse(pred_p &gt;= [B],\"genuine\",\"counterfeit\")) \nbank_res\n\n(f) Create a confusion table by running the code below. What is the accuracy?\n\nN &lt;- nrow(bank_res)\n\nconfusion_mat &lt;- table(bank_res %&gt;% select(status_binary, pred_result))\nconfusion_mat\n\naccuracy &lt;- (confusion_mat %&gt;% diag %&gt;% sum)/N\naccuracy\n\n(g) Now rerun all of the above but instead use a multiple logistic regression model with Top and Diagonal as predictors. Which model indicates the best performance when it comes to distinguishing counterfeit notes from genuine ones?"
  },
  {
    "objectID": "Tutorial7.html#exercise-1",
    "href": "Tutorial7.html#exercise-1",
    "title": "DS152 Tutorial Sheet 6",
    "section": "",
    "text": "We will work with the Swiss banknotes dataset and perform logistic regression to determine whether the status of a bank note is genuine or counterfeit, based on six predictors related to measurements made on the bills.\n\nlibrary(tidyverse)\nlibrary(mclust)\nglimpse(banknote)\n\nRows: 200\nColumns: 7\n$ Status   &lt;fct&gt; genuine, genuine, genuine, genuine, genuine, genuine, genuine…\n$ Length   &lt;dbl&gt; 214.8, 214.6, 214.8, 214.8, 215.0, 215.7, 215.5, 214.5, 214.9…\n$ Left     &lt;dbl&gt; 131.0, 129.7, 129.7, 129.7, 129.6, 130.8, 129.5, 129.6, 129.4…\n$ Right    &lt;dbl&gt; 131.1, 129.7, 129.7, 129.6, 129.7, 130.5, 129.7, 129.2, 129.7…\n$ Bottom   &lt;dbl&gt; 9.0, 8.1, 8.7, 7.5, 10.4, 9.0, 7.9, 7.2, 8.2, 9.2, 7.9, 7.7, …\n$ Top      &lt;dbl&gt; 9.7, 9.5, 9.6, 10.4, 7.7, 10.1, 9.6, 10.7, 11.0, 10.0, 11.7, …\n$ Diagonal &lt;dbl&gt; 141.0, 141.7, 142.2, 142.0, 141.8, 141.4, 141.6, 141.7, 141.9…\n\n\n(a) Run the code below to add a binary (0,1) variable to the dataset called status_binary where the value is 0 when the Status is counterfeit and 1 when the Status is genuine.\n\nbanknote &lt;- banknote %&gt;% \n              mutate(status_binary = as.numeric(Status == \"genuine\")) \nglimpse(banknote) \n\nRows: 200\nColumns: 8\n$ Status        &lt;fct&gt; genuine, genuine, genuine, genuine, genuine, genuine, ge…\n$ Length        &lt;dbl&gt; 214.8, 214.6, 214.8, 214.8, 215.0, 215.7, 215.5, 214.5, …\n$ Left          &lt;dbl&gt; 131.0, 129.7, 129.7, 129.7, 129.6, 130.8, 129.5, 129.6, …\n$ Right         &lt;dbl&gt; 131.1, 129.7, 129.7, 129.6, 129.7, 130.5, 129.7, 129.2, …\n$ Bottom        &lt;dbl&gt; 9.0, 8.1, 8.7, 7.5, 10.4, 9.0, 7.9, 7.2, 8.2, 9.2, 7.9, …\n$ Top           &lt;dbl&gt; 9.7, 9.5, 9.6, 10.4, 7.7, 10.1, 9.6, 10.7, 11.0, 10.0, 1…\n$ Diagonal      &lt;dbl&gt; 141.0, 141.7, 142.2, 142.0, 141.8, 141.4, 141.6, 141.7, …\n$ status_binary &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n\n\n(b) Replace [A], [B] and [C] in the code below to create a scatter point plot showing status_binary as the response variable and Top as a predictor. Do you think Top predictors for separating the counterfeit from the genuine notes?\n\nggplot(banknote, aes(x = [A], y = [B])) +\n  geom_[C]\n\n(c) Split the data into 85% training and 15% test data by replacing [A], [B], [C], [D] and [E] in the following code. Set the seed to 10465.\n\nlibrary(rsample)\nset.seed([A])\nbank_split &lt;- initial_split([B], prop = [C])\n\ntrain_bank_data &lt;- [D](bank_split)\ntest_bank_data  &lt;- [E](bank_split)\n\n(d) Replace [A], [B], [C] and [D] in the code below to fit a simple logistic regression model to the training data, using status_binary as the response variable and Top as a predictor.\n\nlogistic_model &lt;- [A]([B] ~ [C],\n                    family = binomial,\n                    data = [D])\nlogistic_model\n\n(e) Set up a threshold of 0.50 for classifying banknotes as genuine based on the test data set by replacing [A] and [B] in the following code.\n\nbank_res &lt;- test_bank_data %&gt;% \n            select(Status, status_binary) %&gt;% \n            mutate(pred_p = predict(logistic_model, \n                                    type = \"response\", newdata = [A])) %&gt;% \n            mutate(pred_status = ifelse(pred_p &gt;= [B],\"genuine\",\"counterfeit\")) \nbank_res\n\n(f) Create a confusion table by running the code below. What is the accuracy?\n\nN &lt;- nrow(bank_res)\n\nconfusion_mat &lt;- table(bank_res %&gt;% select(status_binary, pred_result))\nconfusion_mat\n\naccuracy &lt;- (confusion_mat %&gt;% diag %&gt;% sum)/N\naccuracy\n\n(g) Now rerun all of the above but instead use a multiple logistic regression model with Top and Diagonal as predictors. Which model indicates the best performance when it comes to distinguishing counterfeit notes from genuine ones?"
  },
  {
    "objectID": "Tutorial7.html#exercise-2",
    "href": "Tutorial7.html#exercise-2",
    "title": "DS152 Tutorial Sheet 6",
    "section": "Exercise 2",
    "text": "Exercise 2\nWe will consider data on crime rates by US state. This data set contains arrests per 100,000 residents for assault and murder in each of the 50 US states in 1973. A glimpse of the dataset, called arrests_dat, is displayed below:\n\nlibrary(tidyverse)\narrests_dat &lt;- read_csv(\"https://www.dropbox.com/s/8dc41ynd12fwvhr/arrests_dat.csv?raw=1\")\nglimpse(arrests_dat)\n\nRows: 50\nColumns: 3\n$ state   &lt;chr&gt; \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Col…\n$ murder  &lt;dbl&gt; 13.2, 10.0, 8.1, 8.8, 9.0, 7.9, 3.3, 5.9, 15.4, 17.4, 5.3, 2.6…\n$ assault &lt;dbl&gt; 236, 263, 294, 190, 276, 204, 110, 238, 335, 211, 46, 120, 249…\n\n\n(a) To visualise the data, what would you replace [A], [B], [C] and [D] in the code below with to create this plot?\n\nggplot(arrests_dat, [A](x = [B], y = [C])) +\n  [D]() +\n  xlab(\"Murder arrests (per 100,000)\") +\n  ylab(\"Assault arrests (per 100,000)\")\n\n\n\n\n\n\n\n\n\n\n(b) Now, let’s perform k-means clustering. Firstly, we will create a new dataset that contains only the murder and assault variables from the arrests_dat dataset. Then we will run the k-means algorithm with 2 clusters on this data. Replace [E],[F] and [G] in the code such that this objective can be achieved.\n\narrests_dat2 &lt;- arrests_dat %&gt;% \n              [E](murder, assault)\n\nkmean_res &lt;- [F](arrests_dat2, centers = [G])\n\n(c) Next we want to visualise the clustering results. What would you replace [H], [I], [J] in the code below to create this plot?\n\nlibrary(factoextra)\n[H]([I] , data = arrests_dat2, [J] = \"point\")"
  },
  {
    "objectID": "Tutorial7_soln.html",
    "href": "Tutorial7_soln.html",
    "title": "DS152 Tutorial Sheet 6",
    "section": "",
    "text": "We will work with the Swiss banknotes dataset and perform logistic regression to determine whether the status of a bank note is genuine or counterfeit, based on six predictors related to measurements made on the bills.\n\nlibrary(tidyverse)\nlibrary(mclust)\nglimpse(banknote)\n\nRows: 200\nColumns: 7\n$ Status   &lt;fct&gt; genuine, genuine, genuine, genuine, genuine, genuine, genuine…\n$ Length   &lt;dbl&gt; 214.8, 214.6, 214.8, 214.8, 215.0, 215.7, 215.5, 214.5, 214.9…\n$ Left     &lt;dbl&gt; 131.0, 129.7, 129.7, 129.7, 129.6, 130.8, 129.5, 129.6, 129.4…\n$ Right    &lt;dbl&gt; 131.1, 129.7, 129.7, 129.6, 129.7, 130.5, 129.7, 129.2, 129.7…\n$ Bottom   &lt;dbl&gt; 9.0, 8.1, 8.7, 7.5, 10.4, 9.0, 7.9, 7.2, 8.2, 9.2, 7.9, 7.7, …\n$ Top      &lt;dbl&gt; 9.7, 9.5, 9.6, 10.4, 7.7, 10.1, 9.6, 10.7, 11.0, 10.0, 11.7, …\n$ Diagonal &lt;dbl&gt; 141.0, 141.7, 142.2, 142.0, 141.8, 141.4, 141.6, 141.7, 141.9…\n\n\n(a) Run the code below to add a binary (0,1) variable to the dataset called status_binary where the value is 0 when the Status is counterfeit and 1 when the Status is genuine.\n\nbanknote &lt;- banknote %&gt;% \n              mutate(status_binary = as.numeric(Status == \"genuine\")) \nglimpse(banknote) \n\nRows: 200\nColumns: 8\n$ Status        &lt;fct&gt; genuine, genuine, genuine, genuine, genuine, genuine, ge…\n$ Length        &lt;dbl&gt; 214.8, 214.6, 214.8, 214.8, 215.0, 215.7, 215.5, 214.5, …\n$ Left          &lt;dbl&gt; 131.0, 129.7, 129.7, 129.7, 129.6, 130.8, 129.5, 129.6, …\n$ Right         &lt;dbl&gt; 131.1, 129.7, 129.7, 129.6, 129.7, 130.5, 129.7, 129.2, …\n$ Bottom        &lt;dbl&gt; 9.0, 8.1, 8.7, 7.5, 10.4, 9.0, 7.9, 7.2, 8.2, 9.2, 7.9, …\n$ Top           &lt;dbl&gt; 9.7, 9.5, 9.6, 10.4, 7.7, 10.1, 9.6, 10.7, 11.0, 10.0, 1…\n$ Diagonal      &lt;dbl&gt; 141.0, 141.7, 142.2, 142.0, 141.8, 141.4, 141.6, 141.7, …\n$ status_binary &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n\n\n(b) Replace [A], [B] and [C] in the code below to create a scatter point plot showing status_binary as the response variable and Top as a predictor. Do you think Top predictors for separating the counterfeit from the genuine notes?\n\nggplot(banknote, aes(x = Top, y = status_binary)) +\n  geom_point()\n\n\n\n\n\n\n\n\n“Genuine” is the reference group here. From the graph, it appears that as Top increases the chance of being a genuine note decreases.\n(c) Split the data into 85% training and 15% test data by replacing [A], [B], [C], [D] and [E] in the following code. Set the seed to 10465.\n\nlibrary(rsample)\nset.seed(10465)\nbank_split &lt;- initial_split(banknote, prop = 0.85)\n\ntrain_bank_data &lt;- training(bank_split)\ntest_bank_data  &lt;- testing(bank_split)\n\n(d) Replace [A], [B], [C] and [D] in the code below to fit a simple logistic regression model to the training data, using status_binary as the response variable and Top as a predictor.\n\nlogistic_model &lt;- glm(status_binary ~ Top,\n                    family = binomial,\n                    data = train_bank_data)\nlogistic_model\n\n\nCall:  glm(formula = status_binary ~ Top, family = binomial, data = train_bank_data)\n\nCoefficients:\n(Intercept)          Top  \n     25.664       -2.416  \n\nDegrees of Freedom: 169 Total (i.e. Null);  168 Residual\nNull Deviance:      235.6 \nResidual Deviance: 159  AIC: 163\n\n\nNote for tutors: Remind students that we use glm for logistic regression rather than lm. Highlight the use of the training data for fitting the model rather than the full dataset.\n(e) Set up a threshold of 0.50 for classifying banknotes as genuine based on the test data set by replacing [A] and [B] in the following code.\n\nbank_res &lt;- test_bank_data %&gt;% \n            select(Status, status_binary) %&gt;% \n            mutate(pred_p = predict(logistic_model, \n                                    type = \"response\", newdata = test_bank_data)) %&gt;% \n            mutate(pred_status = ifelse(pred_p &gt;= 0.5,\"genuine\",\"counterfeit\")) \nbank_res\n\n        Status status_binary     pred_p pred_status\n1      genuine             1 0.92193446     genuine\n2      genuine             1 0.63087725     genuine\n3      genuine             1 0.45292194 counterfeit\n4      genuine             1 0.28623810 counterfeit\n5      genuine             1 0.57306421     genuine\n6      genuine             1 0.81794016     genuine\n7      genuine             1 0.45292194 counterfeit\n8      genuine             1 0.95036554     genuine\n9      genuine             1 0.98051882     genuine\n10     genuine             1 0.51318350     genuine\n11     genuine             1 0.81794016     genuine\n12     genuine             1 0.57306421     genuine\n13     genuine             1 0.45292194 counterfeit\n14     genuine             1 0.51318350     genuine\n15     genuine             1 0.81794016     genuine\n16     genuine             1 0.68516262     genuine\n17     genuine             1 0.68516262     genuine\n18 counterfeit             0 0.10699452 counterfeit\n19 counterfeit             0 0.63087725     genuine\n20 counterfeit             0 0.13236623 counterfeit\n21 counterfeit             0 0.05485377 counterfeit\n22 counterfeit             0 0.19829875 counterfeit\n23 counterfeit             0 0.19829875 counterfeit\n24 counterfeit             0 0.01704413 counterfeit\n25 counterfeit             0 0.77916995     genuine\n26 counterfeit             0 0.10699452 counterfeit\n27 counterfeit             0 0.81794016     genuine\n28 counterfeit             0 0.13236623 counterfeit\n29 counterfeit             0 0.13236623 counterfeit\n30 counterfeit             0 0.10699452 counterfeit\n\n\nNote for tutors: Highlight the use of the test data for getting predictions from the model rather than the full dataset.\n(f) Create a confusion table by running the code below. What is the accuracy?\n\nN &lt;- nrow(bank_res)\n\nconfusion_mat &lt;- table(bank_res %&gt;% select(Status, pred_status))\nconfusion_mat\n\n             pred_status\nStatus        counterfeit genuine\n  counterfeit          10       3\n  genuine               4      13\n\naccuracy &lt;- (confusion_mat %&gt;% diag %&gt;% sum)/N\naccuracy\n\n[1] 0.7666667\n\n\n(g) Now rerun all of the above but instead use a multiple logistic regression model with Top and Diagonal as predictors. Which model indicates the best performance when it comes to distinguishing counterfeit notes from genuine ones?\n\nlogistic_model2 &lt;- glm(status_binary ~ Top + Diagonal,\n                    family = binomial,\n                    data = train_bank_data)\nlogistic_model2\n\n\nCall:  glm(formula = status_binary ~ Top + Diagonal, family = binomial, \n    data = train_bank_data)\n\nCoefficients:\n(Intercept)          Top     Diagonal  \n   -850.438       -1.957        6.205  \n\nDegrees of Freedom: 169 Total (i.e. Null);  167 Residual\nNull Deviance:      235.6 \nResidual Deviance: 17.78    AIC: 23.78\n\n#### Update bank_res from earlier with prediction from model 2\nbank_res &lt;- bank_res %&gt;% \n            mutate(pred_p2 = predict(logistic_model2, \n                                    type = \"response\", newdata = test_bank_data)) %&gt;% \n            mutate(pred_status2 = ifelse(pred_p2 &gt;= 0.5,\"genuine\",\"counterfeit\")) \nbank_res\n\n        Status status_binary     pred_p pred_status      pred_p2 pred_status2\n1      genuine             1 0.92193446     genuine 9.999979e-01      genuine\n2      genuine             1 0.63087725     genuine 9.999649e-01      genuine\n3      genuine             1 0.45292194 counterfeit 9.995938e-01      genuine\n4      genuine             1 0.28623810 counterfeit 9.997887e-01      genuine\n5      genuine             1 0.57306421     genuine 9.999876e-01      genuine\n6      genuine             1 0.81794016     genuine 9.998079e-01      genuine\n7      genuine             1 0.45292194 counterfeit 9.997815e-01      genuine\n8      genuine             1 0.95036554     genuine 9.999992e-01      genuine\n9      genuine             1 0.98051882     genuine 9.993964e-01      genuine\n10     genuine             1 0.51318350     genuine 9.183236e-01      genuine\n11     genuine             1 0.81794016     genuine 9.977071e-01      genuine\n12     genuine             1 0.57306421     genuine 9.998523e-01      genuine\n13     genuine             1 0.45292194 counterfeit 9.995938e-01      genuine\n14     genuine             1 0.51318350     genuine 9.749300e-01      genuine\n15     genuine             1 0.81794016     genuine 9.999445e-01      genuine\n16     genuine             1 0.68516262     genuine 9.859047e-01      genuine\n17     genuine             1 0.68516262     genuine 9.958835e-01      genuine\n18 counterfeit             0 0.10699452 counterfeit 7.207559e-03  counterfeit\n19 counterfeit             0 0.63087725     genuine 5.880352e-02  counterfeit\n20 counterfeit             0 0.13236623 counterfeit 1.370679e-03  counterfeit\n21 counterfeit             0 0.05485377 counterfeit 7.450716e-03  counterfeit\n22 counterfeit             0 0.19829875 counterfeit 1.696606e-04  counterfeit\n23 counterfeit             0 0.19829875 counterfeit 6.375529e-07  counterfeit\n24 counterfeit             0 0.01704413 counterfeit 6.819483e-05  counterfeit\n25 counterfeit             0 0.77916995     genuine 4.220317e-04  counterfeit\n26 counterfeit             0 0.10699452 counterfeit 6.064948e-04  counterfeit\n27 counterfeit             0 0.81794016     genuine 3.291979e-03  counterfeit\n28 counterfeit             0 0.13236623 counterfeit 2.133337e-04  counterfeit\n29 counterfeit             0 0.13236623 counterfeit 2.133337e-04  counterfeit\n30 counterfeit             0 0.10699452 counterfeit 1.127354e-03  counterfeit\n\nconfusion_mat2 &lt;- table(bank_res %&gt;% select(Status, pred_status2))\nconfusion_mat2\n\n             pred_status2\nStatus        counterfeit genuine\n  counterfeit          13       0\n  genuine               0      17\n\naccuracy2 &lt;- (confusion_mat2 %&gt;% diag %&gt;% sum)/N\naccuracy2\n\n[1] 1"
  },
  {
    "objectID": "Tutorial7_soln.html#exercise-1",
    "href": "Tutorial7_soln.html#exercise-1",
    "title": "DS152 Tutorial Sheet 6",
    "section": "",
    "text": "We will work with the Swiss banknotes dataset and perform logistic regression to determine whether the status of a bank note is genuine or counterfeit, based on six predictors related to measurements made on the bills.\n\nlibrary(tidyverse)\nlibrary(mclust)\nglimpse(banknote)\n\nRows: 200\nColumns: 7\n$ Status   &lt;fct&gt; genuine, genuine, genuine, genuine, genuine, genuine, genuine…\n$ Length   &lt;dbl&gt; 214.8, 214.6, 214.8, 214.8, 215.0, 215.7, 215.5, 214.5, 214.9…\n$ Left     &lt;dbl&gt; 131.0, 129.7, 129.7, 129.7, 129.6, 130.8, 129.5, 129.6, 129.4…\n$ Right    &lt;dbl&gt; 131.1, 129.7, 129.7, 129.6, 129.7, 130.5, 129.7, 129.2, 129.7…\n$ Bottom   &lt;dbl&gt; 9.0, 8.1, 8.7, 7.5, 10.4, 9.0, 7.9, 7.2, 8.2, 9.2, 7.9, 7.7, …\n$ Top      &lt;dbl&gt; 9.7, 9.5, 9.6, 10.4, 7.7, 10.1, 9.6, 10.7, 11.0, 10.0, 11.7, …\n$ Diagonal &lt;dbl&gt; 141.0, 141.7, 142.2, 142.0, 141.8, 141.4, 141.6, 141.7, 141.9…\n\n\n(a) Run the code below to add a binary (0,1) variable to the dataset called status_binary where the value is 0 when the Status is counterfeit and 1 when the Status is genuine.\n\nbanknote &lt;- banknote %&gt;% \n              mutate(status_binary = as.numeric(Status == \"genuine\")) \nglimpse(banknote) \n\nRows: 200\nColumns: 8\n$ Status        &lt;fct&gt; genuine, genuine, genuine, genuine, genuine, genuine, ge…\n$ Length        &lt;dbl&gt; 214.8, 214.6, 214.8, 214.8, 215.0, 215.7, 215.5, 214.5, …\n$ Left          &lt;dbl&gt; 131.0, 129.7, 129.7, 129.7, 129.6, 130.8, 129.5, 129.6, …\n$ Right         &lt;dbl&gt; 131.1, 129.7, 129.7, 129.6, 129.7, 130.5, 129.7, 129.2, …\n$ Bottom        &lt;dbl&gt; 9.0, 8.1, 8.7, 7.5, 10.4, 9.0, 7.9, 7.2, 8.2, 9.2, 7.9, …\n$ Top           &lt;dbl&gt; 9.7, 9.5, 9.6, 10.4, 7.7, 10.1, 9.6, 10.7, 11.0, 10.0, 1…\n$ Diagonal      &lt;dbl&gt; 141.0, 141.7, 142.2, 142.0, 141.8, 141.4, 141.6, 141.7, …\n$ status_binary &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n\n\n(b) Replace [A], [B] and [C] in the code below to create a scatter point plot showing status_binary as the response variable and Top as a predictor. Do you think Top predictors for separating the counterfeit from the genuine notes?\n\nggplot(banknote, aes(x = Top, y = status_binary)) +\n  geom_point()\n\n\n\n\n\n\n\n\n“Genuine” is the reference group here. From the graph, it appears that as Top increases the chance of being a genuine note decreases.\n(c) Split the data into 85% training and 15% test data by replacing [A], [B], [C], [D] and [E] in the following code. Set the seed to 10465.\n\nlibrary(rsample)\nset.seed(10465)\nbank_split &lt;- initial_split(banknote, prop = 0.85)\n\ntrain_bank_data &lt;- training(bank_split)\ntest_bank_data  &lt;- testing(bank_split)\n\n(d) Replace [A], [B], [C] and [D] in the code below to fit a simple logistic regression model to the training data, using status_binary as the response variable and Top as a predictor.\n\nlogistic_model &lt;- glm(status_binary ~ Top,\n                    family = binomial,\n                    data = train_bank_data)\nlogistic_model\n\n\nCall:  glm(formula = status_binary ~ Top, family = binomial, data = train_bank_data)\n\nCoefficients:\n(Intercept)          Top  \n     25.664       -2.416  \n\nDegrees of Freedom: 169 Total (i.e. Null);  168 Residual\nNull Deviance:      235.6 \nResidual Deviance: 159  AIC: 163\n\n\nNote for tutors: Remind students that we use glm for logistic regression rather than lm. Highlight the use of the training data for fitting the model rather than the full dataset.\n(e) Set up a threshold of 0.50 for classifying banknotes as genuine based on the test data set by replacing [A] and [B] in the following code.\n\nbank_res &lt;- test_bank_data %&gt;% \n            select(Status, status_binary) %&gt;% \n            mutate(pred_p = predict(logistic_model, \n                                    type = \"response\", newdata = test_bank_data)) %&gt;% \n            mutate(pred_status = ifelse(pred_p &gt;= 0.5,\"genuine\",\"counterfeit\")) \nbank_res\n\n        Status status_binary     pred_p pred_status\n1      genuine             1 0.92193446     genuine\n2      genuine             1 0.63087725     genuine\n3      genuine             1 0.45292194 counterfeit\n4      genuine             1 0.28623810 counterfeit\n5      genuine             1 0.57306421     genuine\n6      genuine             1 0.81794016     genuine\n7      genuine             1 0.45292194 counterfeit\n8      genuine             1 0.95036554     genuine\n9      genuine             1 0.98051882     genuine\n10     genuine             1 0.51318350     genuine\n11     genuine             1 0.81794016     genuine\n12     genuine             1 0.57306421     genuine\n13     genuine             1 0.45292194 counterfeit\n14     genuine             1 0.51318350     genuine\n15     genuine             1 0.81794016     genuine\n16     genuine             1 0.68516262     genuine\n17     genuine             1 0.68516262     genuine\n18 counterfeit             0 0.10699452 counterfeit\n19 counterfeit             0 0.63087725     genuine\n20 counterfeit             0 0.13236623 counterfeit\n21 counterfeit             0 0.05485377 counterfeit\n22 counterfeit             0 0.19829875 counterfeit\n23 counterfeit             0 0.19829875 counterfeit\n24 counterfeit             0 0.01704413 counterfeit\n25 counterfeit             0 0.77916995     genuine\n26 counterfeit             0 0.10699452 counterfeit\n27 counterfeit             0 0.81794016     genuine\n28 counterfeit             0 0.13236623 counterfeit\n29 counterfeit             0 0.13236623 counterfeit\n30 counterfeit             0 0.10699452 counterfeit\n\n\nNote for tutors: Highlight the use of the test data for getting predictions from the model rather than the full dataset.\n(f) Create a confusion table by running the code below. What is the accuracy?\n\nN &lt;- nrow(bank_res)\n\nconfusion_mat &lt;- table(bank_res %&gt;% select(Status, pred_status))\nconfusion_mat\n\n             pred_status\nStatus        counterfeit genuine\n  counterfeit          10       3\n  genuine               4      13\n\naccuracy &lt;- (confusion_mat %&gt;% diag %&gt;% sum)/N\naccuracy\n\n[1] 0.7666667\n\n\n(g) Now rerun all of the above but instead use a multiple logistic regression model with Top and Diagonal as predictors. Which model indicates the best performance when it comes to distinguishing counterfeit notes from genuine ones?\n\nlogistic_model2 &lt;- glm(status_binary ~ Top + Diagonal,\n                    family = binomial,\n                    data = train_bank_data)\nlogistic_model2\n\n\nCall:  glm(formula = status_binary ~ Top + Diagonal, family = binomial, \n    data = train_bank_data)\n\nCoefficients:\n(Intercept)          Top     Diagonal  \n   -850.438       -1.957        6.205  \n\nDegrees of Freedom: 169 Total (i.e. Null);  167 Residual\nNull Deviance:      235.6 \nResidual Deviance: 17.78    AIC: 23.78\n\n#### Update bank_res from earlier with prediction from model 2\nbank_res &lt;- bank_res %&gt;% \n            mutate(pred_p2 = predict(logistic_model2, \n                                    type = \"response\", newdata = test_bank_data)) %&gt;% \n            mutate(pred_status2 = ifelse(pred_p2 &gt;= 0.5,\"genuine\",\"counterfeit\")) \nbank_res\n\n        Status status_binary     pred_p pred_status      pred_p2 pred_status2\n1      genuine             1 0.92193446     genuine 9.999979e-01      genuine\n2      genuine             1 0.63087725     genuine 9.999649e-01      genuine\n3      genuine             1 0.45292194 counterfeit 9.995938e-01      genuine\n4      genuine             1 0.28623810 counterfeit 9.997887e-01      genuine\n5      genuine             1 0.57306421     genuine 9.999876e-01      genuine\n6      genuine             1 0.81794016     genuine 9.998079e-01      genuine\n7      genuine             1 0.45292194 counterfeit 9.997815e-01      genuine\n8      genuine             1 0.95036554     genuine 9.999992e-01      genuine\n9      genuine             1 0.98051882     genuine 9.993964e-01      genuine\n10     genuine             1 0.51318350     genuine 9.183236e-01      genuine\n11     genuine             1 0.81794016     genuine 9.977071e-01      genuine\n12     genuine             1 0.57306421     genuine 9.998523e-01      genuine\n13     genuine             1 0.45292194 counterfeit 9.995938e-01      genuine\n14     genuine             1 0.51318350     genuine 9.749300e-01      genuine\n15     genuine             1 0.81794016     genuine 9.999445e-01      genuine\n16     genuine             1 0.68516262     genuine 9.859047e-01      genuine\n17     genuine             1 0.68516262     genuine 9.958835e-01      genuine\n18 counterfeit             0 0.10699452 counterfeit 7.207559e-03  counterfeit\n19 counterfeit             0 0.63087725     genuine 5.880352e-02  counterfeit\n20 counterfeit             0 0.13236623 counterfeit 1.370679e-03  counterfeit\n21 counterfeit             0 0.05485377 counterfeit 7.450716e-03  counterfeit\n22 counterfeit             0 0.19829875 counterfeit 1.696606e-04  counterfeit\n23 counterfeit             0 0.19829875 counterfeit 6.375529e-07  counterfeit\n24 counterfeit             0 0.01704413 counterfeit 6.819483e-05  counterfeit\n25 counterfeit             0 0.77916995     genuine 4.220317e-04  counterfeit\n26 counterfeit             0 0.10699452 counterfeit 6.064948e-04  counterfeit\n27 counterfeit             0 0.81794016     genuine 3.291979e-03  counterfeit\n28 counterfeit             0 0.13236623 counterfeit 2.133337e-04  counterfeit\n29 counterfeit             0 0.13236623 counterfeit 2.133337e-04  counterfeit\n30 counterfeit             0 0.10699452 counterfeit 1.127354e-03  counterfeit\n\nconfusion_mat2 &lt;- table(bank_res %&gt;% select(Status, pred_status2))\nconfusion_mat2\n\n             pred_status2\nStatus        counterfeit genuine\n  counterfeit          13       0\n  genuine               0      17\n\naccuracy2 &lt;- (confusion_mat2 %&gt;% diag %&gt;% sum)/N\naccuracy2\n\n[1] 1"
  },
  {
    "objectID": "Tutorial7_soln.html#exercise-2",
    "href": "Tutorial7_soln.html#exercise-2",
    "title": "DS152 Tutorial Sheet 6",
    "section": "Exercise 2",
    "text": "Exercise 2\nWe will consider data on crime rates by US state. This data set contains arrests per 100,000 residents for assault and murder in each of the 50 US states in 1973. A glimpse of the dataset, called arrests_dat, is displayed below:\n\nlibrary(tidyverse)\narrests_dat &lt;- read_csv(\"https://www.dropbox.com/s/8dc41ynd12fwvhr/arrests_dat.csv?raw=1\")\nglimpse(arrests_dat)\n\nRows: 50\nColumns: 3\n$ state   &lt;chr&gt; \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Col…\n$ murder  &lt;dbl&gt; 13.2, 10.0, 8.1, 8.8, 9.0, 7.9, 3.3, 5.9, 15.4, 17.4, 5.3, 2.6…\n$ assault &lt;dbl&gt; 236, 263, 294, 190, 276, 204, 110, 238, 335, 211, 46, 120, 249…\n\n\n(a) To visualise the data, what would you replace [A], [B], [C] and [D] in the code below with to create this plot?\n\nggplot(arrests_dat, aes(x = murder, y = assault)) +\n  geom_point() +\n  xlab(\"Murder arrests (per 100,000)\") +\n  ylab(\"Assault arrests (per 100,000)\")\n\n\n\n\n\n\n\n\n(b) Now, let’s perform k-means clustering. Firstly, we will create a new dataset that contains only the murder and assault variables from the arrests_dat dataset. Then we will run the k-means algorithm with 2 clusters on this data. Replace [E],[F] and [G] in the code such that this objective can be achieved.\n\narrests_dat2 &lt;- arrests_dat %&gt;% \n                  dplyr::select(murder, assault)\n\nkmean_res &lt;- kmeans(arrests_dat2, centers = 2)\n\n(c) Next we want to visualise the clustering results. What would you replace [H], [I], [J] in the code below to create this plot?\n\nlibrary(factoextra)\n\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n\nfviz_cluster(kmean_res , data = arrests_dat2, geom = \"point\")"
  }
]